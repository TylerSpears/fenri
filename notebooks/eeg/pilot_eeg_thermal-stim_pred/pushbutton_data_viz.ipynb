{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import collections\n",
    "import copy\n",
    "import datetime\n",
    "import functools\n",
    "import inspect\n",
    "import io\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import pdb\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "import time\n",
    "import typing\n",
    "import warnings\n",
    "import zipfile\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint as ppr\n",
    "\n",
    "from box import Box\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib widget\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import networkx\n",
    "import einops\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "plt.rcParams.update({\"image.cmap\": \"gray\"})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import\n",
    "SUBJ_DATA_DIR_ROOT = Path(\n",
    "    \"/data/srv/data/pitn/uva/liu_insula_implant_study/pilot/eeg_scalp_thermal_stim/set_file\"\n",
    ")\n",
    "assert SUBJ_DATA_DIR_ROOT.exists()\n",
    "\n",
    "MONTAGE_F = SUBJ_DATA_DIR_ROOT.parent / \"eeg_cap_info\" / \"CACS-64_REF.bvef\"\n",
    "MONTAGE = mne.channels.read_custom_montage(MONTAGE_F)\n",
    "\n",
    "SUBJ_IDS = (\"S001\", \"S002\", \"S003\")\n",
    "# SUBJ_IDS = (\"S002\",)\n",
    "\n",
    "# Locate files for each subject.\n",
    "subj_data = Box(default_box=True)\n",
    "for s in SUBJ_IDS:\n",
    "    s_f = dict()\n",
    "\n",
    "    s_dir = SUBJ_DATA_DIR_ROOT / s\n",
    "    s_f[\"fdt\"] = next(s_dir.glob(\"Resting_State_Medoc*.fdt\"))\n",
    "    s_f[\"set\"] = next(s_dir.glob(\"Resting_State_Medoc*.set\"))\n",
    "    subj_data[s].files = s_f\n",
    "\n",
    "# Based on average adult head sizes according to actiCAP\n",
    "CAP_CIRCUMFERENCE_CM = 57\n",
    "head_radius_cm = CAP_CIRCUMFERENCE_CM / (2 * np.pi)\n",
    "# This is roughly 9 cm, which is \"close enough\" to 1 decimeter. So, the montage unit\n",
    "# should just be set to 'dm'.\n",
    "\n",
    "# Create MNE Raw object readers from files\n",
    "for s in subj_data.keys():\n",
    "    # Decimeter montage unit size?\n",
    "    data = mne.io.read_raw_eeglab(\n",
    "        subj_data[s].files.set,\n",
    "        montage_units=\"dm\",\n",
    "    )\n",
    "    data.set_montage(\n",
    "        MONTAGE,\n",
    "        match_case=False,\n",
    "        match_alias=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    subj_data[s].raw = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach additional metadata/cleanup and parse events\n",
    "THERMAL_RAMPUP_TIME_S = 10.0\n",
    "\n",
    "for s, data in subj_data.items():\n",
    "    data.raw.annotations.rename({\"R128\": \"pushbutton\"})\n",
    "    events, _ = mne.events_from_annotations(data.raw, regexp=\"pushbutton\")\n",
    "    therm_rampup_end_times = data.raw.times[events[:, 0]]\n",
    "    min_therm_ramp_start_times = therm_rampup_end_times - THERMAL_RAMPUP_TIME_S\n",
    "    data.raw.annotations.append(\n",
    "        onset=min_therm_ramp_start_times,\n",
    "        duration=THERMAL_RAMPUP_TIME_S + 2,\n",
    "        description=[\n",
    "            f\"possible_therm_ramp\" for i in range(len(min_therm_ramp_start_times))\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in subj_data.keys():\n",
    "    subj_data[s].preproc = subj_data[s].raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad channels from the start.\n",
    "BAD_CHANNELS = {\"S002\": (\"FT10\", \"AF7\", \"FT8\", \"FC2\")}\n",
    "\n",
    "for s in BAD_CHANNELS.keys():\n",
    "    if s not in subj_data.keys():\n",
    "        continue\n",
    "    subj_data[s].preproc.info[\"bads\"] = list(BAD_CHANNELS[s])\n",
    "\n",
    "BAD_SPANS = {\n",
    "    \"S001\": [\n",
    "        (0.0, 14.877),\n",
    "        (205.535, 274.775),\n",
    "        (448.082, 576.625),\n",
    "    ],\n",
    "    \"S002\": [\n",
    "        (166.914, 188.814),\n",
    "        (194.137, 197.821),\n",
    "        (316.695, 318.357),\n",
    "        (326.071, 327.739),\n",
    "        (338.782, 342.160),\n",
    "        (362.216, 365.255),\n",
    "    ],\n",
    "    \"S003\": [(67.062, 94.477), (180.352, 193.434), (395.036, 397.768)],\n",
    "}\n",
    "\n",
    "\n",
    "for s in BAD_SPANS.keys():\n",
    "    if s not in subj_data.keys():\n",
    "        continue\n",
    "    onsets = list()\n",
    "    durs = list()\n",
    "    for span in BAD_SPANS[s]:\n",
    "        onsets.append(span[0])\n",
    "        durs.append(span[1] - span[0])\n",
    "    subj_data[s].preproc.annotations.append(\n",
    "        onset=onsets, duration=durs, description=\"bad_dropout\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate resting/breaks.\n",
    "MIN_BREAK_DURATION = 6\n",
    "\n",
    "for s, data in subj_data.items():\n",
    "    breaks = mne.preprocessing.annotate_break(\n",
    "        data.preproc,\n",
    "        min_break_duration=MIN_BREAK_DURATION,\n",
    "        t_start_after_previous=5,\n",
    "        t_stop_before_next=0.5,\n",
    "        verbose=True,\n",
    "    )\n",
    "    breaks.rename({\"BAD_break\": \"break\"})\n",
    "    data.preproc.annotations.append(\n",
    "        onset=breaks.onset, duration=breaks.duration, description=breaks.description\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reference channel as the average of all good channels\n",
    "for s in subj_data.keys():\n",
    "    subj_data[s].preproc.load_data()\n",
    "    subj_data[s].preproc.set_eeg_reference(\"average\")\n",
    "\n",
    "# Filter out power line noise with a notch filter\n",
    "# Only spikes at 60Hz and 180Hz were visible in these data.\n",
    "POWER_LINE_FREQS = (60, 180)\n",
    "\n",
    "for s in subj_data.keys():\n",
    "    subj_data[s].preproc.load_data()\n",
    "    subj_data[s].preproc.notch_filter(POWER_LINE_FREQS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = subj_data.S001.raw.copy()\n",
    "# r.set_eeg_reference('average')\n",
    "# r.filter(l_freq=1.0, h_freq=None)\n",
    "# r.plot(remove_dc=True, butterfly=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of bridged electrodes for later interpolation.\n",
    "\n",
    "# Override some bridge indices, as they seem spatially unlikely.\n",
    "BRIDGE_OVERRIDE = {\n",
    "    \"S002\": [(19, 21), (19, 54), (21, 54)],\n",
    "    \"S003\": [\n",
    "        # REMOVE (4, 35) # (FT9, F1)\n",
    "        # REMOVE (12, 45) # (Pz, PO7))\n",
    "        (13, 14),  # (P3, P7)\n",
    "        (13, 47),  # (P3, POz)\n",
    "        (14, 47),  # (P7, POz)\n",
    "        (16, 17),  # (Oz, O2)\n",
    "        (16, 49),  # (Oz, PO8)\n",
    "        (16, 51),  # (Oz, P2)\n",
    "        (17, 49),  # (O2, PO8)\n",
    "        (17, 51),  # (O2, P2)\n",
    "        (18, 50),  # (P4, P6)\n",
    "        (19, 21),  # (P8, CP6)\n",
    "        (19, 54),  # (P8, TP8)\n",
    "        (21, 54),  # (CP6, TP8)\n",
    "        # REMOVE (27, 62) # (FC6, F2)\n",
    "        (49, 51),  # (PO8, P2)\n",
    "    ],\n",
    "}\n",
    "\n",
    "for subj_id in SUBJ_IDS:\n",
    "    print(subj_id)\n",
    "    t = subj_data[subj_id].preproc.times\n",
    "    # Find signal distances on raw data, on a smaller section of the data, ~4 minutes.\n",
    "    short_span = (\n",
    "        subj_data[subj_id]\n",
    "        .preproc.copy()\n",
    "        .crop(tmin=t.max() - ((4 * 60) + 20), tmax=t.max() - 20)\n",
    "    )\n",
    "    short_span.load_data()\n",
    "    # These parameters are *very* forgiving when it comes to overlooking potential\n",
    "    # bridges. Otherwise, a ton of the data would be thrown out in at least 2 subjects.\n",
    "    bridged_idx, ed_matrix = mne.preprocessing.compute_bridged_electrodes(\n",
    "        short_span, epoch_threshold=0.9, lm_cutoff=5.0, verbose=True\n",
    "    )\n",
    "\n",
    "    subj_data[subj_id].bridged_idx = bridged_idx\n",
    "    subj_data[subj_id].ed_matrix = ed_matrix\n",
    "    if subj_id in BRIDGE_OVERRIDE.keys():\n",
    "        print(\"******* Overriding bridged index for subj\", subj_id)\n",
    "        subj_data[subj_id].bridged_idx = BRIDGE_OVERRIDE[subj_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate virtual channels to fill in the bridged electrodes.\n",
    "for subj_id in SUBJ_IDS:\n",
    "    bridge_idx = subj_data[subj_id].bridged_idx\n",
    "    subj_data[subj_id].preproc = mne.preprocessing.interpolate_bridged_electrodes(\n",
    "        subj_data[subj_id].preproc, bridge_idx, bad_limit=(len(bridge_idx) * 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bridged connections for a subject.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "s = \"S002\"\n",
    "t = subj_data[s].preproc.times\n",
    "# short_span = (\n",
    "#     subj_data[s]\n",
    "#     .preproc.copy()\n",
    "#     .crop(tmin=t.max() - ((4 * 60) + 20), tmax=t.max() - 20)\n",
    "# )\n",
    "short_span = (\n",
    "    subj_data[s].raw.copy().crop(tmin=t.max() - ((4 * 60) + 20), tmax=t.max() - 20)\n",
    ")\n",
    "short_span.load_data()\n",
    "# These parameters are *very* forgiving when it comes to overlooking potential\n",
    "# bridges. Otherwise, a ton of the data would be thrown out in at least 2 subjects.\n",
    "bridged_idx, ed_matrix = mne.preprocessing.compute_bridged_electrodes(\n",
    "    short_span, epoch_threshold=0.9, lm_cutoff=5.0, verbose=True\n",
    ")\n",
    "\n",
    "# med_dist = np.nanquantile(ed_matrix, 0.9, axis=0)\n",
    "med_dist = np.nanmedian(ed_matrix, axis=0)\n",
    "im1 = ax1.imshow(med_dist, cmap=\"magma\")\n",
    "cax1 = fig.colorbar(im1, ax=ax1)\n",
    "cax1.set_label(r\"Electrical Distance ($\\mu$$V^2$)\")\n",
    "\n",
    "im2 = ax2.imshow(med_dist, cmap=\"magma\", vmax=5)\n",
    "cax2 = fig.colorbar(im2, ax=ax2)\n",
    "cax2.set_label(r\"Electrical Distance ($\\mu$$V^2$)\")\n",
    "plt.show()\n",
    "\n",
    "mne.viz.plot_bridged_electrodes(\n",
    "    # subj_data[s].preproc.info,\n",
    "    subj_data[s].raw.info,\n",
    "    bridged_idx,\n",
    "    ed_matrix,\n",
    "    topomap_args=dict(vlim=(None, 5)),\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "subset_raws = list()\n",
    "for pair_i, (br_j, br_k) in enumerate(bridged_idx):\n",
    "    # ch_j = subj_data[s].preproc.ch_names[br_j]\n",
    "    # ch_k = subj_data[s].preproc.ch_names[br_k]\n",
    "    ch_j = subj_data[s].raw.ch_names[br_j]\n",
    "    ch_k = subj_data[s].raw.ch_names[br_k]\n",
    "\n",
    "    print(f\"({ch_j}, {ch_k}) | ({br_j}, {br_k})\")\n",
    "    subset_raws.append(\n",
    "        subj_data[s]\n",
    "        .raw.copy()\n",
    "        .pick([ch_j, ch_k])\n",
    "        .rename_channels({ch_j: f\"{pair_i}_{ch_j}\", ch_k: f\"{pair_i}_{ch_k}\"})\n",
    "    )\n",
    "    # subset_raws.append(\n",
    "    #     subj_data[s]\n",
    "    #     .preproc.copy()\n",
    "    #     .pick([ch_j, ch_k])\n",
    "    #     .rename_channels({ch_j: f\"{pair_i}_{ch_j}\", ch_k: f\"{pair_i}_{ch_k}\"})\n",
    "    # )\n",
    "subset_raws[0].add_channels(subset_raws[1:]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EOG Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_COMPONENT_VARIANCE_SUM = 0.99\n",
    "# The number used during reconstruction will be:\n",
    "# the number of ICA components + (number of PCA components - number of ICA components)\n",
    "# with the latter term being the \"PCA residuals\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.preproc.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(dpi=120)\n",
    "for subj_id, data in subj_data.items():\n",
    "    # Fit ICA to original, raw data\n",
    "    # High-pass filter to remove potential slow drift.\n",
    "    raw = data.raw.load_data().copy()\n",
    "    if len(data.preproc.info[\"bads\"]) > 0:\n",
    "        raw.info[\"bads\"] = data.preproc.info[\"bads\"]\n",
    "    raw.set_eeg_reference(\"average\")\n",
    "    raw_filtered = raw.copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "    # Determine the number of PCA components from, roughly, the rank of the output\n",
    "    # according to the number of \"merged\" electrodes caused by bridged connections.\n",
    "    g = networkx.parse_edgelist(\n",
    "        [f\"{i[0]} {i[1]}\" for i in list(subj_data[subj_id].bridged_idx)]\n",
    "    )\n",
    "    n_cliques = len(list(networkx.find_cliques(g)))\n",
    "    n_bridges = len(subj_data[subj_id].bridged_idx)\n",
    "    n_channels = len(set(data.preproc.ch_names) - set(data.preproc.info[\"bads\"]))\n",
    "    rank = n_channels - n_bridges + n_cliques\n",
    "    subj_data[subj_id].rank = rank\n",
    "\n",
    "    # Calculate noise covariance matrix for pre-whitening.\n",
    "    break_events, break_event_ids = mne.events_from_annotations(\n",
    "        data.preproc, regexp=\"break\"\n",
    "    )\n",
    "    break_epochs = mne.Epochs(\n",
    "        raw,\n",
    "        break_events,\n",
    "        break_event_ids[\"break\"],\n",
    "        tmin=-MIN_BREAK_DURATION / 2,\n",
    "        tmax=MIN_BREAK_DURATION / 2,\n",
    "        baseline=(None, None),\n",
    "        preload=True,\n",
    "    )\n",
    "    noise_cov = mne.compute_covariance(\n",
    "        break_epochs, rank={\"eeg\": subj_data[subj_id].rank}, verbose=\"error\"\n",
    "    )\n",
    "\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=ICA_COMPONENT_VARIANCE_SUM,\n",
    "        noise_cov=noise_cov,\n",
    "        method=\"picard\",\n",
    "        max_iter=\"auto\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    ica = ica.fit(raw_filtered, verbose=True)\n",
    "\n",
    "    subj_data[subj_id].ica = ica\n",
    "\n",
    "    print(\n",
    "        f\"Subj {subj_id} ICA | iterations {ica.n_samples_}, components {ica.n_components_}\"\n",
    "    )\n",
    "    expl_var = ica.pca_explained_variance_ / ica.pca_explained_variance_.sum()\n",
    "    explained_var_cumsum = np.cumsum(expl_var)\n",
    "    plt.plot(\n",
    "        np.arange(explained_var_cumsum.shape[0]) + 1,\n",
    "        explained_var_cumsum,\n",
    "        label=subj_id,\n",
    "        marker=\".\",\n",
    "        alpha=0.7,\n",
    "        lw=2.0,\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Principle Component Index\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first N principle components, filter and process.\n",
    "# subj_preproc_data[\"S001\"]\n",
    "# subj_preproc_data[\"S002\"]\n",
    "# subj_preproc_data[\"S003\"]\n",
    "for subj_id, data in subj_data.items():\n",
    "    s = subj_data[subj_id].preproc.copy()\n",
    "    ica = subj_data[subj_id].ica.copy()\n",
    "    eog_artifact_exclude_idx, eog_artifact_scores = ica.find_bads_eog(\n",
    "        s, [\"Fp1\", \"Fp2\"], start=2.0, measure=\"zscore\", threshold=3.0, verbose=True\n",
    "    )\n",
    "    muscle_artifact_exclude_idx, muscle_artifact_scores = ica.find_bads_muscle(\n",
    "        s, threshold=0.65, l_freq=7, h_freq=45, start=2.0, verbose=True\n",
    "    )\n",
    "    print(\n",
    "        f\"EOG components: {eog_artifact_exclude_idx} | Muscle components: {muscle_artifact_exclude_idx}\"\n",
    "    )\n",
    "    ica.exclude = list(\n",
    "        set(ica.exclude)\n",
    "        | set(eog_artifact_exclude_idx)\n",
    "        | set(muscle_artifact_exclude_idx)\n",
    "    )\n",
    "\n",
    "    s = ica.apply(\n",
    "        s, n_pca_components=subj_data[subj_id].rank, on_baseline=\"raise\", verbose=True\n",
    "    )\n",
    "\n",
    "    # Set a reference channel\n",
    "    s.set_eeg_reference(\"average\")\n",
    "    # High-pass filter to remove DC offset.\n",
    "    s.filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "    if len(s.info[\"bads\"]) > 0:\n",
    "        s.interpolate_bads(reset_bads=True, mode=\"accurate\")\n",
    "\n",
    "    subj_data[subj_id].preproc = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling & Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj_id, data in subj_data.items():\n",
    "    s = data.preproc.copy()\n",
    "    pushbutton_events, pushbutton_event_ids = mne.events_from_annotations(\n",
    "        s, regexp=\"pushbutton\"\n",
    "    )\n",
    "    pushb_epochs = mne.Epochs(\n",
    "        s,\n",
    "        pushbutton_events,\n",
    "        pushbutton_event_ids,\n",
    "        tmin=-10.0,\n",
    "        tmax=1 / 5000,\n",
    "        baseline=(None, -4.0),\n",
    "        preload=True,\n",
    "    )\n",
    "    subj_data[subj_id].pushbutton_epochs = pushb_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to a desired frequency.\n",
    "# current_sample_freq = subj_preproc_data.S001.reduced_eeg.info[\"sfreq\"]\n",
    "current_sample_freq = 5000\n",
    "target_sample_freq = 250.0\n",
    "decim = np.round(current_sample_freq / target_sample_freq).astype(int)\n",
    "obtained_sample_freq = current_sample_freq / decim\n",
    "lowpass_freq = obtained_sample_freq / 3.0\n",
    "print(\n",
    "    current_sample_freq, target_sample_freq, decim, obtained_sample_freq, lowpass_freq\n",
    ")\n",
    "\n",
    "for subj_id, data in subj_data.items():\n",
    "    s = data.preproc.copy()\n",
    "    # Low-pass the cleaned data to 1/3 the target frequency. This rule-of-thumb is\n",
    "    # specifically selected for the default parameters in `Raw.filter()`.\n",
    "    s = s.filter(l_freq=None, h_freq=lowpass_freq)\n",
    "\n",
    "    # Re-create the epoching steps above\n",
    "    pushbutton_events, pushbutton_event_ids = mne.events_from_annotations(\n",
    "        s, regexp=\"pushbutton\"\n",
    "    )\n",
    "    pushb_epochs_decim = mne.Epochs(\n",
    "        s,\n",
    "        pushbutton_events,\n",
    "        pushbutton_event_ids,\n",
    "        decim=decim,\n",
    "        tmin=-10.0,\n",
    "        tmax=0.0,\n",
    "        baseline=(None, -5.0),\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    subj_data[subj_id].resampled_pushbutton_epochs = pushb_epochs_decim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windowing & Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "CHANNEL_ORDER = (\n",
    "    'Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3',\n",
    "    'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1',\n",
    "    'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz',\n",
    "    'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2',\n",
    "    'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'C1',\n",
    "    'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz',\n",
    "    'PO4', 'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6',\n",
    "    'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'Iz',\n",
    ")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOW_SPAN_TIME = 1.5 #seconds\n",
    "# window_span_timepoints = math.ceil(WINDOW_SPAN_TIME * target_sample_freq)\n",
    "# TARGET_BACKOFF_TIMEPOINTS = 1\n",
    "\n",
    "LOAD_CACHE_DATASET = False\n",
    "SAVE_CACHE_DATASET = True\n",
    "\n",
    "input_windows = Box(default_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_CACHE_DATASET:\n",
    "\n",
    "    input_windows.times = None\n",
    "\n",
    "    for subj_id, data in subj_data.items():\n",
    "        epochs = subj_data[subj_id].resampled_pushbutton_epochs.copy().load_data()\n",
    "        # Apply baseline correction.\n",
    "        epochs = epochs.apply_baseline()\n",
    "        # Channels should be in the correct order, but enforce a standard order just in\n",
    "        # case.\n",
    "        epochs = epochs.reorder_channels(list(CHANNEL_ORDER))\n",
    "\n",
    "        epoch_data = epochs.get_data(picks=\"eeg\", units=\"uV\").copy()\n",
    "\n",
    "        input_windows[subj_id] = epoch_data\n",
    "\n",
    "        if input_windows.times is None:\n",
    "            input_windows.times = epochs.times.copy()\n",
    "\n",
    "    if SAVE_CACHE_DATASET:\n",
    "        np.savez_compressed(\n",
    "            \"preproc_eeg_pushbutton_epochs.npz\", **input_windows.to_dict()\n",
    "        )\n",
    "else:\n",
    "    input_windows = Box(**np.load(\"preproc_eeg_pushbutton_epochs.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5000 / 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(input_windows.times, input_windows.S003[0].T, lw=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sandbox\n",
    "s = subj_data.S002.raw.load_data(verbose=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOG artifact correction\n",
    "s1 = s.copy()\n",
    "\n",
    "breaks = mne.preprocessing.annotate_break(\n",
    "    s1, min_break_duration=13, t_start_after_previous=3, t_stop_before_next=3\n",
    ")\n",
    "s1.annotations.append(\n",
    "    onset=breaks.onset, duration=breaks.duration, description=breaks.description\n",
    ")\n",
    "\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(\n",
    "    s1, ch_name=[\"Fp1\", \"Fp2\"], l_freq=1, h_freq=40\n",
    ")\n",
    "eog_evoked = eog_epochs.average().apply_baseline(baseline=(None, -0.2))\n",
    "\n",
    "# Visualization of average of eog events\n",
    "eog_evoked.plot_joint(\n",
    "    times=[-0.1, -0.01, 0.01, 0.1],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_events, break_event_ids = mne.events_from_annotations(s1, regexp=\"BAD_break\")\n",
    "break_epochs = mne.Epochs(\n",
    "    s1,\n",
    "    break_events,\n",
    "    break_event_ids[\"BAD_break\"],\n",
    "    reject_by_annotation=False,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ICA to data\n",
    "# High-pass filter to remove potential slow drift.\n",
    "s_filter = s.copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "ica = mne.preprocessing.ICA(n_components=15, method=\"picard\", max_iter=\"auto\")\n",
    "ica.fit(s_filter)\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(s, show_scrollbars=False)\n",
    "ica.plot_components();\n",
    "# ica.plot_overlay(s, exclude=[0, 1], picks='eeg');\n",
    "# ica.plot_properties(s, picks=[0, 1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find components on a second subject.\n",
    "# Fit ICA to data\n",
    "# High-pass filter to remove potential slow drift.\n",
    "s3_filter = subj_data.S003.raw.copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "ica_s3 = mne.preprocessing.ICA(n_components=15, method=\"picard\", max_iter=\"auto\")\n",
    "ica_s3.fit(s3_filter)\n",
    "ica_s3.plot_components();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_indices, eog_scores = ica.find_bads_eog(\n",
    "    s, [\"Fp1\", \"Fp2\"], threshold=0.7, measure=\"correlation\", l_freq=1.0, h_freq=100\n",
    ")\n",
    "print(eog_indices)\n",
    "print(eog_scores)\n",
    "# ica.exclude = eog_indices\n",
    "ica.exclude = [0, 1]\n",
    "\n",
    "ica.plot_scores(eog_scores)\n",
    "ica.plot_properties(s, picks=ica.exclude)\n",
    "ica.plot_sources(eog_evoked);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.find_bads_ecg(s, method=\"correlation\", threshold=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = subj_data.S002.raw.copy()\n",
    "breaks = mne.preprocessing.annotate_break(\n",
    "    s, min_break_duration=13, t_start_after_previous=3, t_stop_before_next=3\n",
    ")\n",
    "s.annotations.append(\n",
    "    onset=breaks.onset, duration=breaks.duration, description=breaks.description\n",
    ")\n",
    "\n",
    "pushbutton_events, pushbutton_event_ids = mne.events_from_annotations(\n",
    "    s, regexp=\"pushbutton\"\n",
    ")\n",
    "pushb_epochs = mne.Epochs(\n",
    "    s,\n",
    "    pushbutton_events,\n",
    "    pushbutton_event_ids,\n",
    "    tmin=-7.0,\n",
    "    tmax=0.5,\n",
    "    baseline=(None, -4.0),\n",
    "    preload=True,\n",
    ")\n",
    "pushb_evoked = pushb_epochs.apply_baseline().average()\n",
    "\n",
    "# Viz average pushbutton channel amplitudes.\n",
    "pushb_evoked.plot_joint(\n",
    "    times=[-6.0, -3.0, -1.0, -0.5, -0.1, -0.05, -0.01, 0.01],\n",
    ")\n",
    "pushb_evoked.plot(gfp=\"only\", spatial_colors=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushb_noise_cov = mne.compute_covariance(\n",
    "    pushb_epochs, tmax=0, method=\"shrunk\", rank=None, verbose=\"error\"\n",
    ")\n",
    "# pushb_epochs.plot(events=True)\n",
    "# pushb_epochs.plot(noise_cov=pushb_noise_cov, events=True);\n",
    "pushb_evoked.plot(time_unit=\"s\")\n",
    "pushb_evoked.plot(noise_cov=pushb_noise_cov, time_unit=\"s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average intensities per epoch for a second subject\n",
    "\n",
    "s3 = subj_data.S003.raw.copy()\n",
    "s3_breaks = mne.preprocessing.annotate_break(\n",
    "    s3, min_break_duration=13, t_start_after_previous=3, t_stop_before_next=3\n",
    ")\n",
    "s3.annotations.append(\n",
    "    onset=s3_breaks.onset,\n",
    "    duration=s3_breaks.duration,\n",
    "    description=s3_breaks.description,\n",
    ")\n",
    "\n",
    "s3_pushbutton_events, s3_pushbutton_event_ids = mne.events_from_annotations(\n",
    "    s3, regexp=\"pushbutton\"\n",
    ")\n",
    "s3_pushb_epochs = mne.Epochs(\n",
    "    s3,\n",
    "    s3_pushbutton_events,\n",
    "    s3_pushbutton_event_ids,\n",
    "    tmin=-7.0,\n",
    "    tmax=0.5,\n",
    "    baseline=(None, -4.0),\n",
    "    preload=True,\n",
    ")\n",
    "s3_pushb_evoked = s3_pushb_epochs.apply_baseline().average()\n",
    "\n",
    "# Viz average pushbutton channel amplitudes.\n",
    "s3_pushb_evoked.plot_joint(\n",
    "    times=[-6.0, -3.0, -1.0, -0.5, -0.1, -0.05, -0.01, 0.01],\n",
    ")\n",
    "s3_pushb_evoked.plot(gfp=\"only\", spatial_colors=True)\n",
    "\n",
    "s3_pushb_noise_cov = mne.compute_covariance(\n",
    "    s3_pushb_epochs, tmax=0, method=\"shrunk\", rank=None, verbose=\"error\"\n",
    ")\n",
    "# pushb_epochs.plot(events=True)\n",
    "# pushb_epochs.plot(noise_cov=pushb_noise_cov, events=True);\n",
    "s3_pushb_evoked.plot(time_unit=\"s\")\n",
    "s3_pushb_evoked.plot(noise_cov=s3_pushb_noise_cov, time_unit=\"s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.logspace(*np.log10([1, 50]), num=30)\n",
    "# freqs = np.linspace(1, 10, num=20)\n",
    "n_cycles = freqs / 2.0  # different number of cycle per frequency\n",
    "print(f\"Temporal windows {n_cycles / freqs} for frequencies {freqs}\")\n",
    "power, itc = mne.time_frequency.tfr_morlet(\n",
    "    pushb_epochs,\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    use_fft=True,\n",
    "    return_itc=True,\n",
    "    decim=2,\n",
    "    n_jobs=None,\n",
    ")\n",
    "power.plot_joint(\n",
    "    mode=\"mean\",\n",
    "    tmin=-7.0,\n",
    "    tmax=0.05,\n",
    "    baseline=(None, -4.0),\n",
    "    timefreqs=[(-2.99, 10), (-0.1, 9)],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-frequency plot on a second subject\n",
    "freqs = np.logspace(*np.log10([1, 100]), num=30)\n",
    "# freqs = np.linspace(1, 10, num=20)\n",
    "n_cycles = freqs / 10  # different number of cycle per frequency\n",
    "print(f\"Temporal windows {n_cycles / freqs} for frequencies {freqs}\")\n",
    "s3_power, s3_itc = mne.time_frequency.tfr_morlet(\n",
    "    s3_pushb_epochs,\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    use_fft=True,\n",
    "    return_itc=True,\n",
    "    decim=2,\n",
    "    n_jobs=None,\n",
    ")\n",
    "s3_power.plot_joint(\n",
    "    mode=\"mean\",\n",
    "    tmin=-5.0,\n",
    "    tmax=0.05,\n",
    "    baseline=(None, -4.0),\n",
    "    timefreqs=[(-2.99, 10), (-0.1, 9)],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz of breaks\n",
    "break_events, break_event_ids = mne.events_from_annotations(s, regexp=\"BAD_break\")\n",
    "break_epochs = mne.Epochs(\n",
    "    s,\n",
    "    break_events,\n",
    "    break_event_ids[\"BAD_break\"],\n",
    "    tmin=-3.75,\n",
    "    tmax=3.75,\n",
    "    baseline=(None, None),\n",
    "    reject_by_annotation=False,\n",
    "    preload=True,\n",
    ")\n",
    "break_evoked = break_epochs.apply_baseline().average()\n",
    "break_evoked.plot_joint(times=[-3, -2, -1, 0, 1, 2, 3]);\n",
    "\n",
    "#     s,\n",
    "#     pushbutton_events,\n",
    "#     pushbutton_event_ids,\n",
    "#     tmin=-7.0,\n",
    "#     tmax=0.5,\n",
    "#     baseline=(None, -4.0),\n",
    "#     preload=True,\n",
    "# )\n",
    "# pushb_evoked = pushb_epochs.apply_baseline().average()\n",
    "\n",
    "# # Viz average pushbutton channel amplitudes.\n",
    "# pushb_evoked.plot_joint(\n",
    "#     times=[-6.0, -3.0, -1.0, -0.5, -0.1, -0.05, -0.01, 0.01],\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushb_evoked\n",
    "# break_evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
