{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spline Baseline\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "* `R. Tanno et al., “Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,” NeuroImage, vol. 225, p. 117366, Jan. 2021, doi: 10.1016/j.neuroimage.2020.117366.`\n",
    "* `D. C. Alexander et al., “Image quality transfer and applications in diffusion MRI,” NeuroImage, vol. 152, pp. 283–298, May 2017, doi: 10.1016/j.neuroimage.2017.02.089.`\n",
    "* `S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import einops\n",
    "import torchinfo\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    if \"CUDA_PYTORCH_DEVICE_IDX\" in os.environ.keys():\n",
    "        dev_idx = int(os.environ[\"CUDA_PYTORCH_DEVICE_IDX\"])\n",
    "    else:\n",
    "        dev_idx = 0\n",
    "    device = torch.device(f\"cuda:{dev_idx}\")\n",
    "    print(\"CUDA Device IDX \", dev_idx)\n",
    "    torch.cuda.set_device(device)\n",
    "    print(\"CUDA Current Device \", torch.cuda.current_device())\n",
    "    print(\"CUDA Device properties: \", torch.cuda.get_device_properties(device))\n",
    "\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2022-03-27T05:51:35.597651+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-100-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: d8162cca518d2e6c2f05523feb712a52b5ea3f05\n",
      "\n",
      "seaborn          : 0.11.1\n",
      "torch            : 1.10.2\n",
      "pytorch_lightning: 1.5.10\n",
      "scipy            : 1.5.3\n",
      "natsort          : 7.1.1\n",
      "einops           : 0.3.0\n",
      "nibabel          : 3.2.1\n",
      "dipy             : 1.4.1\n",
      "box              : 5.4.1\n",
      "torchio          : 0.18.30\n",
      "json             : 2.0.9\n",
      "matplotlib       : 3.4.1\n",
      "sys              : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "monai            : 0.8.0\n",
      "ipywidgets       : 7.6.3\n",
      "pitn             : 0.0.post1.dev132+g02c0d1a\n",
      "torchinfo        : 1.6.2\n",
      "pandas           : 1.2.3\n",
      "skimage          : 0.18.1\n",
      "numpy            : 1.20.2\n",
      "\n",
      "==================================================GPU Specs==================================================\n",
      "  id  Name              Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ----------------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  NVIDIA TITAN RTX  470.103.01                  11.3  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Reading & Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Here are all the parameters! This makes it easy to find them! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "###############################################\n",
    "params.experiment_name = \"test_spline\"\n",
    "params.override_experiment_name = False\n",
    "###############################################\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 48\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "params.use_anat = False\n",
    "params.use_half_precision_float = False\n",
    "params.num_workers = 8\n",
    "params.use_log_euclid = True\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "\n",
    "params.data.eigval_clip_cutoff = 0.00332008\n",
    "\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    if \"PITN_CONFIG\" in os.environ.keys():\n",
    "        config_fname = Path(os.environ[\"PITN_CONFIG\"])\n",
    "    else:\n",
    "        config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\".yaml\", \".yml\"}:\n",
    "        f_params = Box.from_yaml(filename=config_fname)\n",
    "    elif f_type == \".json\":\n",
    "        f_params = Box.from_json(filename=config_fname)\n",
    "    elif f_type == \".toml\":\n",
    "        f_params = Box.from_toml(filename=config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    print(\"WARNING: Config file not loaded\")\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = params.experiment_name\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "if not params.override_experiment_name:\n",
    "    experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "else:\n",
    "    experiment_name = EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "# Only grab directories that are timestamped starting with a year.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"[0-9][0-9][0-9][0-9]*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 5\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-27T05_51_39__test_spline\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # Parameters.\n",
    "    f.write(pprint.pformat(params.to_dict()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100408': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-100408'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-100408')},\n",
      " '103010': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-103010'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-103010')},\n",
      " '103515': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-103515'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-103515')},\n",
      " '108828': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-108828'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-108828')},\n",
      " '118124': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-118124'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-118124')},\n",
      " '118730': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-118730'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-118730')},\n",
      " '124220': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-124220'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-124220')},\n",
      " '135528': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-135528'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-135528')},\n",
      " '140117': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-140117'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-140117')},\n",
      " '141422': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-141422'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-141422')},\n",
      " '150019': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-150019'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-150019')},\n",
      " '156637': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-156637'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-156637')},\n",
      " '157437': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-157437'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-157437')},\n",
      " '164030': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-164030'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-164030')},\n",
      " '167238': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-167238'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-167238')},\n",
      " '175035': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-175035'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-175035')},\n",
      " '185947': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-185947'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-185947')},\n",
      " '189450': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-189450'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-189450')},\n",
      " '196952': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-196952'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-196952')},\n",
      " '198047': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-198047'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-198047')},\n",
      " '203923': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-203923'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-203923')},\n",
      " '224022': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-224022'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-224022')},\n",
      " '227432': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-227432'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-227432')},\n",
      " '231928': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-231928'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-231928')},\n",
      " '297655': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-297655'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-297655')},\n",
      " '303624': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-303624'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-303624')},\n",
      " '307127': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-307127'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-307127')},\n",
      " '382242': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-382242'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-382242')},\n",
      " '386250': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-386250'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-386250')},\n",
      " '397154': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-397154'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-397154')},\n",
      " '406432': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-406432'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-406432')},\n",
      " '567759': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-567759'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-567759')},\n",
      " '567961': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-567961'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-567961')},\n",
      " '634748': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-634748'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-634748')},\n",
      " '644246': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-644246'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-644246')},\n",
      " '679770': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-679770'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-679770')},\n",
      " '690152': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-690152'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-690152')},\n",
      " '700634': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-700634'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-700634')},\n",
      " '701535': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-701535'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-701535')},\n",
      " '751348': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-751348'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-751348')},\n",
      " '753251': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-753251'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-753251')},\n",
      " '792867': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-792867'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-792867')},\n",
      " '803240': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-803240'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-803240')},\n",
      " '810439': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-810439'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-810439')},\n",
      " '815247': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-815247'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-815247')},\n",
      " '894774': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-894774'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-894774')},\n",
      " '910241': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-910241'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-910241')},\n",
      " '978578': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-978578'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-978578')}}\n"
     ]
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "    \"406432\",\n",
    "    \"803240\",\n",
    "    \"815247\",\n",
    "    \"167238\",\n",
    "    \"100408\",\n",
    "    \"792867\",\n",
    "    \"157437\",\n",
    "    \"164030\",\n",
    "    \"103515\",\n",
    "    \"118730\",\n",
    "    \"198047\",\n",
    "    \"189450\",\n",
    "    \"203923\",\n",
    "    \"108828\",\n",
    "    \"124220\",\n",
    "    \"386250\",\n",
    "    \"118124\",\n",
    "    \"701535\",\n",
    "    \"679770\",\n",
    "    \"382242\",\n",
    "    \"231928\",\n",
    "    \"196952\",  # Hold-out subject; for visualization, ensure never in the train or val sets\n",
    "    \"567961\",\n",
    "    \"910241\",\n",
    "    \"175035\",\n",
    "    \"567759\",\n",
    "    \"978578\",\n",
    "    \"150019\",\n",
    "    \"690152\",\n",
    "    \"297655\",\n",
    "    \"307127\",\n",
    "    \"634748\",\n",
    "]\n",
    "HOLDOUT_SUBJ_ID = \"196952\"\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=(11, 11, 11),\n",
    "    )\n",
    "}\n",
    "fr2lr_patch_coords_fn[\"lr_log_euclid\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "fr2lr_patch_coords_fn[\"lr_mask\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(np.asarray((11, 11, 11)) * params.data.downsampled_by_factor).astype(\n",
    "            int\n",
    "        )\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"log_euclid\", \"mask\"},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "# Coefficients to the log-euclidean lower triangle/6D vector that properly scales\n",
    "# the Euclidean distance under the log-euclidean metrics.\n",
    "mat_norm_coeffs = torch.ones(6)\n",
    "mat_norm_coeffs[torch.as_tensor([1, 3, 4])] = np.sqrt(2)\n",
    "mat_norm_coeffs = mat_norm_coeffs.reshape(-1, 1, 1, 1)\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "        data = dict()\n",
    "        data[\"subj_id\"] = subj_id\n",
    "        fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "        lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "        data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "        data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "        ####### Low-resolution DTIs/volumes\n",
    "        lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            lr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(lr_dti_f)\n",
    "        lr_dti, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        lr_dti = torch.from_numpy(lr_dti)\n",
    "        lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "        data[\"lr_dti\"] = lr_dti\n",
    "        data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "        # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "        lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "        target_fr_shape = np.floor(\n",
    "            lr_dti_shape * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "\n",
    "        ####### Full-resolution images/volumes.\n",
    "        # DTI.\n",
    "        dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(dti_f)\n",
    "        dti, meta = nib_reader.get_data(im)\n",
    "        dti = torch.from_numpy(dti)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            dti, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "        data[\"dti\"] = dti\n",
    "        data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "        # Diffusion mask.\n",
    "        mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.mask_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(mask_f)\n",
    "        mask, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        mask = torch.from_numpy(mask)\n",
    "        # Add channel dim if not available.\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[None]\n",
    "        mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            mask, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "        mask = mask.bool()\n",
    "        data[\"mask\"] = mask\n",
    "        data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "        # Consider this as the \"noise correction\" step to have more informative, consistent\n",
    "        # results with minimal biasing. Otherwise, outliers (which are clearly errors) can\n",
    "        # change loss and performance metrics by orders of magnitude for no good reason!\n",
    "        if \"eigval_clip_cutoff\" in params.data and params.data.eigval_clip_cutoff:\n",
    "            correct_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"dti\"])\n",
    "            correct_dti = correct_dti * data[\"mask\"]\n",
    "            ####\n",
    "            sae_fr = (\n",
    "                F.l1_loss(data[\"dti\"], correct_dti, reduction=\"none\") * data[\"mask\"]\n",
    "            )\n",
    "            sae_fr = sae_fr.view(6, -1).sum(1)\n",
    "            mae_fr = sae_fr / torch.count_nonzero(data[\"mask\"])\n",
    "            print(f\"---Subj {subj_id}---\")\n",
    "            print(\n",
    "                \"MAE of FR DTI after eigenvalue clipping:\\n\",\n",
    "                mae_fr.tolist(),\n",
    "            )\n",
    "            ####\n",
    "            data[\"dti\"] = correct_dti\n",
    "\n",
    "            correct_lr_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"lr_dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"lr_dti\"])\n",
    "            lr_mask = (data[\"lr_dti\"] != 0).max(0, keepdim=True).values\n",
    "            correct_lr_dti = correct_lr_dti * lr_mask\n",
    "            ####\n",
    "            sae_lr = (\n",
    "                F.l1_loss(data[\"lr_dti\"], correct_lr_dti, reduction=\"none\") * lr_mask\n",
    "            )\n",
    "            sae_lr = sae_lr.view(6, -1).sum(1)\n",
    "            mae_lr = sae_lr / torch.count_nonzero(lr_mask)\n",
    "            print(\n",
    "                \"MAE of LR DTI after eigenvalue clipping:\\n\",\n",
    "                mae_lr.tolist(),\n",
    "            )\n",
    "            ####\n",
    "            data[\"lr_dti\"] = correct_lr_dti\n",
    "\n",
    "        ####### Log-euclid pre-computed volumes\n",
    "        # Construct a quick and cheap mask for the LR DTI\n",
    "        cheap_lr_mask = F.interpolate(\n",
    "            data[\"mask\"][None].float(),\n",
    "            size=data[\"lr_dti\"][0].shape,\n",
    "            mode=\"nearest\",\n",
    "        )[0]\n",
    "        data[\"lr_mask\"] = cheap_lr_mask.bool()\n",
    "\n",
    "        # LR log-euclid volume.\n",
    "        lr_log_euclid = pitn.eig.tril_vec2sym_mat(data[\"lr_dti\"], tril_dim=0)\n",
    "        lr_log_euclid = pitn.riemann.log_euclid.log_map(lr_log_euclid)\n",
    "        lr_log_euclid = pitn.eig.sym_mat2tril_vec(lr_log_euclid, tril_dim=0)\n",
    "        lr_log_euclid = lr_log_euclid * mat_norm_coeffs\n",
    "        data[\"lr_log_euclid\"] = lr_log_euclid\n",
    "\n",
    "        log_euclid = pitn.eig.tril_vec2sym_mat(data[\"dti\"], tril_dim=0)\n",
    "        log_euclid = pitn.riemann.log_euclid.log_map(log_euclid)\n",
    "        log_euclid = pitn.eig.sym_mat2tril_vec(log_euclid, tril_dim=0)\n",
    "        log_euclid = log_euclid * mat_norm_coeffs\n",
    "        data[\"log_euclid\"] = log_euclid\n",
    "\n",
    "        ######## Normalized Subj Volumes\n",
    "        fr_means = (\n",
    "            torch.masked_select(data[\"dti\"], data[\"mask\"])\n",
    "            .view(6, -1)\n",
    "            .mean(1)\n",
    "            .reshape(6, 1, 1, 1)\n",
    "        )\n",
    "        fr_stds = torch.std(\n",
    "            torch.masked_select(data[\"dti\"], data[\"mask\"]).view(6, -1), 1\n",
    "        ).reshape(6, 1, 1, 1)\n",
    "        lr_means = (\n",
    "            torch.masked_select(data[\"lr_dti\"], data[\"lr_mask\"])\n",
    "            .view(6, -1)\n",
    "            .mean(1)\n",
    "            .reshape(6, 1, 1, 1)\n",
    "        )\n",
    "        lr_stds = torch.std(\n",
    "            torch.masked_select(data[\"lr_dti\"], data[\"lr_mask\"]).view(6, -1), 1\n",
    "        ).reshape(6, 1, 1, 1)\n",
    "\n",
    "        data[\"dti_means\"] = fr_means\n",
    "        data[\"dti_stds\"] = fr_stds\n",
    "        data[\"lr_dti_means\"] = lr_means\n",
    "        data[\"lr_dti_stds\"] = lr_stds\n",
    "\n",
    "        vol_names = {\n",
    "            \"dti\",\n",
    "            \"mask\",\n",
    "            \"lr_dti\",\n",
    "            \"lr_mask\",\n",
    "            \"log_euclid\",\n",
    "            \"lr_log_euclid\",\n",
    "        }\n",
    "        metadata_names = set(data.keys()) - vol_names\n",
    "        vol_d = {k: data[k] for k in vol_names}\n",
    "        meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "        # Create multi-volume dataset for this subj-session.\n",
    "        subj_dataset = pitn.data.SubjSesDataset(\n",
    "            vol_d,\n",
    "            primary_vol_name=\"dti\",\n",
    "            special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "            transform=None,\n",
    "            primary_patch_kwargs=patch_kwargs,\n",
    "            **meta_d,\n",
    "        )\n",
    "\n",
    "        # Finalize this subject.\n",
    "        subj_data[subj_id] = subj_dataset\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Aggregate Statistics for Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_data)\n",
    "num_test_subjs = int(params.n_subjs)\n",
    "num_val_subjs = 0\n",
    "num_train_subjs = 0\n",
    "\n",
    "subj_list = list(subj_data.keys())\n",
    "\n",
    "test_subjs = subj_list[:num_test_subjs]\n",
    "val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "# print(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\")\n",
    "# print(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\")\n",
    "# print(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\")\n",
    "# with open(log_txt_file, \"a+\") as f:\n",
    "#     f.write(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\\n\")\n",
    "#     f.write(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\\n\")\n",
    "#     f.write(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\\n\")\n",
    "\n",
    "# logger.add_text(\"train_subjs\", str(train_subjs))\n",
    "# logger.add_text(\"val_subjs\", str(val_subjs))\n",
    "# logger.add_text(\"test_subjs\", str(test_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders for test, validation, and training steps.\n",
    "sample_kws = {\n",
    "    \"subj_id\": \"subj_id\",\n",
    "    \"dti\": \"dti\",\n",
    "    \"lr_dti\": \"lr_dti\",\n",
    "    \"mask\": \"mask\",\n",
    "    \"lr_mask\": \"lr_mask\",\n",
    "    \"log_euclid\": \"log_euclid\",\n",
    "    \"lr_log_euclid\": \"lr_log_euclid\",\n",
    "}\n",
    "\n",
    "# Test & Validation\n",
    "# Only need raw DTIs for testing and validation, not training.\n",
    "tv_sample_kws = sample_kws\n",
    "test_val_collate_fn = functools.partial(pitn.samplers.collate_dicts, **tv_sample_kws)\n",
    "\n",
    "test_ds = list()\n",
    "for subj_id in test_subjs:\n",
    "    test_ds.append(subj_data[subj_id])\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_ds)\n",
    "test_loader = monai.data.DataLoader(\n",
    "    test_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Aggregate Statistics for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only choose subjects in the training and validation datasets.\n",
    "\n",
    "subj_agg_stats = Box(default_box=True)\n",
    "subj_agg_stats.dti.min = torch.zeros(params.n_channels).to(\n",
    "    list(subj_data.values())[0][0][\"dti\"]\n",
    ")\n",
    "subj_agg_stats.dti.max = torch.zeros(params.n_channels).to(subj_agg_stats.dti.min)\n",
    "\n",
    "subj_agg_stats.log_euclid.min = subj_agg_stats.dti.min\n",
    "subj_agg_stats.log_euclid.max = subj_agg_stats.dti.max\n",
    "\n",
    "for subj_id in set(test_subjs):\n",
    "    s = subj_data[subj_id]\n",
    "    fr_mask = s[0][\"mask\"]\n",
    "    dti = torch.masked_select(s[0][\"dti\"], fr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "    lr_dti = s[0][\"lr_dti\"]\n",
    "    lr_mask = (lr_dti == 0).all(0)[\n",
    "        None,\n",
    "    ]\n",
    "    lr_dti = torch.masked_select(lr_dti, lr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, lr_dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, lr_dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "    log_euclid = torch.masked_select(s[0][\"log_euclid\"], fr_mask).view(\n",
    "        params.n_channels, -1\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.min = torch.minimum(\n",
    "        subj_agg_stats.log_euclid.min,\n",
    "        log_euclid.view(params.n_channels, -1).min(-1).values,\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.max = torch.maximum(\n",
    "        subj_agg_stats.log_euclid.max,\n",
    "        log_euclid.view(params.n_channels, -1).max(-1).values,\n",
    "    )\n",
    "    lr_log_euclid = torch.masked_select(s[0][\"lr_log_euclid\"], lr_mask).view(\n",
    "        params.n_channels, -1\n",
    "    )\n",
    "    # lr_log_euclid = s[0][\"lr_log_euclid\"][lr_mask]\n",
    "    subj_agg_stats.log_euclid.min = torch.minimum(\n",
    "        subj_agg_stats.log_euclid.min,\n",
    "        lr_log_euclid.view(params.n_channels, -1).min(-1).values,\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.max = torch.maximum(\n",
    "        subj_agg_stats.log_euclid.max,\n",
    "        lr_log_euclid.view(params.n_channels, -1).max(-1).values,\n",
    "    )\n",
    "\n",
    "print(subj_agg_stats.dti.min)\n",
    "print(subj_agg_stats.dti.max)\n",
    "print(subj_agg_stats.log_euclid.min)\n",
    "print(subj_agg_stats.log_euclid.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_scalers = dict()\n",
    "\n",
    "expander = functools.partial(einops.rearrange, pattern=\"c -> 1 c 1 1 1\")\n",
    "# Collect DTI global data features.\n",
    "\n",
    "feat_min: torch.Tensor\n",
    "feat_max: torch.Tensor\n",
    "dti_min = expander(subj_agg_stats.dti.min)\n",
    "dti_max = expander(subj_agg_stats.dti.max)\n",
    "\n",
    "\n",
    "feat_min, feat_max = torch.as_tensor(\n",
    "    [\n",
    "        [0] * 6,\n",
    "        [1] * 6,\n",
    "    ]\n",
    ")\n",
    "print(\"PSNR will be scaled to \", feat_min, feat_max)\n",
    "feat_min = expander(feat_min)\n",
    "feat_max = expander(feat_max)\n",
    "\n",
    "net_scalers[\"input_scaler\"] = lambda o: o\n",
    "net_scalers[\"output_descaler\"] = lambda o: o\n",
    "\n",
    "# PSNR is calculated on the final output tensor components, so no log-euclidean or\n",
    "# scaling will occur here.\n",
    "psnr_range_params = pitn.data.norm.GlobalScaleParams(\n",
    "    feature_min=feat_min, feature_max=feat_max, data_min=dti_min, data_max=dti_max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DIQTESPCNSystem(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        upscale_factor: int,\n",
    "        psnr_range_params: pitn.data.norm.GlobalScaleParams,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = channels\n",
    "        self._upscale_factor = upscale_factor\n",
    "        self._psnr_range_params = psnr_range_params\n",
    "        # Coefficients to the log-euclidean lower triangle/6D vector that properly scales\n",
    "        # the Euclidean distance under the log-euclidean metrics.\n",
    "        self.mat_norm_coeffs = torch.ones(6).float()\n",
    "        self.mat_norm_coeffs[torch.as_tensor([1, 3, 4])] = np.sqrt(2)\n",
    "        self.mat_norm_coeffs = mat_norm_coeffs.reshape(-1, 1, 1, 1)\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Box(\n",
    "            {\n",
    "                \"test_loss\": {\n",
    "                    \"rmse\": dict(),\n",
    "                    \"nrmse\": dict(),\n",
    "                    \"rmse_log_euclid\": dict(),\n",
    "                    \"nrmse_log_euclid\": dict(),\n",
    "                    \"scaled_psnr\": dict(),\n",
    "                    \"ssim_fa\": dict(),\n",
    "                    \"rmse_fa\": dict(),\n",
    "                    \"nrmse_fa\": dict(),\n",
    "                },\n",
    "                \"viz\": {\n",
    "                    \"test_preds_dti\": dict(),\n",
    "                    \"test_preds_le\": dict(),\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return None\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return None\n",
    "\n",
    "    def pred_spline(self, x, order=3):\n",
    "        x_np = x.detach().cpu().numpy()\n",
    "        ys = list()\n",
    "        for b in x_np:\n",
    "            y_b = scipy.ndimage.zoom(\n",
    "                b,\n",
    "                zoom=(\n",
    "                    1,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                    self._upscale_factor,\n",
    "                ),\n",
    "                order=order,\n",
    "            )\n",
    "\n",
    "            ys.append(torch.from_numpy(y_b))\n",
    "\n",
    "        y = torch.stack(ys, dim=0)\n",
    "        y = y.to(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def on_test_start(self):\n",
    "        # Initialize the metrics as hyperparams so they appear under the tensorboard\n",
    "        # hparams tab. From:\n",
    "        # <https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging-hyperparameters>\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/rmse\": 0,\n",
    "                \"hp/nrmse\": 0,\n",
    "                \"hp/scaled_psnr\": 0,\n",
    "                \"hp/ssim_fa\": 0,\n",
    "                \"hp/rmse_log_euclid\": 0,\n",
    "                \"hp/nrmse_log_euclid\": 0,\n",
    "                \"hp/rmse_fa\": 0,\n",
    "                \"hp/nrmsa_fa\": 0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        # Assume batch size of 1 for the validation set.\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti.float()\n",
    "        log_euclid_x = batch.lr_log_euclid.float()\n",
    "        y = batch.dti.float()\n",
    "        y_cropped = y\n",
    "        log_euclid_y = batch.log_euclid\n",
    "        log_euclid_y_cropped = log_euclid_y\n",
    "\n",
    "        lr_mask = batch.lr_mask.bool()\n",
    "        mask = batch.mask.bool()\n",
    "        mask_cropped = mask\n",
    "        lr_mask = batch.lr_mask.bool()\n",
    "\n",
    "        ### Network predictions\n",
    "        y_pred = self.pred_spline(x)\n",
    "\n",
    "        # If the network operates in euclidian space natively, then take the original\n",
    "        # prediction and log map it.\n",
    "        log_euclid_y_pred = self.pred_spline(log_euclid_x)\n",
    "\n",
    "        output_select_shape = tuple(\n",
    "            torch.masked_select(y_pred, mask_cropped)\n",
    "            .view(y_pred.shape[0], y_pred.shape[1], -1)\n",
    "            .shape\n",
    "        )\n",
    "        # Mask select the target and prediction(s)\n",
    "        y_cropped_select = torch.masked_select(y_cropped, mask_cropped).view(\n",
    "            *output_select_shape\n",
    "        )\n",
    "\n",
    "        y_pred_select = torch.masked_select(y_pred, mask_cropped).view(\n",
    "            *output_select_shape\n",
    "        )\n",
    "\n",
    "        ###### Calculate network performance metrics.\n",
    "        # MSE metrics.\n",
    "        rmse_loss = pitn.nn.loss.dti_root_vec_fro_norm_loss(\n",
    "            y_pred, y_cropped, mask=mask_cropped, scale_off_diags=True, reduction=\"mean\"\n",
    "        )\n",
    "        nrmse_loss = pitn.metrics.minmax_normalized_dti_root_vec_fro_norm(\n",
    "            y_pred,\n",
    "            y_cropped,\n",
    "            mask=mask_cropped,\n",
    "            scale_off_diags=True,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        rmse_log_euclid_loss = pitn.nn.loss.dti_root_vec_fro_norm_loss(\n",
    "            log_euclid_y_pred,\n",
    "            log_euclid_y_cropped,\n",
    "            mask=mask_cropped,\n",
    "            scale_off_diags=False,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        nrmse_log_euclid_loss = pitn.metrics.minmax_normalized_dti_root_vec_fro_norm(\n",
    "            log_euclid_y_pred,\n",
    "            log_euclid_y_cropped,\n",
    "            mask=mask_cropped,\n",
    "            scale_off_diags=False,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # Need to reshape the mins and maxes to play nice with the mask-selected tensors.\n",
    "        min_shape_pre = tuple(self._psnr_range_params.data_min.shape[:2])\n",
    "        max_shape_pre = tuple(self._psnr_range_params.data_max.shape[:2])\n",
    "        scaled_psnr_loss = pitn.metrics.psnr_batch_channel_regularized(\n",
    "            y_pred_select,\n",
    "            y_cropped_select,\n",
    "            range_min=self._psnr_range_params.data_min.view(*min_shape_pre, -1),\n",
    "            range_max=self._psnr_range_params.data_max.view(*max_shape_pre, -1),\n",
    "        )\n",
    "\n",
    "        #### FA metrics\n",
    "        y_cropped_fa = pitn.metrics.fast_fa(y_cropped, foreground_mask=mask_cropped)\n",
    "        y_pred_fa = pitn.metrics.fast_fa(y_pred, foreground_mask=mask_cropped)\n",
    "        y_cropped_fa_select = torch.masked_select(y_cropped_fa, mask_cropped).view(\n",
    "            y_cropped_fa.shape[0], y_cropped_fa.shape[1], -1\n",
    "        )\n",
    "        y_pred_fa_select = torch.masked_select(y_pred_fa, mask_cropped).view(\n",
    "            y_pred_fa.shape[0], y_pred_fa.shape[1], -1\n",
    "        )\n",
    "\n",
    "        ssim_fa_loss = pitn.metrics.ssim_y_range(\n",
    "            y_pred_fa,\n",
    "            y_cropped_fa,\n",
    "        )\n",
    "        rmse_fa_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                y_pred_fa_select,\n",
    "                y_cropped_fa_select,\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        nrmse_fa_loss = pitn.metrics.minmax_normalized_rmse(\n",
    "            y_pred_fa_select,\n",
    "            y_cropped_fa_select,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # on_epoch and reduce_fx gather the individual test epoch values and aggregate\n",
    "        # them at the end of the testing epoch.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"test_loss/rmse\": rmse_loss,\n",
    "                \"test_loss/nrmse\": nrmse_loss,\n",
    "                \"test_loss/nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "                \"test_loss/rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "                \"test_loss/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"test_loss/ssim_fa\": ssim_fa_loss,\n",
    "                \"test_loss/rmse_fa\": rmse_fa_loss,\n",
    "                \"test_loss/nrmse_fa\": nrmse_fa_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        # Log loss as an hparam metric to be shown alongside the experiment's hparams.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"hp/rmse\": rmse_loss,\n",
    "                \"hp/nrmse\": nrmse_loss,\n",
    "                \"hp/nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "                \"hp/rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "                \"hp/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"hp/ssim_fa\": ssim_fa_loss,\n",
    "                \"hp/rmse_fa\": rmse_fa_loss,\n",
    "                \"hp/nrmse_fa\": nrmse_fa_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        self.plain_log.test_loss.rmse[subj_id] = rmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.nrmse[subj_id] = nrmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.rmse_log_euclid[subj_id] = (\n",
    "            rmse_log_euclid_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.nrmse_log_euclid[subj_id] = (\n",
    "            nrmse_log_euclid_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.scaled_psnr[subj_id] = (\n",
    "            scaled_psnr_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.ssim_fa[subj_id] = ssim_fa_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.rmse_fa[subj_id] = rmse_fa_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.nrmse_fa[subj_id] = nrmse_fa_loss.detach().cpu().item()\n",
    "\n",
    "        # Store entire predicted DTI for saving & visualization.\n",
    "        self.plain_log.viz.test_preds_dti[subj_id] = y_pred[0].detach().cpu()\n",
    "        self.plain_log.viz.test_preds_le[subj_id] = log_euclid_y_pred[0].detach().cpu()\n",
    "\n",
    "        return {\n",
    "            \"rmse\": rmse_loss,\n",
    "            \"nrmse\": nrmse_loss,\n",
    "            \"nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "            \"rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "            \"scaled_psnr\": scaled_psnr_loss,\n",
    "            \"ssim_fa\": ssim_fa_loss,\n",
    "            \"rmse_fa\": rmse_fa_loss,\n",
    "            \"nrmse_fa\": nrmse_fa_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    channels=params.n_channels,\n",
    "    upscale_factor=params.data.downsampled_by_factor,\n",
    "    psnr_range_params=psnr_range_params,\n",
    ")\n",
    "\n",
    "# Create model from given kwargs.\n",
    "model = DIQTESPCNSystem(**model_kwargs)\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    # fast_dev_run=12,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_checkpointing=False,\n",
    "    logger=pl_logger,\n",
    ")\n",
    "\n",
    "# # Many warnings are produced here, so it's better for my sanity (i.e., worse in every other\n",
    "# # way) to just filter and ignore them...\n",
    "# # with warnings.catch_warnings():\n",
    "# #     warnings.simplefilter(\"ignore\")\n",
    "# try:\n",
    "#     trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "# except RuntimeError as e:\n",
    "#     with open(log_txt_file, \"a+\") as f:\n",
    "#         f.write(\"\\n\")\n",
    "#         f.write(\"!!!!! Fatal ERROR !!!!!!!\\n\")\n",
    "#         f.write(\"Traceback:\\n\")\n",
    "#         f.write(str(e) + \"\\n\")\n",
    "#         f.write(\"!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "#         raise e\n",
    "\n",
    "# train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "# print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save out trained model\n",
    "# trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), experiment_results_dir / \"model_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(log_txt_file, \"a+\") as f:\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write(f\"Training time: {train_duration}\\n\")\n",
    "#     f.write(\n",
    "#         f\"\\t{train_duration.days} Days, \"\n",
    "#         + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "#         + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "#         + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot rolling average window of training loss values.\n",
    "# plt.figure(dpi=110)\n",
    "# window = 1000\n",
    "# rolling_mean = (\n",
    "#     np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    "# )\n",
    "# rolling_start = 100\n",
    "# plt.plot(\n",
    "#     np.arange(\n",
    "#         window + rolling_start,\n",
    "#         window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "#     ),\n",
    "#     rolling_mean[rolling_start:],\n",
    "# )\n",
    "# plt.title(\"Training Loss \" + params.train.loss_name + f\"\\nRolling Mean {window}\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# # plt.ylim(0, 1)\n",
    "# print(np.median(rolling_mean))\n",
    "# print(\n",
    "#     np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "#     np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "#     np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "# )\n",
    "\n",
    "# plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_state = model.state_dict()\n",
    "\n",
    "# test_mod = DIQTCascadeSystem(\n",
    "#     channels=params.n_channels,\n",
    "#     batch_size=params.train.batch_size,\n",
    "#     in_patch_shape=params.train.in_patch_size,\n",
    "#     upscale_factor=params.net.upscale_factor,\n",
    "#     anat_batch_key=params.data.anat_type,\n",
    "#     train_loss_method=params.train.loss_name,\n",
    "#     opt_params=params.optim.kwargs,\n",
    "#     hparams=hyperparams,\n",
    "#     **params.net.kwargs,\n",
    "# )\n",
    "# test_mod.load_state_dict(mod_state)\n",
    "# trainer.test(test_mod, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_losses = (\n",
    "    \"rmse\",\n",
    "    \"nrmse\",\n",
    "    \"rmse_log_euclid\",\n",
    "    \"nrmse_log_euclid\",\n",
    "    \"scaled_psnr\",\n",
    "    \"ssim_fa\",\n",
    "    \"rmse_fa\",\n",
    "    \"nrmse_fa\",\n",
    ")\n",
    "loss_comparison_directions = {\n",
    "    \"rmse\": \"↓\",\n",
    "    \"nrmse\": \"↓\",\n",
    "    \"rmse_log_euclid\": \"↓\",\n",
    "    \"nrmse_log_euclid\": \"↓\",\n",
    "    \"scaled_psnr\": \"↑\",\n",
    "    \"ssim_fa\": \"↑\",\n",
    "    \"rmse_fa\": \"↓\",\n",
    "    \"nrmse_fa\": \"↓\",\n",
    "}\n",
    "\n",
    "test_results = Box(subj_id=list(), model=list(), metric=list(), value=list())\n",
    "for subj_id in test_subjs:\n",
    "    for metric in test_losses:\n",
    "        # DIQT model\n",
    "        test_results.subj_id.append(subj_id)\n",
    "        test_results.model.append(\"diqt\")\n",
    "        test_results.metric.append(metric)\n",
    "        test_results.value.append(model.plain_log.test_loss[metric][subj_id])\n",
    "\n",
    "# Convert to a pandas dataframe.\n",
    "test_results = pd.DataFrame(test_results.to_dict())\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss functions: {list(test_losses)}\\n\")\n",
    "\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "test_results.to_csv(test_loss_log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison within experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with mpl.rc_context(\n",
    "#     {\n",
    "#         \"font.size\": 8.0,\n",
    "#     }\n",
    "# ):\n",
    "#     fig, axs = plt.subplots(\n",
    "#         ncols=len(test_losses),\n",
    "#         sharex=True,\n",
    "#         figsize=(11, 4),\n",
    "#         dpi=130,\n",
    "#         gridspec_kw={\"wspace\": 1.0, \"hspace\": 0},\n",
    "#     )\n",
    "#     sns.despine(fig=fig, top=True, right=True)\n",
    "\n",
    "#     for i, l in enumerate(test_losses):\n",
    "\n",
    "#         ax = axs[i]\n",
    "#         df = test_results.loc[test_results.metric == l]\n",
    "#         vplot = sns.violinplot(\n",
    "#             x=\"model\", y=\"value\", data=df, ax=ax, scale=\"count\", inner=None\n",
    "#         )\n",
    "#         axs[i].grid(axis=\"y\", alpha=0.5)\n",
    "#         points_plot = sns.swarmplot(\n",
    "#             x=\"model\",\n",
    "#             y=\"value\",\n",
    "#             hue=\"subj_id\",\n",
    "#             data=df,\n",
    "#             ax=ax,\n",
    "#             # color=\"white\",\n",
    "#             edgecolor=\"black\",\n",
    "#             size=4,\n",
    "#             linewidth=0.8,\n",
    "#         )\n",
    "#         points_plot.get_legend().remove()\n",
    "\n",
    "#         # Calculate mean performance score.\n",
    "#         means = df.groupby(\"model\").mean()\n",
    "#         # Make sure the order follows seaborn's x-axis ordering.\n",
    "#         model_order = list(map(lambda ax: ax.get_text(), axs[i].get_xticklabels()))\n",
    "#         means = means.reindex(model_order)\n",
    "\n",
    "#         # Grab colors corresponding to each model.\n",
    "#         colors = sns.color_palette(None, n_colors=len(df.model.unique()))\n",
    "\n",
    "#         lines = ax.hlines(\n",
    "#             y=means.value,\n",
    "#             xmin=np.arange(0, len(colors)) - 0.5 + 0.05,\n",
    "#             xmax=np.arange(1, len(colors) + 1) - 0.5 - 0.05,\n",
    "#             colors=colors,\n",
    "#             lw=1.5,\n",
    "#         )\n",
    "\n",
    "#         outline_path_effects = [\n",
    "#             mpl.patheffects.Stroke(linewidth=5, foreground=\"white\", alpha=0.9),\n",
    "#             mpl.patheffects.Normal(),\n",
    "#         ]\n",
    "#         lines.set_path_effects(outline_path_effects)\n",
    "\n",
    "#         ax.set_xticklabels(ax.get_xticklabels(), rotation=25)\n",
    "\n",
    "#         fig.canvas.draw()\n",
    "#         ax_format = ax.get_yaxis().get_major_formatter()\n",
    "\n",
    "#         for m, c in zip(means.value, colors):\n",
    "\n",
    "#             ax.annotate(\n",
    "#                 f\"{m:.4g}\",\n",
    "#                 xy=(ax.get_xlim()[0] + (ax.get_xlim()[0] * 0.4), m),\n",
    "#                 xycoords=\"data\",\n",
    "#                 color=c,\n",
    "#                 ha=\"right\",\n",
    "#                 va=\"center\",\n",
    "#                 annotation_clip=False,\n",
    "#                 fontweight=\"bold\",\n",
    "#                 snap=True,\n",
    "#                 bbox=dict(\n",
    "#                     boxstyle=\"square,pad=0.3\", fc=\"white\", lw=0, snap=True, alpha=0.75\n",
    "#                 ),\n",
    "#             )\n",
    "#         ax.set_title(f\"{l.replace('_', ' ')} {loss_comparison_directions[l]}\")\n",
    "#         ax.set_ylabel(\"\")\n",
    "#         ax.set_xlabel(\"\")\n",
    "# plt.savefig(experiment_results_dir / \"test_result_within_experiment.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with other works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "hist = sns.histplot(\n",
    "    list(model.plain_log[\"test_loss\"].rmse.values()),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    hatch=\"\\\\\\\\\",\n",
    "    ec=\"blue\",\n",
    ")\n",
    "hist.yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    9.72e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    9.76e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nBest ESPCN\\n[but not really]\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    8.46e-4,\n",
    "    label=\"(Blumberg etal, 2018)\\nBest Overall\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(\"Test Loss Histogram Over All Subjects with Test Metric RMSE\")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all subjects.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    \"(Tanno etal, 2021)\\nC-Spline\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2021)\\nRand. Forest\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    '(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\n\"Best\" ESPCN',\n",
    "    \"(Blumberg etal, 2018)\\nBest Overall\",\n",
    ")\n",
    "\n",
    "rmse_bounds = np.asarray(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [31.738e-4, 10.069e-4],\n",
    "        [23.139e-4, 6.974e-4],\n",
    "        [13.609e-4, 6.212e-4],\n",
    "        [13.82e-4, 6.29e-4],\n",
    "        [12.13e-4, 5.58e-4],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    rmse_bounds[2].mean(),\n",
    "    rmse_bounds[3].mean(),\n",
    "    9.72e-4,\n",
    "    9.76e-4,\n",
    "    8.46e-4,\n",
    ")\n",
    "\n",
    "rmse_score_ranges = np.asarray(rmse_scores)[:, None] - rmse_bounds\n",
    "rmse_score_ranges[:1] = rmse_score_ranges[:1] * 0\n",
    "rmse_score_ranges = rmse_score_ranges.T\n",
    "\n",
    "colors = sns.color_palette(\"deep\", n_colors=len(rmse_scores))\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "# Plot our evaluation scores.\n",
    "end_idx = 2\n",
    "ax.bar(\n",
    "    models[:end_idx],\n",
    "    rmse_scores[:end_idx],\n",
    "    color=colors[:end_idx],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "\n",
    "start_idx = end_idx\n",
    "# Plot the crazy evaluation scores.\n",
    "ax.bar(\n",
    "    models[start_idx:],\n",
    "    height=rmse_bounds[start_idx:, 0] - rmse_bounds[start_idx:, 1],\n",
    "    bottom=rmse_bounds[start_idx:, 1],\n",
    "    color=colors[start_idx:],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    "    alpha=0.8,\n",
    ")\n",
    "end_idx = start_idx + 2\n",
    "bar_width = ax.patches[0].get_width()\n",
    "# Dotted lines for the \"approximate\" actual rmse score.\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:end_idx],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"--\",\n",
    ")\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "start_idx = end_idx\n",
    "end_idx = len(models)\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"-\",\n",
    ")\n",
    "\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(\"Mean Over Subjects Test Loss RMSE\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_test_idx = np.argsort(np.asarray(list(model.plain_log.test_loss.rmse.values())))\n",
    "sorted_test_results = dict(\n",
    "    list(model.plain_log.test_loss.rmse.items())[i] for i in sorted_test_idx\n",
    ")\n",
    "ppr(sorted_test_results, sort_dicts=False)\n",
    "print(np.mean(list(list(model.plain_log.test_loss.rmse.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diqt_results = test_results.loc[test_results.model == \"diqt\"]\n",
    "\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(diqt_results.loc[diqt_results.metric == \"rmse\"].value)\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_log_euclid_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"rmse_log_euclid\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_log_euclid_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse_log_euclid\"].value),\n",
    ")\n",
    "\n",
    "logger.add_histogram(\n",
    "    \"test/scaled_psnr_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"scaled_psnr\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/ssim_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"ssim_fa\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"rmse_fa\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse_fa\"].value),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volumes of full-res ground truth, low-res downsample, full-res mask,\n",
    "# anatomical image, and full-res predictions.\n",
    "\n",
    "results_viz = Box(default_box=True)\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset:\n",
    "        # Index into the only item in the subject dataset.\n",
    "        s = Box(default_box=True)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        s.mask = subj[\"mask\"]\n",
    "        s.dti = subj[\"dti\"]\n",
    "        s.affine = subj[\"dti_meta_dict\"][\"affine\"]\n",
    "        s.lr_dti = subj[\"lr_dti\"]\n",
    "\n",
    "        s.pred = model.plain_log.viz.test_preds_dti[subj_id]\n",
    "        s.le_pred = model.plain_log.viz.test_preds_le[subj_id]\n",
    "\n",
    "        s.dti = s.dti * s.mask\n",
    "        s.pred = s.pred * s.mask\n",
    "        s.le_pred = s.le_pred * s.mask\n",
    "        s.metrics.rmse = model.plain_log.test_loss.rmse[subj_id]\n",
    "        s.abs_error = torch.abs(s.pred - s.dti)\n",
    "\n",
    "        for k in {\n",
    "            \"mask\",\n",
    "            \"dti\",\n",
    "            \"lr_dti\",\n",
    "            \"pred\",\n",
    "            \"le_pred\",\n",
    "            \"abs_error\",\n",
    "        }:\n",
    "            v = s[k]\n",
    "            if torch.is_tensor(v):\n",
    "                v = v.detach().cpu().numpy()\n",
    "            if k == \"mask\":\n",
    "                v = v.astype(bool)\n",
    "            else:\n",
    "                v = v.astype(float)\n",
    "            # s[k] = np.rot90(v)\n",
    "            s[k] = v\n",
    "\n",
    "        results_viz[subj_id] = s\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.pred, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=6,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "\n",
    "\n",
    "# And the pre-anat predictions.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.le_pred, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_le.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_le.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=7,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick the worst performing subject from the test set to visualize.\n",
    "sel_rmse = test_results.loc[\n",
    "    (test_results.model == \"diqt\") & (test_results.metric == \"rmse\")\n",
    "][[\"subj_id\", \"value\"]]\n",
    "sel_rmse = sel_rmse.sort_values(\"value\")\n",
    "# Or 2nd worst performing...\n",
    "bad_rmse = sel_rmse.iloc[-2]\n",
    "viz_subj_id = bad_rmse.subj_id\n",
    "print(viz_subj_id, bad_rmse.value)\n",
    "viz_subj = results_viz[viz_subj_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select indices for visualizing.\n",
    "dti_shape = np.asarray(viz_subj.dti.shape[1:])\n",
    "lr_dti_shape = np.asarray(viz_subj.lr_dti.shape[1:])\n",
    "\n",
    "viz_idx = dti_shape // 2\n",
    "# Last dimension (saggital) shouldn't be exactly centered, as the longitudinal fissure\n",
    "# doesn't have many fibers outside the corpus collosum.\n",
    "viz_idx[2] = viz_idx[2] + 6\n",
    "viz_lr_idx = lr_dti_shape // 2\n",
    "viz_lr_idx[2] = viz_lr_idx[2] + 6 // params.data.downsampled_by_factor\n",
    "\n",
    "viz_slice_idx = [\n",
    "    np.s_[:, viz_idx[0], :, :],\n",
    "    np.s_[:, :, viz_idx[1], :],\n",
    "    np.s_[:, :, :, viz_idx[2]],\n",
    "]\n",
    "\n",
    "viz_lr_slice_idx = [\n",
    "    np.s_[:, viz_lr_idx[0], :, :],\n",
    "    np.s_[:, :, viz_lr_idx[1], :],\n",
    "    np.s_[:, :, :, viz_lr_idx[2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ims = list()\n",
    "for im, slices in zip(\n",
    "    [viz_subj.dti, viz_subj.pred, viz_subj.lr_dti],\n",
    "    (viz_slice_idx, viz_slice_idx, viz_lr_slice_idx),\n",
    "):\n",
    "    for sl in slices:\n",
    "        selection = im[sl]\n",
    "        fa_w = pitn.viz.direction_map(selection, channels_first=True)\n",
    "        fa_w = fa_w.transpose(1, 2, 0)\n",
    "        ims.append(fa_w)\n",
    "\n",
    "dim_labels = [\n",
    "    \"Axial\",\n",
    "    \"Coronal\",\n",
    "    \"Saggital\",\n",
    "]\n",
    "vol_labels = [\"Ground Truth\", \"Pred\", \"LR Input\"]\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 12.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=130, figsize=(7, 7))\n",
    "    fig = pitn.viz.plot_im_grid(\n",
    "        ims,\n",
    "        nrows=len(vol_labels),\n",
    "        title=f\"Subj {viz_subj_id} Prediction Results\",\n",
    "        row_headers=vol_labels,\n",
    "        col_headers=dim_labels,\n",
    "        colorbars=None,\n",
    "        fig=fig,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"dir_map_pred.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "\n",
    "dim_labels = [\n",
    "    \"\\nAxial\",\n",
    "    \"\\nCor.\",\n",
    "    \"\\nSagg.\",\n",
    "]\n",
    "\n",
    "dti_names = [\n",
    "    \"FR\",\n",
    "    \"Pred\",\n",
    "    \"LR\",\n",
    "    \"Abs Err\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "cmap = \"gray\"\n",
    "title = f\"DTI Subj {viz_subj_id} Summary\"\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 6.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=150, figsize=(8, 12))\n",
    "    fig = pitn.viz.plot_vol_slices(\n",
    "        viz_subj.dti,\n",
    "        viz_subj.pred,\n",
    "        viz_subj.lr_dti,\n",
    "        viz_subj.abs_error,\n",
    "        slice_idx=(None, None, viz_idx[2] / dti_shape[2]),\n",
    "        title=title,\n",
    "        vol_labels=dti_names,\n",
    "        slice_labels=dim_labels,\n",
    "        channel_labels=channel_names,\n",
    "        colorbars=\"col\",\n",
    "        fig=fig,\n",
    "        cmap=cmap,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "\n",
    "\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(\n",
    "        experiment_results_dir / f\"Spline_DTI_sub-{viz_subj_id}_pred_result.png\"\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_logger.experiment.flush()\n",
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was for debugging.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02b6fbf192f5f02a9e4be2e8493e981ac4440e63c59c4307b81de14e51e6a1b0"
  },
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
