{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pain in the Net - DIQT with Anatomical Refinement\n",
    "Application of Deep Image Quality Transfer (DIQT) with domain adaptation.\n",
    "\n",
    "\n",
    "Code by:\n",
    "\n",
    "Tyler Spears - tas6hh@virginia.edu\n",
    "\n",
    "Dr. Tom Fletcher\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "* `R. Tanno et al., “Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI,” NeuroImage, vol. 225, p. 117366, Jan. 2021, doi: 10.1016/j.neuroimage.2020.117366.`\n",
    "* `D. C. Alexander et al., “Image quality transfer and applications in diffusion MRI,” NeuroImage, vol. 152, pp. 283–298, May 2017, doi: 10.1016/j.neuroimage.2017.02.089.`\n",
    "* `S. B. Blumberg, R. Tanno, I. Kokkinos, and D. C. Alexander, “Deeper Image Quality Transfer: Training Low-Memory Neural Networks for 3D Images,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2018, Cham, 2018, pp. 118–125, doi: 10.1007/978-3-030-00928-1_14.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import einops\n",
    "import torchinfo\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    if \"CUDA_PYTORCH_DEVICE_IDX\" in os.environ.keys():\n",
    "        dev_idx = int(os.environ[\"CUDA_PYTORCH_DEVICE_IDX\"])\n",
    "    else:\n",
    "        dev_idx = 0\n",
    "    device = torch.device(f\"cuda:{dev_idx}\")\n",
    "    print(\"CUDA Device IDX \", dev_idx)\n",
    "    torch.cuda.set_device(device)\n",
    "    print(\"CUDA Current Device \", torch.cuda.current_device())\n",
    "    print(\"CUDA Device properties: \", torch.cuda.get_device_properties(device))\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Reading & Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Here are all the parameters! This makes it easy to find them! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "###############################################\n",
    "params.experiment_name = \"uvers_pitn_anat_stream_dti_split_1\"\n",
    "params.override_experiment_name = False\n",
    "###############################################\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 48\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "params.use_anat = True\n",
    "params.use_log_euclid = False\n",
    "params.use_half_precision_float = True\n",
    "params.progress_bar = True\n",
    "params.num_workers = 8\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "params.data.anat_descr = \"t2w\"\n",
    "params.data.anat_fname_patterns = [\n",
    "    f\"sub-*t2w.nii.gz\",\n",
    "]\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# This is the number of voxels to remove (read: center crop out) from the network's\n",
    "# prediction. This allows for an \"oversampling\" of the low-res voxels to help inform a\n",
    "# more constrained HR prediction. This value of voxels will be removed from each spatial\n",
    "# dimension (D, H, and W) starting at the center of the output patches.\n",
    "# Ex. A size of 1 will remove the 2 outer-most voxels from each dimension in the output,\n",
    "# while still keeping the corresponding voxels in the LR input.\n",
    "params.hr_center_crop_per_side = 0\n",
    "\n",
    "# Maximum allowed eigenvalue for *all* DTIs. This was calculated as the median of the\n",
    "# eigenvalue thresholds found in the \"notebooks/data/dti_thresholding.ipynb\" notebook.\n",
    "# Actual computed value is 0.0033200803422369068, rounded here\n",
    "# **This counts as outlier removal and will change both the training and test data**\n",
    "params.data.eigval_clip_cutoff = 0.00332008\n",
    "\n",
    "# Second data scaling method, where the training data will be scaled and possibly clipped,\n",
    "# but the testing data will be compared on the originals.\n",
    "# Scale input data by the valid values of each channel of the DTI.\n",
    "# I.e., Dx,x in [0, 1], Dx,y in [-1, 1], Dy,y in [0, 1], Dy,z in [-1, 1], etc.\n",
    "params.data.scale_method = \"standard\"\n",
    "\n",
    "# Network params.\n",
    "# The network's goal is to upsample the input by this factor.\n",
    "params.net.upscale_factor = params.data.downsampled_by_factor\n",
    "params.net.kwargs.n_res_units = 3\n",
    "params.net.kwargs.n_dense_units = 3\n",
    "params.net.kwargs.interior_channels = 24\n",
    "params.net.kwargs.anat_in_channels = 1\n",
    "params.net.kwargs.anat_interior_channels = 14\n",
    "params.net.kwargs.anat_n_res_units = 2\n",
    "params.net.kwargs.anat_n_dense_units = 2\n",
    "\n",
    "params.net.kwargs.activate_fn = \"elu\"\n",
    "params.net.kwargs.upsample_activate_fn = \"elu\"\n",
    "params.net.kwargs.center_crop_output_side_amt = params.hr_center_crop_per_side\n",
    "\n",
    "# Adam optimizer kwargs\n",
    "params.optim.name = \"AdamW\"\n",
    "params.optim.kwargs.lr = 2.5e-4\n",
    "# params.optim.kwargs.lr = 1e-3\n",
    "params.optim.kwargs.betas = (0.9, 0.999)\n",
    "params.optim.kwargs.eps = (\n",
    "    1e-8 if not params.use_half_precision_float else torch.finfo(torch.float16).tiny\n",
    ")\n",
    "\n",
    "# Force subject split to be read in from config file.\n",
    "# # Testing params\n",
    "# params.test.dataset_subj_percent = 0.4\n",
    "\n",
    "# # Validation params\n",
    "# params.val.dataset_subj_percent = 0.2\n",
    "\n",
    "# # Testing params\n",
    "# params.test.subjs = [\n",
    "#     \"701535\",\n",
    "#     \"978578\",\n",
    "#     \"118124\",\n",
    "#     \"894774\",\n",
    "#     \"185947\",\n",
    "#     \"297655\",\n",
    "#     \"135528\",\n",
    "#     \"679770\",\n",
    "#     \"792867\",\n",
    "#     \"567961\",\n",
    "#     \"189450\",\n",
    "#     \"227432\",\n",
    "#     \"108828\",\n",
    "#     \"307127\",\n",
    "#     \"156637\",\n",
    "#     \"803240\",\n",
    "#     \"164030\",\n",
    "#     \"196952\",\n",
    "#     \"753251\",\n",
    "#     \"140117\",\n",
    "#     \"103515\",\n",
    "#     \"198047\",\n",
    "#     \"124220\",\n",
    "#     \"118730\",\n",
    "#     \"303624\",\n",
    "#     \"103010\",\n",
    "#     \"397154\",\n",
    "#     \"700634\",\n",
    "#     \"810439\",\n",
    "#     \"382242\",\n",
    "#     \"203923\",\n",
    "#     \"224022\",\n",
    "#     \"175035\",\n",
    "#     \"167238\",\n",
    "# ]\n",
    "# params.test.dataset_n_subjs = len(params.test.subjs)\n",
    "\n",
    "# # Validation params\n",
    "# params.val.subjs = [\"644246\", \"567759\", \"231928\", \"157437\"]\n",
    "# params.val.dataset_n_subjs = len(params.val.subjs)\n",
    "\n",
    "# # Training params\n",
    "# params.train.subjs = [\n",
    "#     \"634748\",\n",
    "#     \"386250\",\n",
    "#     \"751348\",\n",
    "#     \"150019\",\n",
    "#     \"910241\",\n",
    "#     \"406432\",\n",
    "#     \"815247\",\n",
    "#     \"690152\",\n",
    "#     \"141422\",\n",
    "#     \"100408\",\n",
    "# ]\n",
    "# params.train.dataset_n_subjs = len(params.train.subjs)\n",
    "\n",
    "params.train.in_patch_size = (24, 24, 24)\n",
    "params.train.batch_size = 32\n",
    "params.train.samples_per_subj_per_epoch = 4000\n",
    "params.train.max_epochs = 50\n",
    "params.train.loss_name = \"vfro\"\n",
    "params.train.lambda_dti_stream_loss = 0.35\n",
    "# Percentage of subjs in dataset that go into the training set.\n",
    "# params.train.dataset_subj_percent = 1 - (\n",
    "#     params.test.dataset_subj_percent + params.val.dataset_subj_percent\n",
    "# )\n",
    "params.train.grad_2norm_clip_val = 0.25\n",
    "params.train.accumulate_grad_batches = None\n",
    "# Learning rate scheduler config.\n",
    "params.train.lr_scheduler = None\n",
    "# num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "# num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "# num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "# params.train.lr_scheduler.kwargs.steps_per_epoch = (\n",
    "#     params.train.samples_per_subj_per_epoch * num_train_subjs // params.train.batch_size\n",
    "# )\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    if \"PITN_CONFIG\" in os.environ.keys():\n",
    "        config_fname = Path(os.environ[\"PITN_CONFIG\"])\n",
    "    else:\n",
    "        config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\".yaml\", \".yml\"}:\n",
    "        f_params = Box.from_yaml(filename=config_fname)\n",
    "    elif f_type == \".json\":\n",
    "        f_params = Box.from_json(filename=config_fname)\n",
    "    elif f_type == \".toml\":\n",
    "        f_params = Box.from_toml(filename=config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    print(\"WARNING: Config file not loaded\")\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose a subset of all params as the hyperparams of the model.\n",
    "hyperparams = Box(\n",
    "    batch_size=params.train.batch_size,\n",
    "    samples_per_subj_epoch=params.train.samples_per_subj_per_epoch,\n",
    "    epochs=params.train.max_epochs,\n",
    "    loss_fn=params.train.loss_name,\n",
    "    optim=params.optim.name,\n",
    "    anat=params.data.anat_descr if params.use_anat else False,\n",
    "    lambda_dti_loss=params.train.lambda_dti_stream_loss,\n",
    "    n_subjs=params.n_subjs,\n",
    ").to_dict()\n",
    "\n",
    "if \"lr_scheduler\" in params.train and params.train.lr_scheduler:\n",
    "    hyperparams[\"lr_scheduler\"] = params.train.lr_scheduler.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard experiment logging setup.\n",
    "EXPERIMENT_NAME = params.experiment_name\n",
    "\n",
    "ts = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "# Break ISO format because many programs don't like having colons ':' in a filename.\n",
    "ts = ts.replace(\":\", \"_\")\n",
    "if not params.override_experiment_name:\n",
    "    experiment_name = ts + \"__\" + EXPERIMENT_NAME\n",
    "else:\n",
    "    experiment_name = EXPERIMENT_NAME\n",
    "run_name = experiment_name\n",
    "# experiment_results_dir = results_dir / experiment_name\n",
    "\n",
    "# Create temporary directory for results directory, in case experiment does not finish.\n",
    "# Only grab directories that are timestamped starting with a year.\n",
    "tmp_dirs = list(tmp_results_dir.glob(\"[0-9][0-9][0-9][0-9]*\"))\n",
    "\n",
    "# Only keep up to N tmp results.\n",
    "n_tmp_to_keep = 5\n",
    "if len(tmp_dirs) > (n_tmp_to_keep - 1):\n",
    "    print(f\"More than {n_tmp_to_keep} temporary results, culling to the most recent\")\n",
    "    tmps_to_delete = natsorted([str(tmp_dir) for tmp_dir in tmp_dirs])[\n",
    "        : -(n_tmp_to_keep - 1)\n",
    "    ]\n",
    "    for tmp_dir in tmps_to_delete:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        print(\"Deleted temporary results directory \", tmp_dir)\n",
    "\n",
    "experiment_results_dir = tmp_results_dir / experiment_name\n",
    "# Final target directory, to be made when experiment is complete.\n",
    "final_experiment_results_dir = results_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass this object into the pytorchlightning Trainer object, for easier logging within\n",
    "# the training/testing loops.\n",
    "pl_logger = pl.loggers.TensorBoardLogger(\n",
    "    tmp_results_dir,\n",
    "    name=experiment_name,\n",
    "    version=\"\",\n",
    "    log_graph=False,\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "# Use the lower-level logger for logging histograms, images, etc.\n",
    "logger = pl_logger.experiment\n",
    "\n",
    "# Create a separate txt file to log streams of events & info besides parameters & results.\n",
    "log_txt_file = Path(logger.log_dir) / \"log.txt\"\n",
    "print_safe_params = Box(params.copy(), box_recast={\"fr_dir\": str, \"lr_dir\": str})\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Experiment Name: {experiment_name}\\n\")\n",
    "    f.write(f\"Timestamp: {ts}\\n\")\n",
    "    # Parameters.\n",
    "    f.write(pprint.pformat(print_safe_params.to_dict()) + \"\\n\")\n",
    "    # cap is defined in an ipython magic command\n",
    "    f.write(f\"Environment and Hardware Info:\\n {cap}\\n\\n\")\n",
    "params_file = Path(logger.log_dir) / \"run_params.yaml\"\n",
    "print_safe_params.to_yaml(filename=params_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "    \"406432\",\n",
    "    \"803240\",\n",
    "    \"815247\",\n",
    "    \"167238\",\n",
    "    \"100408\",\n",
    "    \"792867\",\n",
    "    \"157437\",\n",
    "    \"164030\",\n",
    "    \"103515\",\n",
    "    \"118730\",\n",
    "    \"198047\",\n",
    "    \"189450\",\n",
    "    \"203923\",\n",
    "    \"108828\",\n",
    "    \"124220\",\n",
    "    \"386250\",\n",
    "    \"118124\",\n",
    "    \"701535\",\n",
    "    \"679770\",\n",
    "    \"382242\",\n",
    "    \"231928\",\n",
    "    \"196952\",  # Hold-out subject; for visualization, ensure never in the train or val sets\n",
    "    \"567961\",\n",
    "    \"910241\",\n",
    "    \"175035\",\n",
    "    \"567759\",\n",
    "    \"978578\",\n",
    "    \"150019\",\n",
    "    \"690152\",\n",
    "    \"297655\",\n",
    "    \"307127\",\n",
    "    \"634748\",\n",
    "]\n",
    "HOLDOUT_SUBJ_ID = \"196952\"\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Selected Subjects: {selected_ids}\\n\")\n",
    "\n",
    "logger.add_text(\"subjs\", pprint.pformat(selected_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "fr2lr_patch_coords_fn[\"lr_log_euclid\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "fr2lr_patch_coords_fn[\"lr_mask\"] = fr2lr_patch_coords_fn[\"lr_dti\"]\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"log_euclid\", \"anat\", \"mask\"},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "data_scaler_cls = pitn.nn.norm.norm_method_lookup[params.data.scale_method]\n",
    "data_scaler_kws = list()\n",
    "for vol in (\"dti\", \"log_euclid\", \"anat\", \"lr_dti\", \"lr_log_euclid\"):\n",
    "    data_scaler_kws.append(vol + \"_scale_kwargs\")\n",
    "\n",
    "# Coefficients to the log-euclidean lower triangle/6D vector that properly scales\n",
    "# the Euclidean distance under the log-euclidean metrics.\n",
    "mat_norm_coeffs = torch.ones(6)\n",
    "mat_norm_coeffs[torch.as_tensor([1, 3, 4])] = np.sqrt(2)\n",
    "mat_norm_coeffs = mat_norm_coeffs.reshape(-1, 1, 1, 1)\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "        data = dict()\n",
    "        data[\"subj_id\"] = subj_id\n",
    "        fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "        lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "        data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "        data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "        ####### Low-resolution DTIs/volumes\n",
    "        lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            lr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(lr_dti_f)\n",
    "        lr_dti, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        lr_dti = torch.from_numpy(lr_dti)\n",
    "        lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "        data[\"lr_dti\"] = lr_dti\n",
    "        data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "        # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "        lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "        target_fr_shape = np.floor(lr_dti_shape * params.net.upscale_factor).astype(int)\n",
    "\n",
    "        ####### Full-resolution images/volumes.\n",
    "        # DTI.\n",
    "        dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.dti_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(dti_f)\n",
    "        dti, meta = nib_reader.get_data(im)\n",
    "        dti = torch.from_numpy(dti)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            dti, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "        data[\"dti\"] = dti\n",
    "        data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "        # Diffusion mask.\n",
    "        mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "            fr_subj_dir, params.data.mask_fname_pattern\n",
    "        )\n",
    "        im = nib_reader.read(mask_f)\n",
    "        mask, meta = nib_reader.get_data(im)\n",
    "        meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "        mask = torch.from_numpy(mask)\n",
    "        # Add channel dim if not available.\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[None]\n",
    "        mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "            mask, meta[\"affine\"], target_fr_shape\n",
    "        )\n",
    "        mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "        mask = mask.bool()\n",
    "        data[\"mask\"] = mask\n",
    "        data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "        # Anatomical/structural volume.\n",
    "        # May have multiple types of anatomical refinement volumes, so concat them\n",
    "        # channel-wise and just call it 'anat'\n",
    "        anat_vols = list()\n",
    "        anat_meta = None\n",
    "        for anat_f_pattern in params.data.anat_fname_patterns:\n",
    "            anat_f = pitn.utils.system.get_file_glob_unique(fr_subj_dir, anat_f_pattern)\n",
    "            im = nib_reader.read(anat_f)\n",
    "            anat, meta = nib_reader.get_data(im)\n",
    "            meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "            anat = torch.from_numpy(anat)\n",
    "            if anat.ndim == 3:\n",
    "                anat = anat[\n",
    "                    None,\n",
    "                ]\n",
    "            anat, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "                anat, meta[\"affine\"], target_fr_shape\n",
    "            )\n",
    "            anat, meta[\"affine\"] = orient_to_viz(anat, meta[\"affine\"])\n",
    "            # Just choose the first meta dict that is found, they should all be the\n",
    "            # same...\n",
    "            if anat_meta is None:\n",
    "                anat_meta = meta\n",
    "            anat_vols.append(anat)\n",
    "\n",
    "        anat_vols = torch.concat(anat_vols, dim=0)\n",
    "        data[\"anat\"] = anat_vols\n",
    "        data[\"anat_meta_dict\"] = anat_meta\n",
    "\n",
    "        # Construct a quick and cheap mask for the LR DTI\n",
    "        cheap_lr_mask = F.interpolate(\n",
    "            data[\"mask\"][None].float(),\n",
    "            size=data[\"lr_dti\"][0].shape,\n",
    "            mode=\"nearest\",\n",
    "        )[0]\n",
    "        data[\"lr_mask\"] = cheap_lr_mask.bool()\n",
    "\n",
    "        # Consider this as the \"noise correction\" step to have more informative, consistent\n",
    "        # results with minimal biasing. Otherwise, outliers (which are clearly errors) can\n",
    "        # change loss and performance metrics by orders of magnitude for no good reason!\n",
    "        if \"eigval_clip_cutoff\" in params.data and params.data.eigval_clip_cutoff:\n",
    "            correct_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"dti\"])\n",
    "            correct_dti = correct_dti * data[\"mask\"]\n",
    "            ####\n",
    "            sae_fr = (\n",
    "                F.l1_loss(data[\"dti\"], correct_dti, reduction=\"none\") * data[\"mask\"]\n",
    "            )\n",
    "            sae_fr = sae_fr.view(6, -1).sum(1)\n",
    "            mae_fr = sae_fr / torch.count_nonzero(data[\"mask\"])\n",
    "            print(f\"---Subj {subj_id}---\")\n",
    "            print(\n",
    "                \"MAE of FR DTI after eigenvalue clipping:\\n\",\n",
    "                mae_fr.tolist(),\n",
    "            )\n",
    "            ####\n",
    "            data[\"dti\"] = correct_dti\n",
    "\n",
    "            correct_lr_dti = pitn.data.outliers.clip_dti_eigvals(\n",
    "                data[\"lr_dti\"].to(device),\n",
    "                tensor_components_dim=0,\n",
    "                eigval_max=params.data.eigval_clip_cutoff,\n",
    "            ).to(data[\"lr_dti\"])\n",
    "            lr_mask = (data[\"lr_dti\"] != 0).max(0, keepdim=True).values\n",
    "            correct_lr_dti = correct_lr_dti * lr_mask\n",
    "            ####\n",
    "            sae_lr = (\n",
    "                F.l1_loss(data[\"lr_dti\"], correct_lr_dti, reduction=\"none\") * lr_mask\n",
    "            )\n",
    "            sae_lr = sae_lr.view(6, -1).sum(1)\n",
    "            mae_lr = sae_lr / torch.count_nonzero(lr_mask)\n",
    "            print(\n",
    "                \"MAE of LR DTI after eigenvalue clipping:\\n\",\n",
    "                mae_lr.tolist(),\n",
    "            )\n",
    "            ####\n",
    "            data[\"lr_dti\"] = correct_lr_dti\n",
    "\n",
    "        ####### Log-euclid pre-computed volumes\n",
    "\n",
    "        # LR log-euclid volume.\n",
    "        lr_log_euclid = pitn.eig.tril_vec2sym_mat(data[\"lr_dti\"], tril_dim=0)\n",
    "        lr_log_euclid = pitn.riemann.log_euclid.log_map(lr_log_euclid)\n",
    "        lr_log_euclid = pitn.eig.sym_mat2tril_vec(lr_log_euclid, tril_dim=0)\n",
    "        lr_log_euclid = lr_log_euclid * mat_norm_coeffs\n",
    "        data[\"lr_log_euclid\"] = lr_log_euclid\n",
    "\n",
    "        log_euclid = pitn.eig.tril_vec2sym_mat(data[\"dti\"], tril_dim=0)\n",
    "        log_euclid = pitn.riemann.log_euclid.log_map(log_euclid)\n",
    "        log_euclid = pitn.eig.sym_mat2tril_vec(log_euclid, tril_dim=0)\n",
    "        log_euclid = log_euclid * mat_norm_coeffs\n",
    "        data[\"log_euclid\"] = log_euclid\n",
    "\n",
    "        ######## Normalized Subj Volumes\n",
    "        if params.data.scale_method == \"standard\":\n",
    "            # LR params.\n",
    "            mask = data[\"lr_mask\"]\n",
    "            for vol in (\"lr_dti\", \"lr_log_euclid\"):\n",
    "                scale_kwargs = data_scaler_cls.compute_scale_kwargs(\n",
    "                    data[vol], mask=mask, batched=False\n",
    "                )\n",
    "                data[vol + \"_scale_kwargs\"] = scale_kwargs.copy()\n",
    "\n",
    "            # FR params\n",
    "            mask = data[\"mask\"]\n",
    "            for vol in (\"dti\", \"log_euclid\", \"anat\"):\n",
    "                scale_kwargs = data_scaler_cls.compute_scale_kwargs(\n",
    "                    data[vol], mask=mask, batched=False\n",
    "                )\n",
    "                data[vol + \"_scale_kwargs\"] = scale_kwargs.copy()\n",
    "\n",
    "        vol_names = {\n",
    "            \"dti\",\n",
    "            \"anat\",\n",
    "            \"mask\",\n",
    "            \"lr_dti\",\n",
    "            \"lr_mask\",\n",
    "            \"log_euclid\",\n",
    "            \"lr_log_euclid\",\n",
    "        }\n",
    "\n",
    "        metadata_names = set(data.keys()) - vol_names\n",
    "        vol_d = {k: data[k] for k in vol_names}\n",
    "        meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "        # Create multi-volume dataset for this subj-session.\n",
    "        subj_dataset = pitn.data.SubjSesDataset(\n",
    "            vol_d,\n",
    "            primary_vol_name=\"dti\",\n",
    "            special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "            transform=None,\n",
    "            primary_patch_kwargs=patch_kwargs,\n",
    "            **meta_d,\n",
    "        )\n",
    "\n",
    "        # Finalize this subject.\n",
    "        subj_data[subj_id] = subj_dataset\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Up Patch-Based Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data train/validation/test split\n",
    "\n",
    "num_subjs = len(subj_data)\n",
    "if \"dataset_n_subjs\" in params.test and params.test.dataset_n_subjs:\n",
    "    num_test_subjs = int(params.test.dataset_n_subjs)\n",
    "elif \"dataset_subj_percent\" in params.test and params.test.dataset_subj_percent:\n",
    "    num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "else:\n",
    "    raise RuntimeError(\"ERROR: Number of test subjects not given\")\n",
    "\n",
    "if \"dataset_n_subjs\" in params.val and params.val.dataset_n_subjs:\n",
    "    num_val_subjs = int(params.val.dataset_n_subjs)\n",
    "elif \"dataset_subj_percent\" in params.val and params.val.dataset_subj_percent:\n",
    "    num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "else:\n",
    "    raise RuntimeError(\"ERROR: Number of validation subjects not given\")\n",
    "\n",
    "if \"dataset_n_subjs\" in params.train and params.train.dataset_n_subjs:\n",
    "    num_train_subjs = int(params.train.dataset_n_subjs)\n",
    "else:\n",
    "    num_train_subjs = max(1, params.n_subjs - (num_test_subjs + num_val_subjs))\n",
    "\n",
    "if num_test_subjs + num_val_subjs + num_train_subjs > num_subjs:\n",
    "    raise RuntimeError(\n",
    "        \"ERROR: Too many subjects selected train/val/test split \"\n",
    "        + f\"{(num_test_subjs, num_val_subjs, num_train_subjs)}, \"\n",
    "        + f\"only {num_subjs} available.\"\n",
    "    )\n",
    "subj_list = list(subj_data.keys())\n",
    "# Randomly shuffle the list of subjects, then choose the first `num_test_subjs` subjects\n",
    "# for testing.\n",
    "random.shuffle(subj_list)\n",
    "\n",
    "# make sure the pre-set holdout subject is in the *test set*, not in the training or\n",
    "# validation sets.\n",
    "if HOLDOUT_SUBJ_ID in subj_list:\n",
    "    subj_list.remove(HOLDOUT_SUBJ_ID)\n",
    "    subj_list.insert(0, HOLDOUT_SUBJ_ID)\n",
    "\n",
    "# Choose the remaining for training/validation.\n",
    "# If only 1 subject is available, assume this is a debugging run.\n",
    "if num_subjs == 1:\n",
    "    warnings.warn(\n",
    "        \"DEBUG: Only 1 subject selected, mixing training, validation, and testing sets\"\n",
    "    )\n",
    "    num_train_subjs = num_val_subjs = num_test_subjs = 1\n",
    "\n",
    "    test_subjs = subj_list\n",
    "    val_subjs = subj_list\n",
    "    train_subjs = subj_list\n",
    "# If the TVS split is given in the parameters, take that split instead of a random one.\n",
    "elif \"subjs\" in params.test and \"subjs\" in params.val and \"subjs\" in params.train:\n",
    "    test_subjs = params.test.subjs\n",
    "    val_subjs = params.val.subjs\n",
    "    train_subjs = params.train.subjs\n",
    "else:\n",
    "    test_subjs = subj_list[:num_test_subjs]\n",
    "    val_subjs = subj_list[num_test_subjs : (num_test_subjs + num_val_subjs)]\n",
    "    train_subjs = subj_list[(num_test_subjs + num_val_subjs) :]\n",
    "\n",
    "print(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\")\n",
    "print(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\")\n",
    "print(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\")\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"{num_train_subjs}/{num_subjs} Training subject ID(s): {train_subjs}\\n\")\n",
    "    f.write(f\"{num_val_subjs}/{num_subjs} Validation subject ID(s): {val_subjs}\\n\")\n",
    "    f.write(f\"{num_test_subjs}/{num_subjs} Test subject ID(s): {test_subjs}\\n\")\n",
    "\n",
    "logger.add_text(\"train_subjs\", str(train_subjs))\n",
    "logger.add_text(\"val_subjs\", str(val_subjs))\n",
    "logger.add_text(\"test_subjs\", str(test_subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders for test, validation, and training steps.\n",
    "sample_kws = {\n",
    "    **{\n",
    "        \"subj_id\": \"subj_id\",\n",
    "        \"dti\": \"dti\",\n",
    "        \"anat\": \"anat\",\n",
    "        \"lr_dti\": \"lr_dti\",\n",
    "        \"mask\": \"mask\",\n",
    "        \"lr_mask\": \"lr_mask\",\n",
    "        \"log_euclid\": \"log_euclid\",\n",
    "        \"lr_log_euclid\": \"lr_log_euclid\",\n",
    "    },\n",
    "    **{k: k for k in data_scaler_kws},\n",
    "}\n",
    "\n",
    "# Select only the keys that are needed during training, to save on processing time\n",
    "# spent indexing and transferring data to the GPU.\n",
    "if params.use_log_euclid:\n",
    "    train_sample_vol_keys = {\n",
    "        \"log_euclid\",\n",
    "        \"lr_log_euclid\",\n",
    "    }\n",
    "    train_sample_meta_keys = set(filter(lambda s: \"log_euclid\" in s, data_scaler_kws))\n",
    "    train_sample_primary_key = \"log_euclid\"\n",
    "else:\n",
    "    train_sample_vol_keys = {\n",
    "        \"dti\",\n",
    "        \"lr_dti\",\n",
    "    }\n",
    "    train_sample_meta_keys = set(filter(lambda s: \"dti\" in s, data_scaler_kws))\n",
    "    train_sample_primary_key = \"dti\"\n",
    "\n",
    "train_sample_meta_keys.add(\"anat_scale_kwargs\")\n",
    "train_sample_vol_keys.add(\"anat\")\n",
    "train_sample_vol_keys.add(\"mask\")\n",
    "train_sample_vol_keys.add(\"lr_mask\")\n",
    "\n",
    "# Train\n",
    "train_ds = list()\n",
    "for subj_id in train_subjs:\n",
    "    subj_data[subj_id].set_patch_sample_keys(\n",
    "        train_sample_primary_key, *(train_sample_vol_keys - {train_sample_primary_key})\n",
    "    )\n",
    "    train_ds.append(subj_data[subj_id].patches)\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_ds)\n",
    "train_sampler = pitn.samplers.ConcatDatasetBalancedRandomSampler(\n",
    "    train_dataset.datasets,\n",
    "    max_samples_per_dataset=params.train.samples_per_subj_per_epoch,\n",
    "    # Make sure we resample, performance sucks otherwise.\n",
    "    resample_after_empty=True,\n",
    ")\n",
    "train_collate_fn = functools.partial(\n",
    "    pitn.samplers.collate_dicts,\n",
    "    **dict(\n",
    "        zip(\n",
    "            train_sample_vol_keys | train_sample_meta_keys,\n",
    "            train_sample_vol_keys | train_sample_meta_keys,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=params.train.batch_size,\n",
    "    collate_fn=train_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=params.num_workers,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=10,\n",
    ")\n",
    "\n",
    "# Test & Validation\n",
    "# Only need raw DTIs for testing and validation, not training.\n",
    "tv_sample_kws = sample_kws\n",
    "test_val_collate_fn = functools.partial(pitn.samplers.collate_dicts, **tv_sample_kws)\n",
    "\n",
    "test_ds = list()\n",
    "for subj_id in test_subjs:\n",
    "    test_ds.append(subj_data[subj_id])\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_ds)\n",
    "test_loader = monai.data.DataLoader(\n",
    "    test_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")\n",
    "\n",
    "val_ds = list()\n",
    "for subj_id in val_subjs:\n",
    "    val_ds.append(subj_data[subj_id])\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_ds)\n",
    "val_loader = monai.data.DataLoader(\n",
    "    val_dataset, collate_fn=test_val_collate_fn, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Aggregate Statistics for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only choose subjects in the training and validation datasets.\n",
    "\n",
    "subj_agg_stats = Box(default_box=True)\n",
    "subj_agg_stats.dti.min = torch.zeros(params.n_channels).to(\n",
    "    list(subj_data.values())[0][0][\"dti\"]\n",
    ")\n",
    "subj_agg_stats.dti.max = torch.zeros(params.n_channels).to(subj_agg_stats.dti.min)\n",
    "\n",
    "subj_agg_stats.log_euclid.min = subj_agg_stats.dti.min\n",
    "subj_agg_stats.log_euclid.max = subj_agg_stats.dti.max\n",
    "\n",
    "for subj_id in set(train_subjs).union(set(val_subjs)):\n",
    "    s = subj_data[subj_id]\n",
    "    fr_mask = s[0][\"mask\"]\n",
    "    dti = torch.masked_select(s[0][\"dti\"], fr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "    lr_dti = s[0][\"lr_dti\"]\n",
    "    lr_mask = (lr_dti == 0).all(0)[\n",
    "        None,\n",
    "    ]\n",
    "    lr_dti = torch.masked_select(lr_dti, lr_mask)\n",
    "    subj_agg_stats.dti.min = torch.minimum(\n",
    "        subj_agg_stats.dti.min, lr_dti.view(params.n_channels, -1).min(-1).values\n",
    "    )\n",
    "    subj_agg_stats.dti.max = torch.maximum(\n",
    "        subj_agg_stats.dti.max, lr_dti.view(params.n_channels, -1).max(-1).values\n",
    "    )\n",
    "\n",
    "    log_euclid = torch.masked_select(s[0][\"log_euclid\"], fr_mask).view(\n",
    "        params.n_channels, -1\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.min = torch.minimum(\n",
    "        subj_agg_stats.log_euclid.min,\n",
    "        log_euclid.view(params.n_channels, -1).min(-1).values,\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.max = torch.maximum(\n",
    "        subj_agg_stats.log_euclid.max,\n",
    "        log_euclid.view(params.n_channels, -1).max(-1).values,\n",
    "    )\n",
    "    lr_log_euclid = torch.masked_select(s[0][\"lr_log_euclid\"], lr_mask).view(\n",
    "        params.n_channels, -1\n",
    "    )\n",
    "    # lr_log_euclid = s[0][\"lr_log_euclid\"][lr_mask]\n",
    "    subj_agg_stats.log_euclid.min = torch.minimum(\n",
    "        subj_agg_stats.log_euclid.min,\n",
    "        lr_log_euclid.view(params.n_channels, -1).min(-1).values,\n",
    "    )\n",
    "    subj_agg_stats.log_euclid.max = torch.maximum(\n",
    "        subj_agg_stats.log_euclid.max,\n",
    "        lr_log_euclid.view(params.n_channels, -1).max(-1).values,\n",
    "    )\n",
    "\n",
    "\n",
    "print(subj_agg_stats.dti.min)\n",
    "print(subj_agg_stats.dti.max)\n",
    "print(subj_agg_stats.log_euclid.min)\n",
    "print(subj_agg_stats.log_euclid.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Ranges for PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expander = functools.partial(einops.rearrange, pattern=\"c -> 1 c 1 1 1\")\n",
    "# Collect DTI global data features.\n",
    "dti_min = expander(subj_agg_stats.dti.min)\n",
    "dti_max = expander(subj_agg_stats.dti.max)\n",
    "\n",
    "feat_min, feat_max = torch.as_tensor(\n",
    "    [\n",
    "        [0] * 6,\n",
    "        [1] * 6,\n",
    "    ]\n",
    ")\n",
    "feat_min = expander(feat_min)\n",
    "feat_max = expander(feat_max)\n",
    "\n",
    "# PSNR is calculated on the final output tensor components, so no log-euclidean or\n",
    "# scaling will occur here.\n",
    "psnr_range_params = pitn.data.norm.GlobalScaleParams(\n",
    "    feature_min=feat_min, feature_max=feat_max, data_min=dti_min, data_max=dti_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net_scalers = dict()\n",
    "\n",
    "# expander = functools.partial(einops.rearrange, pattern=\"c -> 1 c 1 1 1\")\n",
    "# # Collect DTI global data features.\n",
    "\n",
    "# feat_min: torch.Tensor\n",
    "# feat_max: torch.Tensor\n",
    "# dti_min = expander(subj_agg_stats.dti.min)\n",
    "# dti_max = expander(subj_agg_stats.dti.max)\n",
    "\n",
    "# if params.use_log_euclid and (\n",
    "#     \"dti_scale_range\" in params.data and params.data.dti_scale_range\n",
    "# ):\n",
    "#     print(\"Using log-euclid min/max for tensor input/output scaling.\")\n",
    "#     leu_min = expander(subj_agg_stats.log_euclid.min)\n",
    "#     leu_max = expander(subj_agg_stats.log_euclid.max)\n",
    "\n",
    "#     feat_min, feat_max = torch.as_tensor(params.data.dti_scale_range)\n",
    "#     feat_min = expander(feat_min)\n",
    "#     feat_max = expander(feat_max)\n",
    "\n",
    "#     # Add these stats to the network kwargs in a functional form.\n",
    "#     leu_scaler = pitn.data.norm.MinMaxScaler(\n",
    "#         feature_min=feat_min,\n",
    "#         feature_max=feat_max,\n",
    "#         data_min=leu_min,\n",
    "#         data_max=leu_max,\n",
    "#     )\n",
    "#     net_scalers[\"input_scaler\"] = leu_scaler.scale_to\n",
    "#     net_scalers[\"output_descaler\"] = leu_scaler.unscale_from\n",
    "\n",
    "# elif \"dti_scale_range\" in params.data and params.data.dti_scale_range:\n",
    "#     print(\"Using regular tensor component values for input/output scaling.\")\n",
    "\n",
    "#     feat_min, feat_max = torch.as_tensor(params.data.dti_scale_range)\n",
    "#     feat_min = expander(feat_min)\n",
    "#     feat_max = expander(feat_max)\n",
    "\n",
    "#     dti_global_scale_params = pitn.data.norm.GlobalScaleParams(\n",
    "#         feature_min=feat_min, feature_max=feat_max, data_min=dti_min, data_max=dti_max\n",
    "#     )\n",
    "\n",
    "#     # Add these stats to the network kwargs in a functional form.\n",
    "#     dti_scaler = pitn.data.norm.MinMaxScaler(\n",
    "#         feature_min=dti_global_scale_params.feature_min,\n",
    "#         feature_max=dti_global_scale_params.feature_max,\n",
    "#         data_min=dti_global_scale_params.data_min,\n",
    "#         data_max=dti_global_scale_params.data_max,\n",
    "#     )\n",
    "#     net_scalers[\"input_scaler\"] = dti_scaler.scale_to\n",
    "#     net_scalers[\"output_descaler\"] = dti_scaler.unscale_from\n",
    "# else:\n",
    "#     print(\"No scaling\")\n",
    "\n",
    "#     feat_min, feat_max = torch.as_tensor(\n",
    "#         [\n",
    "#             [0] * 6,\n",
    "#             [1] * 6,\n",
    "#         ]\n",
    "#     )\n",
    "#     feat_min = expander(feat_min)\n",
    "#     feat_max = expander(feat_max)\n",
    "\n",
    "#     net_scalers[\"input_scaler\"] = lambda o: o\n",
    "#     net_scalers[\"output_descaler\"] = lambda o: o\n",
    "\n",
    "# # PSNR is calculated on the final output tensor components, so no log-euclidean or\n",
    "# # scaling will occur here.\n",
    "# psnr_range_params = pitn.data.norm.GlobalScaleParams(\n",
    "#     feature_min=feat_min, feature_max=feat_max, data_min=dti_min, data_max=dti_max\n",
    "# )\n",
    "\n",
    "# ### Anatomical input scaling.\n",
    "# if params.use_anat:\n",
    "#     if \"anat_scale_range\" in params.data and params.data.anat_scale_range:\n",
    "#         # Collect anat global data features.\n",
    "#         anat_min = expander(subj_agg_stats.anat.min)\n",
    "#         anat_max = expander(subj_agg_stats.anat.max)\n",
    "\n",
    "#         if params.use_log_euclid and (\n",
    "#             \"dti_scale_range\" in params.data and params.data.dti_scale_range\n",
    "#         ):\n",
    "#             # If the log-euclid metrics are being used, then the anatomical needs to be log-\n",
    "#             # transformed to hit the range we want. So, combine two scalings with a log in the\n",
    "#             # middle.\n",
    "#             print(\"Scaling anat to log-euclidean, roughly\")\n",
    "#             # Pre-log scaling to match the 1st dti component range.\n",
    "#             pre_log_anat_scaler = pitn.data.norm.MinMaxScaler(\n",
    "#                 feature_min=expander(subj_agg_stats.dti.min)[:, 0][:, None],\n",
    "#                 feature_max=expander(subj_agg_stats.dti.max)[:, 0][:, None],\n",
    "#                 data_min=anat_min,\n",
    "#                 data_max=anat_max,\n",
    "#             )\n",
    "\n",
    "#             leu_feat_min, leu_feat_max = torch.as_tensor(params.data.anat_scale_range)\n",
    "#             leu_feat_min = expander(torch.atleast_1d(leu_feat_min))\n",
    "#             leu_feat_max = expander(torch.atleast_1d(leu_feat_max))\n",
    "\n",
    "#             leu_data_min = expander(subj_agg_stats.log_euclid.min)[:, 0][:, None]\n",
    "#             leu_data_max = expander(subj_agg_stats.log_euclid.max)[:, 0][:, None]\n",
    "#             post_log_anat_scaler = pitn.data.norm.MinMaxScaler(\n",
    "#                 feature_min=leu_feat_min,\n",
    "#                 feature_max=leu_feat_max,\n",
    "#                 data_min=leu_data_min,\n",
    "#                 data_max=leu_data_max,\n",
    "#             )\n",
    "\n",
    "#             # Compose them together for the multi-mode input scaling callable.\n",
    "#             net_scalers[\n",
    "#                 \"multi_modal_input_scaler\"\n",
    "#             ] = lambda anat: post_log_anat_scaler.scale_to(\n",
    "#                 torch.log(pre_log_anat_scaler.scale_to(anat).clamp_min(1e-6))\n",
    "#             )\n",
    "\n",
    "#         else:\n",
    "#             feat_min, feat_max = torch.as_tensor(params.data.anat_scale_range)\n",
    "#             feat_min = expander(torch.atleast_1d(feat_min))\n",
    "#             feat_max = expander(torch.atleast_1d(feat_max))\n",
    "#             anat_global_scale_params = pitn.data.norm.GlobalScaleParams(\n",
    "#                 feature_min=feat_min,\n",
    "#                 feature_max=feat_max,\n",
    "#                 data_min=anat_min,\n",
    "#                 data_max=anat_max,\n",
    "#             )\n",
    "#             anat_scaler = pitn.data.norm.MinMaxScaler(\n",
    "#                 feature_min=anat_global_scale_params.feature_min,\n",
    "#                 feature_max=anat_global_scale_params.feature_max,\n",
    "#                 data_min=anat_global_scale_params.data_min,\n",
    "#                 data_max=anat_global_scale_params.data_max,\n",
    "#             )\n",
    "\n",
    "#             net_scalers[\"multi_modal_input_scaler\"] = anat_scaler.scale_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full pytorch-lightning module for contained training, validation, and testing.\n",
    "debug_prob = -1 / (\n",
    "    params.train.samples_per_subj_per_epoch * len(train_subjs) / params.train.batch_size\n",
    ")\n",
    "\n",
    "\n",
    "class DIQTCascadeSystem(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        batch_size: int,\n",
    "        in_patch_shape: tuple,\n",
    "        upscale_factor: int,\n",
    "        train_loss_method: str,\n",
    "        val_subj_ids: tuple,\n",
    "        lambda_dti_stream_loss: float,\n",
    "        psnr_range_params: pitn.data.norm.GlobalScaleParams,\n",
    "        opt_params: dict,\n",
    "        use_log_euclid: bool,\n",
    "        lr_scheduler_name: str = None,\n",
    "        lr_scheduler_kwargs: dict = None,\n",
    "        net_kwargs: dict = dict(),\n",
    "        **hyper_parameters,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(\n",
    "            \"channels\",\n",
    "            \"batch_size\",\n",
    "            \"train_loss_method\",\n",
    "            *list(hyper_parameters.keys()),\n",
    "        )\n",
    "        self._channels = channels\n",
    "        self._batch_size = batch_size\n",
    "        self._in_patch_shape = in_patch_shape\n",
    "        self._upscale_factor = upscale_factor\n",
    "        self.lambda_dti_stream = lambda_dti_stream_loss\n",
    "        self.use_le = use_log_euclid\n",
    "        self._val_viz_subj_id = random.choice(val_subj_ids)\n",
    "        self._psnr_range_params = psnr_range_params\n",
    "        # Coefficients to the log-euclidean lower triangle/6D vector that properly scales\n",
    "        # the Euclidean distance under the log-euclidean metrics.\n",
    "        self.mat_norm_coeffs = torch.ones(6).float()\n",
    "        self.mat_norm_coeffs[torch.as_tensor([1, 3, 4])] = np.sqrt(2)\n",
    "        self.mat_norm_coeffs = mat_norm_coeffs.reshape(-1, 1, 1, 1)\n",
    "        # Parameters\n",
    "        # Network parameters\n",
    "        if self.use_le:\n",
    "            self.net = pitn.nn.sr.CascadeUpsampleAnatRefineLogEuclid(\n",
    "                self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "            )\n",
    "            # raise NotImplementedError(\"ERROR: LE not implemented with anat yet\")\n",
    "            # self.net = pitn.nn.sr.CascadeUpsampleLogEuclid(\n",
    "            #     self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "            # )\n",
    "        else:\n",
    "            self.net = pitn.nn.sr.CascadeUpsampleAnatRefine(\n",
    "                self._channels, upscale_factor=self._upscale_factor, **net_kwargs\n",
    "            )\n",
    "\n",
    "        ## Training parameters\n",
    "        self.opt_params = opt_params\n",
    "        self._lr_scheduler_name = lr_scheduler_name\n",
    "        self.lr_scheduler_kwargs = lr_scheduler_kwargs\n",
    "\n",
    "        # Select loss method as either one of the pre-selected methods, or a custom\n",
    "        # callable.\n",
    "        try:\n",
    "            self._loss_fn = pitn.utils.torch_lookups.loss_fn[\n",
    "                train_loss_method.casefold()\n",
    "            ]()\n",
    "        except (AttributeError, KeyError):\n",
    "            if callable(train_loss_method):\n",
    "                self._loss_fn = train_loss_method\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"ERROR: Invalid loss function specification {train_loss_method}, \"\n",
    "                    + f\"expected one of {pitn.utils.torch_lookups.loss_fn.keys()} \"\n",
    "                    + \"or a callable.\"\n",
    "                )\n",
    "\n",
    "        self._val_subvol_range = dict()\n",
    "\n",
    "        # My own dinky logging object.\n",
    "        self.plain_log = Box(\n",
    "            {\n",
    "                \"train_loss\": list(),\n",
    "                \"val_loss\": {\"rmse\": list(), \"nrmse\": list()},\n",
    "                \"test_loss\": {\n",
    "                    \"rmse\": dict(),\n",
    "                    \"nrmse\": dict(),\n",
    "                    \"rmse_log_euclid\": dict(),\n",
    "                    \"nrmse_log_euclid\": dict(),\n",
    "                    \"scaled_psnr\": dict(),\n",
    "                    \"ssim_fa\": dict(),\n",
    "                    \"rmse_fa\": dict(),\n",
    "                    \"nrmse_fa\": dict(),\n",
    "                },\n",
    "                \"viz\": {\n",
    "                    \"test_preds\": dict(),\n",
    "                    \"test_preds_pre_anat\": dict(),\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        y = self.net(*args, **kwargs)\n",
    "        return y\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.print(f\"\\tStart Epoch {self.current_epoch}\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = Box(batch)\n",
    "        if self.use_le:\n",
    "            x = batch.lr_log_euclid\n",
    "            y = batch.log_euclid\n",
    "            x_scale_kwargs = batch.lr_log_euclid_scale_kwargs\n",
    "            y_scale_kwargs = batch.log_euclid_scale_kwargs\n",
    "        else:\n",
    "            x = batch.lr_dti\n",
    "            y = batch.dti\n",
    "            x_scale_kwargs = batch.lr_dti_scale_kwargs\n",
    "            y_scale_kwargs = batch.dti_scale_kwargs\n",
    "        x_anat = batch.anat\n",
    "        x_anat_scale_kwargs = batch.anat_scale_kwargs\n",
    "        lr_mask = batch.lr_mask.bool()\n",
    "        uncropped_mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(uncropped_mask)\n",
    "\n",
    "        # Determine whether input should be transformed or not.\n",
    "        transform_x = True\n",
    "        if params.use_log_euclid:\n",
    "            transform_x = False\n",
    "            with torch.no_grad():\n",
    "                x = self.net.input_scale_fn(\n",
    "                    x.float(), mask=lr_mask, **x_scale_kwargs\n",
    "                ).float()\n",
    "        # Determine whether to take both outputs according to the lambda loss\n",
    "        # coefficient. If the coefficient is 0, then the stream 1 prediction should not\n",
    "        # even be calculated.\n",
    "        if self.lambda_dti_stream == 0:\n",
    "            return_two_stream = False\n",
    "        else:\n",
    "            return_two_stream = True\n",
    "\n",
    "        y_pred = self.net(\n",
    "            x,\n",
    "            x_anat,\n",
    "            transform_x=transform_x,\n",
    "            transform_x_anat=True,\n",
    "            transform_y=False,\n",
    "            scale_x_kwargs={**x_scale_kwargs, \"mask\": lr_mask},\n",
    "            scale_x_anat_kwargs={**x_anat_scale_kwargs, \"mask\": uncropped_mask},\n",
    "            return_two_stream=return_two_stream,\n",
    "        )\n",
    "\n",
    "        # Calculate loss in the same space as the network prediction for numerical\n",
    "        # stability and convergence during training.\n",
    "        with torch.no_grad():\n",
    "            y = self.net.transform_ground_truth_for_training(\n",
    "                y.float(), crop=True, **y_scale_kwargs, mask=mask\n",
    "            )\n",
    "\n",
    "        if return_two_stream:\n",
    "            y_pred_1, y_pred_2 = y_pred\n",
    "            loss_1 = self._loss_fn(y_pred_1, y, mask=mask)\n",
    "            loss_2 = self._loss_fn(y_pred_2, y, mask=mask)\n",
    "        else:\n",
    "            loss_1 = 0\n",
    "            loss_2 = self._loss_fn(y_pred, y, mask=mask)\n",
    "\n",
    "        loss = (self.lambda_dti_stream * loss_1) + (\n",
    "            (1 - self.lambda_dti_stream) * loss_2\n",
    "        )\n",
    "        self.log(\"train_loss\", loss, batch_size=self._batch_size)\n",
    "        self.log(\n",
    "            \"train/loss_pre_anat\",\n",
    "            loss_1,\n",
    "            batch_size=self._batch_size,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train/loss_post_anat\",\n",
    "            loss_2,\n",
    "            batch_size=self._batch_size,\n",
    "        )\n",
    "\n",
    "        self.plain_log[\"train_loss\"].append(float(loss.detach().cpu()))\n",
    "        if torch.isnan(loss).any().detach().cpu().item():\n",
    "            raise RuntimeError(\"ERROR: Nan loss\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        # Assume batch size of 1 for the validation set.\n",
    "        subj_id = batch.subj_id[0]\n",
    "        x = batch.lr_dti.float()\n",
    "        y = batch.dti.float()\n",
    "        if self.use_le:\n",
    "            x_scale_kwargs = batch.lr_log_euclid_scale_kwargs\n",
    "            y_scale_kwargs = batch.log_euclid_scale_kwargs\n",
    "        else:\n",
    "            x_scale_kwargs = batch.lr_dti_scale_kwargs\n",
    "            y_scale_kwargs = batch.dti_scale_kwargs\n",
    "\n",
    "        x_anat = batch.anat\n",
    "        x_anat_scale_kwargs = batch.anat_scale_kwargs\n",
    "\n",
    "        y = self.net.crop_full_output(y)\n",
    "        uncropped_mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(uncropped_mask)\n",
    "\n",
    "        x_scale_kwargs[\"mask\"] = batch.lr_mask.bool()\n",
    "        x_anat_scale_kwargs[\"mask\"] = uncropped_mask\n",
    "        y_scale_kwargs[\"mask\"] = mask\n",
    "\n",
    "        y_pred_pre_anat, y_pred = self.net(\n",
    "            x,\n",
    "            x_anat,\n",
    "            scale_x_kwargs=x_scale_kwargs,\n",
    "            scale_x_anat_kwargs=x_anat_scale_kwargs,\n",
    "            scale_y_kwargs=y_scale_kwargs,\n",
    "            return_two_stream=True,\n",
    "        )\n",
    "\n",
    "        y_pred_pre_anat = y_pred_pre_anat.float()\n",
    "        y_pred = y_pred.float()\n",
    "\n",
    "        rmse_loss = pitn.nn.loss.dti_root_vec_fro_norm_loss(\n",
    "            y_pred, y, mask=mask, scale_off_diags=True, reduction=\"mean\"\n",
    "        )\n",
    "\n",
    "        nrmse_loss = pitn.metrics.minmax_normalized_dti_root_vec_fro_norm(\n",
    "            y_pred,\n",
    "            y,\n",
    "            mask=mask,\n",
    "            scale_off_diags=True,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        self.log(\"val_loss/nrmse\", nrmse_loss)\n",
    "        self.log(\"val_loss/rmse\", rmse_loss)\n",
    "        self.plain_log.val_loss.nrmse.append(float(nrmse_loss.detach().cpu()))\n",
    "        self.plain_log.val_loss.rmse.append(float(rmse_loss.detach().cpu()))\n",
    "\n",
    "        # Plot visual of validation volume.\n",
    "        if subj_id == self._val_viz_subj_id and not self._val_subvol_range:\n",
    "            # Take range between 1/4 to 3/4 the size of each dimension.\n",
    "            fr_space = np.asarray(y.shape[2:])\n",
    "            fr_low = np.floor(fr_space * 1 / 4).astype(int)\n",
    "            fr_high = np.floor(fr_space * 3 / 4).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                fr_low[0] : fr_high[0], fr_low[1] : fr_high[1], fr_low[2] : fr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"fr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "            lr_space = np.asarray(x.shape[2:])\n",
    "            lr_low = np.floor(lr_space * 1 / 4).astype(int)\n",
    "            lr_high = np.floor(lr_space * 3 / 4).astype(int)\n",
    "            subvol_slice = np.s_[\n",
    "                lr_low[0] : lr_high[0], lr_low[1] : lr_high[1], lr_low[2] : lr_high[2]\n",
    "            ]\n",
    "            self._val_subvol_range[\"lr\"] = (\n",
    "                0,\n",
    "                ...,\n",
    "            ) + subvol_slice\n",
    "\n",
    "        if subj_id == self._val_viz_subj_id:\n",
    "            # breakpoint()\n",
    "            x_subvol = x.detach()[self._val_subvol_range[\"lr\"]].float()\n",
    "            y_subvol = y.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "            pred_pre_anat_subvol = y_pred_pre_anat.detach()[\n",
    "                self._val_subvol_range[\"fr\"]\n",
    "            ].float()\n",
    "            pred_subvol = y_pred.detach()[self._val_subvol_range[\"fr\"]].float()\n",
    "            pre_anat_vs_post_subvol = torch.abs(pred_pre_anat_subvol - pred_subvol)\n",
    "            # x_min = einops.reduce(x_subvol, \"c d h w -> c 1 1 1\", \"min\")\n",
    "            # y_min = einops.reduce(y_subvol, \"c d h w -> c 1 1 1\", \"min\")\n",
    "            # pred_min = einops.reduce(pred_subvol, \"c d h w -> c 1 1 1\", \"min\")\n",
    "            # subvol_min = torch.minimum(x_min, y_min).minimum(pred_min)\n",
    "            # x_max = einops.reduce(x_subvol, \"c d h w -> c 1 1 1\", \"max\")\n",
    "            # y_max = einops.reduce(y_subvol, \"c d h w -> c 1 1 1\", \"max\")\n",
    "            # pred_min = einops.reduce(pred_subvol, \"c d h w -> c 1 1 1\", \"min\")\n",
    "            # subvol_max = torch.maximum(x_max, y_max).maximum(pred_max)\n",
    "            # pred_subvol = pred_subvol.clamp(\n",
    "            #     min=self._val_subvol_min, max=self._val_subvol_min\n",
    "            # )\n",
    "            # pred_pre_anat_subvol = y_pred_pre_anat.detach()[\n",
    "            #     self._val_subvol_range[\"fr\"]\n",
    "            # ].float()\n",
    "            # x_mode_refine_subvol = x_mode_refine.detach()[\n",
    "            #     self._val_subvol_range[\"fr\"]\n",
    "            # ].expand_as(y_subvol)\n",
    "            # mask_subvol = mask.detach()[self._val_subvol_range[\"fr\"]]\n",
    "\n",
    "            # Create grid plot\n",
    "            # Plot settings to propogate into the figure.\n",
    "            with mpl.rc_context(\n",
    "                {\n",
    "                    \"font.size\": 6.0,\n",
    "                    \"axes.labelpad\": 10.0,\n",
    "                    \"figure.autolayout\": False,\n",
    "                    \"figure.constrained_layout.use\": True,\n",
    "                    \"ytick.color\": \"red\",\n",
    "                }\n",
    "            ):\n",
    "                fig = plt.figure(dpi=130, figsize=(6, 4))\n",
    "                channel_names = [\n",
    "                    r\"$D_{x,x}$\",\n",
    "                    r\"$D_{x,y}$\",\n",
    "                    r\"$D_{y,y}$\",\n",
    "                    r\"$D_{x,z}$\",\n",
    "                    r\"$D_{y,z}$\",\n",
    "                    r\"$D_{z,z}$\",\n",
    "                ]\n",
    "                slice_labels = [\n",
    "                    \"\\nAxial\",\n",
    "                    \"\\nCoronal\",\n",
    "                    \"\\nSagg.\",\n",
    "                ]\n",
    "                img_labels = [\n",
    "                    \"GT\",\n",
    "                    \"Pred\",\n",
    "                    \"Pred Pre Anat\",\n",
    "                    \"Input\",\n",
    "                    \"Pre/Post Anat Diff\",\n",
    "                ]\n",
    "                fig = pitn.viz.plot_vol_slices(\n",
    "                    y_subvol,\n",
    "                    pred_subvol,\n",
    "                    pred_pre_anat_subvol,\n",
    "                    x_subvol,\n",
    "                    pre_anat_vs_post_subvol,\n",
    "                    slice_idx=(0.55, None, None),\n",
    "                    title=f\"Subj {subj_id} Step {self.global_step}\",\n",
    "                    vol_labels=img_labels,\n",
    "                    channel_labels=channel_names,\n",
    "                    slice_labels=slice_labels,\n",
    "                    colorbars=\"cols\",\n",
    "                    fig=fig,\n",
    "                    interpolation=\"antialiased\",\n",
    "                    cmap=\"gray\",\n",
    "                )\n",
    "                self.logger.experiment.add_figure(\"val_slice\", fig, self.global_step)\n",
    "\n",
    "        return {\n",
    "            \"rmse\": rmse_loss,\n",
    "            \"nrmse\": nrmse_loss,\n",
    "        }\n",
    "\n",
    "    def on_test_start(self):\n",
    "        # Initialize the metrics as hyperparams so they appear under the tensorboard\n",
    "        # hparams tab. From:\n",
    "        # <https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging-hyperparameters>\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/rmse\": 0,\n",
    "                \"hp/nrmse\": 0,\n",
    "                \"hp/scaled_psnr\": 0,\n",
    "                \"hp/ssim_fa\": 0,\n",
    "                \"hp/rmse_log_euclid\": 0,\n",
    "                \"hp/nrmse_log_euclid\": 0,\n",
    "                \"hp/rmse_fa\": 0,\n",
    "                \"hp/nrmse_fa\": 0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx):\n",
    "\n",
    "        batch = Box(batch)\n",
    "        # Assume batch size of 1.\n",
    "        subj_id = batch.subj_id[0]\n",
    "\n",
    "        # Input\n",
    "        x = batch.lr_dti.float()\n",
    "        log_euclid_x = batch.lr_log_euclid\n",
    "        x_anat = batch.anat\n",
    "\n",
    "        # Mask\n",
    "        uncropped_mask = batch.mask.bool()\n",
    "        mask = self.net.crop_full_output(uncropped_mask)\n",
    "\n",
    "        # Ground truth.\n",
    "        y = batch.dti.float()\n",
    "        y = self.net.crop_full_output(y)\n",
    "        log_euclid_y = batch.log_euclid\n",
    "        log_euclid_y = self.net.crop_full_output(log_euclid_y)\n",
    "        y_fa = pitn.metrics.fast_fa(y, foreground_mask=mask)\n",
    "\n",
    "        # Scale kwargs.\n",
    "        if self.use_le:\n",
    "            x_scale_kwargs = batch.lr_log_euclid_scale_kwargs\n",
    "            y_scale_kwargs = batch.log_euclid_scale_kwargs\n",
    "        else:\n",
    "            x_scale_kwargs = batch.lr_dti_scale_kwargs\n",
    "            y_scale_kwargs = batch.dti_scale_kwargs\n",
    "        x_anat_scale_kwargs = batch.anat_scale_kwargs\n",
    "        x_scale_kwargs[\"mask\"] = batch.lr_mask.bool()\n",
    "        x_anat_scale_kwargs[\"mask\"] = uncropped_mask\n",
    "        y_scale_kwargs[\"mask\"] = mask\n",
    "\n",
    "        # Network predictions\n",
    "        y_pred_pre_anat, y_pred = self.net(\n",
    "            x,\n",
    "            x_anat,\n",
    "            scale_x_kwargs=x_scale_kwargs,\n",
    "            scale_x_anat_kwargs=x_anat_scale_kwargs,\n",
    "            scale_y_kwargs=y_scale_kwargs,\n",
    "            return_two_stream=True,\n",
    "        )\n",
    "        y_pred = y_pred.float()\n",
    "        y_pred_pre_anat = y_pred_pre_anat.float()\n",
    "        # If the network operates on log domain natively, then run another forward pass.\n",
    "        if self.use_le:\n",
    "            log_euclid_y_pred = self.net(\n",
    "                self.net.input_scale_fn(log_euclid_x, **x_scale_kwargs),\n",
    "                x_anat,\n",
    "                transform_x=False,\n",
    "                transform_x_anat=True,\n",
    "                transform_y=False,\n",
    "                scale_x_anat_kwargs=x_anat_scale_kwargs,\n",
    "                return_two_stream=False,\n",
    "            )\n",
    "            log_euclid_y_pred = self.net.output_descale_fn(\n",
    "                log_euclid_y_pred, **y_scale_kwargs\n",
    "            )\n",
    "        # If the network operates in euclidian space natively, then take the original\n",
    "        # prediction and log map it.\n",
    "        else:\n",
    "            log_euclid_y_pred = pitn.eig.tril_vec2sym_mat(y_pred, tril_dim=1)\n",
    "            log_euclid_y_pred = pitn.riemann.log_euclid.log_map(log_euclid_y_pred)\n",
    "            log_euclid_y_pred = pitn.eig.sym_mat2tril_vec(\n",
    "                log_euclid_y_pred, tril_dim=1, dim1=-2, dim2=-1\n",
    "            )\n",
    "            log_euclid_y_pred = log_euclid_y_pred / self.mat_norm_coeffs.to(\n",
    "                log_euclid_y_pred\n",
    "            )\n",
    "\n",
    "        y_pred_fa = pitn.metrics.fast_fa(y_pred, foreground_mask=mask)\n",
    "\n",
    "        # Mask select the target and prediction(s)\n",
    "        # Mask ground truths.\n",
    "        y_select = torch.masked_select(y, mask).view(y.shape[0], y.shape[1], -1)\n",
    "        y_fa_select = torch.masked_select(y_fa, mask).view(\n",
    "            y_fa.shape[0], y_fa.shape[1], -1\n",
    "        )\n",
    "\n",
    "        # Mask predictions.\n",
    "        y_pred_select = torch.masked_select(y_pred, mask).view(\n",
    "            y_pred.shape[0], y_pred.shape[1], -1\n",
    "        )\n",
    "        y_pred_fa_select = torch.masked_select(y_pred_fa, mask).view(\n",
    "            y_pred_fa.shape[0], y_pred_fa.shape[1], -1\n",
    "        )\n",
    "\n",
    "        ###### Calculate network performance metrics.\n",
    "        # MSE metrics.\n",
    "        rmse_loss = pitn.nn.loss.dti_root_vec_fro_norm_loss(\n",
    "            y_pred, y, mask=mask, scale_off_diags=True, reduction=\"mean\"\n",
    "        )\n",
    "        nrmse_loss = pitn.metrics.minmax_normalized_dti_root_vec_fro_norm(\n",
    "            y_pred,\n",
    "            y,\n",
    "            mask=mask,\n",
    "            scale_off_diags=True,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        rmse_log_euclid_loss = pitn.nn.loss.dti_root_vec_fro_norm_loss(\n",
    "            log_euclid_y_pred,\n",
    "            log_euclid_y,\n",
    "            mask=mask,\n",
    "            scale_off_diags=False,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "        nrmse_log_euclid_loss = pitn.metrics.minmax_normalized_dti_root_vec_fro_norm(\n",
    "            log_euclid_y_pred,\n",
    "            log_euclid_y,\n",
    "            mask=mask,\n",
    "            scale_off_diags=False,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # We want to find the *actual* RMSE and NRMSE of the FA maps, because they are\n",
    "        # no longer DTIs.\n",
    "        rmse_fa_loss = torch.sqrt(\n",
    "            F.mse_loss(\n",
    "                y_pred_fa_select,\n",
    "                y_fa_select,\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        nrmse_fa_loss = pitn.metrics.minmax_normalized_rmse(\n",
    "            y_pred_fa_select,\n",
    "            y_fa_select,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # PSNR metric\n",
    "        # Need to reshape the mins and maxes to play nice with the mask-selected tensors.\n",
    "        min_shape_pre = tuple(self._psnr_range_params.data_min.shape[:2])\n",
    "        max_shape_pre = tuple(self._psnr_range_params.data_max.shape[:2])\n",
    "        scaled_psnr_loss = pitn.metrics.psnr_batch_channel_regularized(\n",
    "            y_pred_select,\n",
    "            y_select,\n",
    "            range_min=self._psnr_range_params.data_min.view(*min_shape_pre, -1),\n",
    "            range_max=self._psnr_range_params.data_max.view(*max_shape_pre, -1),\n",
    "        )\n",
    "\n",
    "        # Perceptual metrics\n",
    "        ssim_fa_loss = pitn.metrics.ssim_y_range(\n",
    "            y_pred_fa,\n",
    "            y_fa,\n",
    "        )\n",
    "\n",
    "        # on_epoch and reduce_fx gather the individual test epoch values and aggregate\n",
    "        # them at the end of the testing epoch.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"test_loss/rmse\": rmse_loss,\n",
    "                \"test_loss/nrmse\": nrmse_loss,\n",
    "                \"test_loss/nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "                \"test_loss/rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "                \"test_loss/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"test_loss/ssim_fa\": ssim_fa_loss,\n",
    "                \"test_loss/rmse_fa\": rmse_fa_loss,\n",
    "                \"test_loss/nrmse_fa\": nrmse_fa_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        # Log loss as an hparam metric to be shown alongside the experiment's hparams.\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"hp/rmse\": rmse_loss,\n",
    "                \"hp/nrmse\": nrmse_loss,\n",
    "                \"hp/nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "                \"hp/rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "                \"hp/scaled_psnr\": scaled_psnr_loss,\n",
    "                \"hp/ssim_fa\": ssim_fa_loss,\n",
    "                \"hp/rmse_fa\": rmse_fa_loss,\n",
    "                \"hp/nrmse_fa\": nrmse_fa_loss,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            reduce_fx=torch.mean,\n",
    "        )\n",
    "        self.plain_log.test_loss.rmse[subj_id] = rmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.nrmse[subj_id] = nrmse_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.rmse_log_euclid[subj_id] = (\n",
    "            rmse_log_euclid_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.nrmse_log_euclid[subj_id] = (\n",
    "            nrmse_log_euclid_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.scaled_psnr[subj_id] = (\n",
    "            scaled_psnr_loss.detach().cpu().item()\n",
    "        )\n",
    "        self.plain_log.test_loss.ssim_fa[subj_id] = ssim_fa_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.rmse_fa[subj_id] = rmse_fa_loss.detach().cpu().item()\n",
    "        self.plain_log.test_loss.nrmse_fa[subj_id] = nrmse_fa_loss.detach().cpu().item()\n",
    "\n",
    "        # Store entire predicted DTI for saving & visualization.\n",
    "        self.plain_log.viz.test_preds[subj_id] = y_pred[0].detach().cpu()\n",
    "        # Also store the pre-anat prediction, just in case.\n",
    "        self.plain_log.viz.test_preds_pre_anat[subj_id] = (\n",
    "            y_pred_pre_anat[0].detach().cpu()\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"rmse\": rmse_loss,\n",
    "            \"nrmse\": nrmse_loss,\n",
    "            \"nrmse_log_euclid\": nrmse_log_euclid_loss,\n",
    "            \"rmse_log_euclid\": rmse_log_euclid_loss,\n",
    "            \"scaled_psnr\": scaled_psnr_loss,\n",
    "            \"ssim_fa\": ssim_fa_loss,\n",
    "            \"rmse_fa\": rmse_fa_loss,\n",
    "            \"nrmse_fa\": nrmse_fa_loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.net.parameters(), **self.opt_params)\n",
    "        opt_system = {\"optimizer\": optimizer}\n",
    "\n",
    "        if self._lr_scheduler_name:\n",
    "            lr_scheduler_class = pitn.utils.torch_lookups.lr_scheduler[\n",
    "                self._lr_scheduler_name\n",
    "            ]\n",
    "            if self._lr_scheduler_name.casefold() == \"sequential\":\n",
    "                schedulers = [\n",
    "                    schedule(optimizer)\n",
    "                    for schedule in self.lr_scheduler_kwargs[\"schedulers\"]\n",
    "                ]\n",
    "                scheduler_kwargs = self.lr_scheduler_kwargs.copy()\n",
    "                scheduler_kwargs[\"schedulers\"] = schedulers\n",
    "                lr_scheduler = lr_scheduler_class(optimizer, **scheduler_kwargs)\n",
    "                lr_scheduler.optimizer = optimizer\n",
    "            else:\n",
    "                lr_scheduler = lr_scheduler_class(optimizer, **self.lr_scheduler_kwargs)\n",
    "            # See\n",
    "            # <https://github.com/PyTorchLightning/pytorch-lightning/issues/4576#issuecomment-723648061>\n",
    "            # Interval for the LR stepping needs to be configured here.\n",
    "            # See also\n",
    "            # <https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers>\n",
    "            lr_scheduler_config = {\n",
    "                \"name\": \"lr \" + self._lr_scheduler_name,\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            }\n",
    "            opt_system[\"lr_scheduler\"] = lr_scheduler_config\n",
    "\n",
    "        return opt_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_kwargs: dict = dict()\n",
    "net_kwargs.update(params.net.kwargs)\n",
    "if params.data.scale_method == \"standard\":\n",
    "    scaler = data_scaler_cls()\n",
    "    net_kwargs[\"input_scale_fn\"] = scaler.scale_to\n",
    "    net_kwargs[\"output_descale_fn\"] = scaler.unscale_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start_timestamp = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "model_kwargs = dict(\n",
    "    channels=params.n_channels,\n",
    "    batch_size=params.train.batch_size,\n",
    "    in_patch_shape=params.train.in_patch_size,\n",
    "    lambda_dti_stream_loss=params.train.lambda_dti_stream_loss,\n",
    "    upscale_factor=params.net.upscale_factor,\n",
    "    train_loss_method=params.train.loss_name,\n",
    "    use_log_euclid=params.use_log_euclid,\n",
    "    val_subj_ids=val_subjs,\n",
    "    psnr_range_params=psnr_range_params,\n",
    "    opt_params=params.optim.kwargs,\n",
    "    net_kwargs=net_kwargs,\n",
    ")\n",
    "\n",
    "if \"lr_scheduler\" in params.train and params.train.lr_scheduler:\n",
    "    model_kwargs[\"lr_scheduler_name\"] = params.train.lr_scheduler.name\n",
    "    model_kwargs[\"lr_scheduler_kwargs\"] = params.train.lr_scheduler.kwargs\n",
    "# Update init kwargs with hyperparams, in case there are overlapping names.\n",
    "model_kwargs.update(**hyperparams)\n",
    "\n",
    "# Create model from given kwargs.\n",
    "model = DIQTCascadeSystem(**model_kwargs)\n",
    "\n",
    "# Build up model summary by feeding in some random input. Also initializes the lazy conv\n",
    "# channel sizes, makes it easier to read the logs.\n",
    "with torch.no_grad():\n",
    "    amp_enabled = params.use_half_precision_float\n",
    "    with torch.cuda.amp.autocast(enabled=amp_enabled):\n",
    "        if params.use_log_euclid:\n",
    "            rx = torch.randn_like(train_dataset[0][\"lr_log_euclid\"]).repeat(\n",
    "                params.train.batch_size, 1, 1, 1, 1\n",
    "            )\n",
    "        else:\n",
    "            rx = torch.randn_like(train_dataset[0][\"lr_dti\"]).repeat(\n",
    "                params.train.batch_size, 1, 1, 1, 1\n",
    "            )\n",
    "        rx_anat = torch.randn_like(train_dataset[0][\"anat\"]).repeat(\n",
    "            params.train.batch_size, 1, 1, 1, 1\n",
    "        )\n",
    "\n",
    "        model.net(\n",
    "            rx, rx_anat, transform_x=False, transform_x_anat=False, transform_y=False\n",
    "        )\n",
    "        model_summary = torchinfo.summary(\n",
    "            model.net,\n",
    "            input_data=[rx, rx_anat],\n",
    "            # batch_dim=0,\n",
    "            col_names=(\"output_size\", \"num_params\", \"kernel_size\"),\n",
    "            col_width=30,\n",
    "            depth=10,\n",
    "            row_settings=(\"depth\", \"var_names\"),\n",
    "            device=device,\n",
    "            verbose=0,\n",
    "            transform_x=False,\n",
    "            transform_x_anat=False,\n",
    "            transform_y=False,\n",
    "        )\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Model overview: \\n{model}\\n\\n\")\n",
    "    f.write(\"torchinfo Model Summary: \\n\\n\")\n",
    "    f.write(str(model_summary))\n",
    "    f.write(\"\\n\\n\")\n",
    "\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(\"step\")\n",
    "device_monitor = pl.callbacks.DeviceStatsMonitor()\n",
    "\n",
    "half_precision_kwargs = dict()\n",
    "if params.use_half_precision_float:\n",
    "    half_precision_kwargs[\"precision\"] = 16\n",
    "    half_precision_kwargs[\"amp_backend\"] = \"native\"\n",
    "\n",
    "# Create trainer object.\n",
    "trainer = pl.Trainer(\n",
    "    # fast_dev_run=10,\n",
    "    gpus=[dev_idx],\n",
    "    accelerator=\"gpu\",\n",
    "    enable_checkpointing=False,\n",
    "    max_epochs=params.train.max_epochs,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=50,\n",
    "    # run validation every 0.5 epochs\n",
    "    val_check_interval=0.5,\n",
    "    # max_time={\"hours\": 4, \"minutes\": 30},\n",
    "    # callbacks=[device_monitor],\n",
    "    benchmark=True,\n",
    "    enable_progress_bar=params.progress_bar,\n",
    "    # track_grad_norm=2,\n",
    "    gradient_clip_val=params.train.grad_2norm_clip_val,\n",
    "    accumulate_grad_batches=params.train.accumulate_grad_batches,\n",
    "    **half_precision_kwargs,\n",
    ")\n",
    "\n",
    "# Many warnings are produced here, so it's better for my sanity (i.e., worse in every other\n",
    "# way) to just filter and ignore them...\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "try:\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "except RuntimeError as e:\n",
    "    with open(log_txt_file, \"a+\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"!!!!! Fatal ERROR !!!!!!!\\n\")\n",
    "        f.write(\"Traceback:\\n\")\n",
    "        f.write(str(e) + \"\\n\")\n",
    "        f.write(\"!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "        raise e\n",
    "\n",
    "train_duration = datetime.datetime.now().replace(microsecond=0) - train_start_timestamp\n",
    "print(f\"Train duration: {train_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out trained model\n",
    "trainer.save_checkpoint(str(experiment_results_dir / \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), experiment_results_dir / \"model_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Training time: {train_duration}\\n\")\n",
    "    f.write(\n",
    "        f\"\\t{train_duration.days} Days, \"\n",
    "        + f\"{train_duration.seconds // 3600} Hours,\"\n",
    "        + f\"{(train_duration.seconds // 60) % 60} Minutes,\"\n",
    "        + f'{train_duration.seconds % 60} Seconds\"\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot rolling average window of training loss values.\n",
    "plt.figure(dpi=110)\n",
    "window = 1000\n",
    "rolling_mean = (\n",
    "    np.convolve(model.plain_log[\"train_loss\"], np.ones(window), \"valid\") / window\n",
    ")\n",
    "rolling_start = 100\n",
    "plt.plot(\n",
    "    np.arange(\n",
    "        window + rolling_start,\n",
    "        window + rolling_start + len(rolling_mean[rolling_start:]),\n",
    "    ),\n",
    "    rolling_mean[rolling_start:],\n",
    ")\n",
    "plt.title(\"Training Loss \" + params.train.loss_name + f\"\\nRolling Mean {window}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim(0, 1)\n",
    "print(np.median(rolling_mean))\n",
    "print(\n",
    "    np.mean(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.var(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    "    np.max(model.plain_log[\"train_loss\"][: window + rolling_start]),\n",
    ")\n",
    "\n",
    "plt.savefig(experiment_results_dir / \"train_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mod_state = model.state_dict()\n",
    "\n",
    "# test_mod = DIQTCascadeSystem(\n",
    "#     channels=params.n_channels,\n",
    "#     batch_size=params.train.batch_size,\n",
    "#     in_patch_shape=params.train.in_patch_size,\n",
    "#     upscale_factor=params.net.upscale_factor,\n",
    "#     anat_batch_key=params.data.anat_type,\n",
    "#     train_loss_method=params.train.loss_name,\n",
    "#     opt_params=params.optim.kwargs,\n",
    "#     hparams=hyperparams,\n",
    "#     **params.net.kwargs,\n",
    "# )\n",
    "# test_mod.load_state_dict(mod_state)\n",
    "# trainer.test(test_mod, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader, ckpt_path=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_losses = (\n",
    "    \"rmse\",\n",
    "    \"nrmse\",\n",
    "    \"rmse_log_euclid\",\n",
    "    \"nrmse_log_euclid\",\n",
    "    \"scaled_psnr\",\n",
    "    \"ssim_fa\",\n",
    "    \"rmse_fa\",\n",
    "    \"nrmse_fa\",\n",
    ")\n",
    "loss_comparison_directions = {\n",
    "    \"rmse\": \"↓\",\n",
    "    \"nrmse\": \"↓\",\n",
    "    \"rmse_log_euclid\": \"↓\",\n",
    "    \"nrmse_log_euclid\": \"↓\",\n",
    "    \"scaled_psnr\": \"↑\",\n",
    "    \"ssim_fa\": \"↑\",\n",
    "    \"rmse_fa\": \"↓\",\n",
    "    \"nrmse_fa\": \"↓\",\n",
    "}\n",
    "\n",
    "test_results = Box(subj_id=list(), model=list(), metric=list(), value=list())\n",
    "for subj_id in test_subjs:\n",
    "    for metric in test_losses:\n",
    "        # DIQT model\n",
    "        test_results.subj_id.append(subj_id)\n",
    "        test_results.model.append(\"diqt\")\n",
    "        test_results.metric.append(metric)\n",
    "        test_results.value.append(model.plain_log.test_loss[metric][subj_id])\n",
    "\n",
    "# Convert to a pandas dataframe.\n",
    "test_results = pd.DataFrame(test_results.to_dict())\n",
    "\n",
    "with open(log_txt_file, \"a+\") as f:\n",
    "    f.write(f\"Test loss functions: {list(test_losses)}\\n\")\n",
    "\n",
    "test_loss_log_file = experiment_results_dir / \"test_loss.csv\"\n",
    "test_results.to_csv(test_loss_log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison within experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 8.0,\n",
    "    }\n",
    "):\n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=len(test_losses),\n",
    "        sharex=True,\n",
    "        figsize=(11, 4),\n",
    "        dpi=130,\n",
    "        gridspec_kw={\"wspace\": 1.0, \"hspace\": 0},\n",
    "    )\n",
    "    sns.despine(fig=fig, top=True, right=True)\n",
    "\n",
    "    for i, l in enumerate(test_losses):\n",
    "\n",
    "        ax = axs[i]\n",
    "        df = test_results.loc[test_results.metric == l]\n",
    "        vplot = sns.violinplot(\n",
    "            x=\"model\", y=\"value\", data=df, ax=ax, scale=\"count\", inner=None\n",
    "        )\n",
    "        axs[i].grid(axis=\"y\", alpha=0.5)\n",
    "        points_plot = sns.swarmplot(\n",
    "            x=\"model\",\n",
    "            y=\"value\",\n",
    "            hue=\"subj_id\",\n",
    "            data=df,\n",
    "            ax=ax,\n",
    "            # color=\"white\",\n",
    "            edgecolor=\"black\",\n",
    "            size=4,\n",
    "            linewidth=0.8,\n",
    "        )\n",
    "        points_plot.get_legend().remove()\n",
    "\n",
    "        # Calculate mean performance score.\n",
    "        means = df.groupby(\"model\").mean()\n",
    "        # Make sure the order follows seaborn's x-axis ordering.\n",
    "        model_order = list(map(lambda ax: ax.get_text(), axs[i].get_xticklabels()))\n",
    "        means = means.reindex(model_order)\n",
    "\n",
    "        # Grab colors corresponding to each model.\n",
    "        colors = sns.color_palette(None, n_colors=len(df.model.unique()))\n",
    "\n",
    "        lines = ax.hlines(\n",
    "            y=means.value,\n",
    "            xmin=np.arange(0, len(colors)) - 0.5 + 0.05,\n",
    "            xmax=np.arange(1, len(colors) + 1) - 0.5 - 0.05,\n",
    "            colors=colors,\n",
    "            lw=1.5,\n",
    "        )\n",
    "\n",
    "        outline_path_effects = [\n",
    "            mpl.patheffects.Stroke(linewidth=5, foreground=\"white\", alpha=0.9),\n",
    "            mpl.patheffects.Normal(),\n",
    "        ]\n",
    "        lines.set_path_effects(outline_path_effects)\n",
    "\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=25)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        ax_format = ax.get_yaxis().get_major_formatter()\n",
    "\n",
    "        for m, c in zip(means.value, colors):\n",
    "\n",
    "            ax.annotate(\n",
    "                f\"{m:.4g}\",\n",
    "                xy=(ax.get_xlim()[0] + (ax.get_xlim()[0] * 0.4), m),\n",
    "                xycoords=\"data\",\n",
    "                color=c,\n",
    "                ha=\"right\",\n",
    "                va=\"center\",\n",
    "                annotation_clip=False,\n",
    "                fontweight=\"bold\",\n",
    "                snap=True,\n",
    "                bbox=dict(\n",
    "                    boxstyle=\"square,pad=0.3\", fc=\"white\", lw=0, snap=True, alpha=0.75\n",
    "                ),\n",
    "            )\n",
    "        ax.set_title(f\"{l.replace('_', ' ')} {loss_comparison_directions[l]}\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(\"\")\n",
    "plt.savefig(experiment_results_dir / \"test_result_within_experiment.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with other works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all patches.\n",
    "fig, ax_prob = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "log_scale = False\n",
    "\n",
    "hist = sns.histplot(\n",
    "    list(model.plain_log[\"test_loss\"].rmse.values()),\n",
    "    alpha=0.5,\n",
    "    stat=\"count\",\n",
    "    log_scale=log_scale,\n",
    "    ax=ax_prob,\n",
    "    legend=False,\n",
    "    hatch=\"\\\\\\\\\",\n",
    "    ec=\"blue\",\n",
    ")\n",
    "hist.yaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "plt.xlabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "# Draw means of different comparison models.\n",
    "comparison_kwargs = {\"ls\": \"-\", \"lw\": 2.5}\n",
    "# Plot the current DNN model performance.\n",
    "plt.axvline(\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    label=\"Current Model Mean\",\n",
    "    color=\"blue\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    9.72e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    color=\"green\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "plt.axvline(\n",
    "    9.76e-4,\n",
    "    label=\"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nBest ESPCN\\n[but not really]\",\n",
    "    color=\"purple\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "# Best performing Blumberg, et. al., 2018 paper model.\n",
    "plt.axvline(\n",
    "    8.46e-4,\n",
    "    label=\"(Blumberg etal, 2018)\\nBest Overall\",\n",
    "    color=\"pink\",\n",
    "    **comparison_kwargs,\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.title(\"Test Loss Histogram Over All Subjects with Test Metric RMSE\")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot testing loss values over all subjects.\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=120)\n",
    "\n",
    "models = (\n",
    "    \"(Ours)\\nCurrent Model\",\n",
    "    \"(Tanno etal, 2021)\\nC-Spline\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2021)\\nRand. Forest\\nMean Approx.\",\n",
    "    \"(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\nESPCN Baseline\",\n",
    "    '(Tanno etal, 2017 &\\n Blumberg etal, 2018)\\n\"Best\" ESPCN',\n",
    "    \"(Blumberg etal, 2018)\\nBest Overall\",\n",
    ")\n",
    "\n",
    "rmse_bounds = np.asarray(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [31.738e-4, 10.069e-4],\n",
    "        [23.139e-4, 6.974e-4],\n",
    "        [13.609e-4, 6.212e-4],\n",
    "        [13.82e-4, 6.29e-4],\n",
    "        [12.13e-4, 5.58e-4],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rmse_scores = (\n",
    "    np.asarray(list(model.plain_log[\"test_loss\"].rmse.values())).mean(),\n",
    "    rmse_bounds[2].mean(),\n",
    "    rmse_bounds[3].mean(),\n",
    "    9.72e-4,\n",
    "    9.76e-4,\n",
    "    8.46e-4,\n",
    ")\n",
    "\n",
    "rmse_score_ranges = np.asarray(rmse_scores)[:, None] - rmse_bounds\n",
    "rmse_score_ranges[:1] = rmse_score_ranges[:1] * 0\n",
    "rmse_score_ranges = rmse_score_ranges.T\n",
    "\n",
    "colors = sns.color_palette(\"deep\", n_colors=len(rmse_scores))\n",
    "\n",
    "ax.grid(True, axis=\"y\", zorder=1000)\n",
    "ax.set_axisbelow(True)\n",
    "# Plot our evaluation scores.\n",
    "end_idx = 2\n",
    "ax.bar(\n",
    "    models[:end_idx],\n",
    "    rmse_scores[:end_idx],\n",
    "    color=colors[:end_idx],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    ")\n",
    "for container in ax.containers:\n",
    "    if isinstance(container, mpl.container.BarContainer):\n",
    "        ax.bar_label(container, fmt=\"%.3e\")\n",
    "\n",
    "\n",
    "start_idx = end_idx\n",
    "# Plot the crazy evaluation scores.\n",
    "ax.bar(\n",
    "    models[start_idx:],\n",
    "    height=rmse_bounds[start_idx:, 0] - rmse_bounds[start_idx:, 1],\n",
    "    bottom=rmse_bounds[start_idx:, 1],\n",
    "    color=colors[start_idx:],\n",
    "    edgecolor=\"black\",\n",
    "    lw=0.75,\n",
    "    alpha=0.8,\n",
    ")\n",
    "end_idx = start_idx + 2\n",
    "bar_width = ax.patches[0].get_width()\n",
    "# Dotted lines for the \"approximate\" actual rmse score.\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:end_idx],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"--\",\n",
    ")\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "start_idx = end_idx\n",
    "end_idx = len(models)\n",
    "ax.hlines(\n",
    "    rmse_scores[start_idx:],\n",
    "    xmin=np.arange(start_idx, end_idx) - bar_width / 2,\n",
    "    xmax=np.arange(start_idx, end_idx) + bar_width / 2,\n",
    "    color=\"black\",\n",
    "    ls=\"-\",\n",
    ")\n",
    "\n",
    "for score, x in zip(\n",
    "    rmse_scores[start_idx:end_idx], np.arange(start_idx, end_idx) - bar_width / 2\n",
    "):\n",
    "    ax.annotate(f\"{score:.3e}\", (x, score + 0.03 * np.asarray(rmse_scores).max()))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.1)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss in $mm^2/second$\")\n",
    "\n",
    "ax.set_title(\"Mean Over Subjects Test Loss RMSE\")\n",
    "ax.set_xticks(models)\n",
    "ax.set_xticklabels(\n",
    "    models, fontsize=\"x-small\", rotation=25, ha=\"right\", rotation_mode=\"anchor\"\n",
    ")\n",
    "plt.savefig(experiment_results_dir / \"test_rmse_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_test_idx = np.argsort(np.asarray(list(model.plain_log.test_loss.rmse.values())))\n",
    "sorted_test_results = dict(\n",
    "    list(model.plain_log.test_loss.rmse.items())[i] for i in sorted_test_idx\n",
    ")\n",
    "ppr(sorted_test_results, sort_dicts=False)\n",
    "print(np.mean(list(list(model.plain_log.test_loss.rmse.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diqt_results = test_results.loc[test_results.model == \"diqt\"]\n",
    "\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_dist\", np.asarray(diqt_results.loc[diqt_results.metric == \"rmse\"].value)\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_log_euclid_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"rmse_log_euclid\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_log_euclid_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse_log_euclid\"].value),\n",
    ")\n",
    "\n",
    "logger.add_histogram(\n",
    "    \"test/scaled_psnr_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"scaled_psnr\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/ssim_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"ssim_fa\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/rmse_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"rmse_fa\"].value),\n",
    ")\n",
    "logger.add_histogram(\n",
    "    \"test/nrmse_fa_dist\",\n",
    "    np.asarray(diqt_results.loc[diqt_results.metric == \"nrmse_fa\"].value),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole-Volume Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debug flag(s)\n",
    "disable_fig_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full 3D volumes of full-res ground truth, low-res downsample, full-res mask,\n",
    "# anatomical image, and full-res predictions.\n",
    "\n",
    "results_viz = Box(default_box=True)\n",
    "with torch.no_grad():\n",
    "\n",
    "    for subj in test_dataset:\n",
    "        # Index into the only item in the subject dataset.\n",
    "        s = Box(default_box=True)\n",
    "        subj_id = subj[\"subj_id\"]\n",
    "        print(f\"Starting subject {subj_id}\")\n",
    "\n",
    "        # Collect all variants of the volume and aggregate into one container object.\n",
    "        s.mask = model.net.crop_full_output(subj[\"mask\"])\n",
    "        s.dti = model.net.crop_full_output(subj[\"dti\"])\n",
    "        s.affine = subj[\"dti_meta_dict\"][\"affine\"]\n",
    "        s.lr_dti = subj[\"lr_dti\"]\n",
    "\n",
    "        s.pred = model.plain_log.viz.test_preds[subj_id]\n",
    "        s.pred_pre_anat = model.plain_log.viz.test_preds_pre_anat[subj_id]\n",
    "\n",
    "        s.dti = s.dti * s.mask\n",
    "        s.pred = s.pred * s.mask\n",
    "        s.metrics.rmse = model.plain_log.test_loss.rmse[subj_id]\n",
    "        s.abs_error = torch.abs(s.pred - s.dti)\n",
    "\n",
    "        for k in {\n",
    "            \"mask\",\n",
    "            \"dti\",\n",
    "            \"lr_dti\",\n",
    "            \"pred\",\n",
    "            \"pred_pre_anat\",\n",
    "            \"abs_error\",\n",
    "        }:\n",
    "            v = s[k]\n",
    "            if torch.is_tensor(v):\n",
    "                v = v.detach().cpu().numpy()\n",
    "            if k == \"mask\":\n",
    "                v = v.astype(bool)\n",
    "            else:\n",
    "                v = v.astype(float)\n",
    "            # s[k] = np.rot90(v)\n",
    "            s[k] = v\n",
    "\n",
    "        results_viz[subj_id] = s\n",
    "        print(f\"Finished subject {subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out all network predictions to Nifti2 files and compress them into a zip archive.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.pred, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(experiment_results_dir / \"predicted_dti.zip\", \"w\") as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=7,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "\n",
    "# And the pre-anat predictions.\n",
    "if not disable_fig_save:\n",
    "    img_names = list()\n",
    "    for subj_id, viz in results_viz.items():\n",
    "        nib_img = nib.Nifti2Image(viz.pred_pre_anat, viz.affine)\n",
    "\n",
    "        filename = experiment_results_dir / f\"{subj_id}_predicted_pre_anat_dti.nii.gz\"\n",
    "        nib.save(nib_img, str(filename))\n",
    "        img_names.append(filename)\n",
    "\n",
    "    with zipfile.ZipFile(\n",
    "        experiment_results_dir / \"predicted_pre_anat_dti.zip\", \"w\"\n",
    "    ) as fzip:\n",
    "        for filename in img_names:\n",
    "            fzip.write(\n",
    "                filename,\n",
    "                arcname=filename.name,\n",
    "                compress_type=zipfile.ZIP_DEFLATED,\n",
    "                compresslevel=7,\n",
    "            )\n",
    "            os.remove(filename)\n",
    "    # Make sure we exit the 'with' statement above.\n",
    "    print(\"Done with files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick the worst performing subject from the test set to visualize.\n",
    "sel_rmse = test_results.loc[\n",
    "    (test_results.model == \"diqt\") & (test_results.metric == \"rmse\")\n",
    "][[\"subj_id\", \"value\"]]\n",
    "sel_rmse = sel_rmse.sort_values(\"value\")\n",
    "# Or 2nd worst performing...\n",
    "bad_rmse = sel_rmse.iloc[-2]\n",
    "viz_subj_id = bad_rmse.subj_id\n",
    "print(viz_subj_id, bad_rmse.value)\n",
    "viz_subj = results_viz[viz_subj_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select indices for visualizing.\n",
    "dti_shape = np.asarray(viz_subj.dti.shape[1:])\n",
    "lr_dti_shape = np.asarray(viz_subj.lr_dti.shape[1:])\n",
    "\n",
    "viz_idx = dti_shape // 2\n",
    "# Last dimension (saggital) shouldn't be exactly centered, as the longitudinal fissure\n",
    "# doesn't have many fibers outside the corpus collosum.\n",
    "viz_idx[2] = viz_idx[2] + 6\n",
    "viz_lr_idx = lr_dti_shape // 2\n",
    "viz_lr_idx[2] = viz_lr_idx[2] + 6 // params.data.downsampled_by_factor\n",
    "\n",
    "viz_slice_idx = [\n",
    "    np.s_[:, viz_idx[0], :, :],\n",
    "    np.s_[:, :, viz_idx[1], :],\n",
    "    np.s_[:, :, :, viz_idx[2]],\n",
    "]\n",
    "\n",
    "viz_lr_slice_idx = [\n",
    "    np.s_[:, viz_lr_idx[0], :, :],\n",
    "    np.s_[:, :, viz_lr_idx[1], :],\n",
    "    np.s_[:, :, :, viz_lr_idx[2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FA-Weighted Direction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ims = list()\n",
    "for im, slices in zip(\n",
    "    [viz_subj.dti, viz_subj.pred, viz_subj.lr_dti],\n",
    "    (viz_slice_idx, viz_slice_idx, viz_lr_slice_idx),\n",
    "):\n",
    "    for sl in slices:\n",
    "        selection = im[sl]\n",
    "        fa_w = pitn.viz.direction_map(selection, channels_first=True)\n",
    "        fa_w = fa_w.transpose(1, 2, 0)\n",
    "        ims.append(fa_w)\n",
    "\n",
    "dim_labels = [\n",
    "    \"Axial\",\n",
    "    \"Coronal\",\n",
    "    \"Saggital\",\n",
    "]\n",
    "vol_labels = [\"Ground Truth\", \"Pred\", \"LR Input\"]\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 12.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=130, figsize=(7, 7))\n",
    "    fig = pitn.viz.plot_im_grid(\n",
    "        ims,\n",
    "        nrows=len(vol_labels),\n",
    "        title=f\"Subj {viz_subj_id} Prediction Results\",\n",
    "        row_headers=vol_labels,\n",
    "        col_headers=dim_labels,\n",
    "        colorbars=None,\n",
    "        fig=fig,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / \"dir_map_pred.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DTI Channel-Wise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"$D_{x,x}$\",\n",
    "    \"$D_{x,y}$\",\n",
    "    \"$D_{y,y}$\",\n",
    "    \"$D_{x,z}$\",\n",
    "    \"$D_{y,z}$\",\n",
    "    \"$D_{z,z}$\",\n",
    "]\n",
    "\n",
    "dim_labels = [\n",
    "    \"\\nAxial\",\n",
    "    \"\\nCor.\",\n",
    "    \"\\nSagg.\",\n",
    "]\n",
    "\n",
    "dti_names = [\n",
    "    \"FR\",\n",
    "    \"Pred\",\n",
    "    \"LR\",\n",
    "    \"Abs Err\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all 6 DTIs for ground truth, predicted, and root squared error\n",
    "cmap = \"gray\"\n",
    "title = f\"DTI Subj {viz_subj_id} Summary\"\n",
    "\n",
    "with mpl.rc_context(\n",
    "    {\n",
    "        \"font.size\": 6.0,\n",
    "        \"axes.labelpad\": 10.0,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "    }\n",
    "):\n",
    "    fig = plt.figure(dpi=150, figsize=(8, 12))\n",
    "    fig = pitn.viz.plot_vol_slices(\n",
    "        viz_subj.dti,\n",
    "        viz_subj.pred,\n",
    "        viz_subj.lr_dti,\n",
    "        viz_subj.abs_error,\n",
    "        slice_idx=(None, None, viz_idx[2] / dti_shape[2]),\n",
    "        title=title,\n",
    "        vol_labels=dti_names,\n",
    "        slice_labels=dim_labels,\n",
    "        channel_labels=channel_names,\n",
    "        colorbars=\"col\",\n",
    "        fig=fig,\n",
    "        cmap=cmap,\n",
    "        interpolation=\"antialiased\",\n",
    "    )\n",
    "\n",
    "\n",
    "if not disable_fig_save:\n",
    "    plt.savefig(experiment_results_dir / f\"DIQT_DTI_sub-{viz_subj_id}_pred_result.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel-Wise Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_logger.experiment.flush()\n",
    "# Close tensorboard logger.\n",
    "# Don't finalize if the experiment was for debugging.\n",
    "if \"debug\" not in EXPERIMENT_NAME.casefold():\n",
    "    pl_logger.finalize(\"success\")\n",
    "    # Experiment is complete, move the results directory to its final location.\n",
    "    if experiment_results_dir != final_experiment_results_dir:\n",
    "        print(\"Moving out of tmp location\")\n",
    "        experiment_results_dir = experiment_results_dir.rename(\n",
    "            final_experiment_results_dir\n",
    "        )\n",
    "        log_txt_file = experiment_results_dir / log_txt_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for subj_id in test_subjs[:5]:\n",
    "#     gt_dti = subj_data[subj_id][0]['dti'][None,]\n",
    "#     mask = subj_data[subj_id][0]['mask'][None,]\n",
    "#     pred_dti = model.plain_log.viz.test_preds[subj_id][None]\n",
    "\n",
    "#     gt_fa = pitn.metrics.fast_fa(gt_dti, mask)\n",
    "#     pred_fa = pitn.metrics.fast_fa(pred_dti, mask)\n",
    "\n",
    "#     gt_select = torch.masked_select(gt_fa, mask)\n",
    "#     pred_select = torch.masked_select(pred_fa, mask)\n",
    "\n",
    "#     diff = gt_select - pred_select\n",
    "#     diff = diff.detach().cpu().numpy().flatten()\n",
    "#     sns.histplot(diff)\n",
    "#     print((diff == 0).sum())\n",
    "#     print(diff.mean())\n",
    "#     print(np.std(diff))\n",
    "\n",
    "#     plt.title(subj_id)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run_dir = experiment_results_dir.parent / \"2022-03-01T06_58_21__pitn_dti_mid_net\"\n",
    "# pred_dir = run_dir / \"predicted_dti\"\n",
    "# dti_only_test_subj_files = list(pred_dir.glob('[0-9]*'))\n",
    "# dti_only_ids = [d.name[:6] for d in dti_only_test_subj_files]\n",
    "# print(dti_only_ids)\n",
    "\n",
    "# for subj_id in dti_only_ids[:5]:\n",
    "#     gt_dti = subj_data[subj_id][0]['dti'][None]\n",
    "#     mask = subj_data[subj_id][0]['mask'][None]\n",
    "\n",
    "#     pred_dti = nib.load(list(pred_dir.glob(subj_id + \"*\"))[0])\n",
    "#     pred_dti = pred_dti.get_fdata()[None]\n",
    "#     pred_dti = torch.from_numpy(pred_dti)\n",
    "#     gt_fa = pitn.metrics.fast_fa(gt_dti, mask)\n",
    "#     pred_fa = pitn.metrics.fast_fa(pred_dti, mask)\n",
    "\n",
    "#     gt_select = torch.masked_select(gt_fa, mask)\n",
    "#     pred_select = torch.masked_select(pred_fa, mask)\n",
    "#     plt.imshow(gt_fa[0, 0, :, 80] - pred_fa[0, 0, :, 80], cmap='gray')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "#     diff = gt_select - pred_select\n",
    "#     diff = diff.detach().cpu().numpy().flatten()\n",
    "#     print((diff == 0).sum())\n",
    "#     sns.histplot(diff)\n",
    "#     print(diff.mean())\n",
    "#     print(np.std(diff))\n",
    "#     plt.title(subj_id)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gt_fa.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02b6fbf192f5f02a9e4be2e8493e981ac4440e63c59c4307b81de14e51e6a1b0"
  },
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
