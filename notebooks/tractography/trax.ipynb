{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import functools\n",
    "from functools import partial\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Change default behavior of jax GPU memory allocation.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".20\"\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "import einops\n",
    "import monai\n",
    "import dipy\n",
    "import dipy.reconst\n",
    "import dipy.reconst.csdeconv, dipy.reconst.shm, dipy.viz\n",
    "import dipy.denoise\n",
    "import dipy.io\n",
    "import dipy.io.streamline\n",
    "import nibabel as nib\n",
    "\n",
    "import jax\n",
    "import jax.config\n",
    "\n",
    "# Disable jit for debugging.\n",
    "# jax.config.update(\"jax_disable_jit\", True)\n",
    "# Enable 64-bit precision.\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update(\"jax_default_matmul_precision\", 32)\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import jax.dlpack\n",
    "\n",
    "import pitn\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "plt.rcParams.update({\"image.cmap\": \"gray\"})\n",
    "plt.rcParams.update({\"image.interpolation\": \"antialiased\"})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    # Pick only one device for the default, may use multiple GPUs for training later.\n",
    "    dev_idx = 0\n",
    "    device = torch.device(f\"cuda:{dev_idx}\")\n",
    "    print(\"CUDA Device IDX \", dev_idx)\n",
    "    torch.cuda.set_device(device)\n",
    "    print(\"CUDA Current Device \", torch.cuda.current_device())\n",
    "    print(\"CUDA Device properties: \", torch.cuda.get_device_properties(device))\n",
    "    # The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n",
    "    # in PyTorch 1.12 and later.\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # See\n",
    "    # <https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices>\n",
    "    # for details.\n",
    "\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "        # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_full_res_data_dir = Path(\"/data/srv/data/pitn/hcp\")\n",
    "hcp_full_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/full-res/fodf\")\n",
    "hcp_low_res_data_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/vol\")\n",
    "hcp_low_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/fodf\")\n",
    "\n",
    "assert hcp_full_res_data_dir.exists()\n",
    "assert hcp_full_res_fodf_dir.exists()\n",
    "assert hcp_low_res_data_dir.exists()\n",
    "assert hcp_low_res_fodf_dir.exists()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed-Based Tractography Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data & Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fod_f = (\n",
    "    hcp_full_res_fodf_dir / \"162329\" / \"T1w\" / \"postproc_wm_msmt_csd_fod.nii.gz\"\n",
    ")\n",
    "fod_coeff_im = nib.load(sample_fod_f)\n",
    "fod_coeff_im = nib.as_closest_canonical(fod_coeff_im)\n",
    "print(\"Original shape\", fod_coeff_im.shape)\n",
    "print(\"Original affine\", fod_coeff_im.affine)\n",
    "mask_f = sample_fod_f.parent / \"postproc_nodif_brain_mask.nii.gz\"\n",
    "mask_im = nib.load(mask_f)\n",
    "mask_im = nib.as_closest_canonical(mask_im)\n",
    "white_matter_mask_f = sample_fod_f.parent / \"postproc_5tt_parcellation.nii.gz\"\n",
    "wm_mask_im = nib.load(white_matter_mask_f)\n",
    "wm_mask_im = nib.as_closest_canonical(wm_mask_im)\n",
    "wm_mask_im = wm_mask_im.slicer[..., 2]\n",
    "\n",
    "# Pre-select voxels of interest in RAS+ space for this specific subject.\n",
    "# CC forceps minor, strong L-R uni-modal lobe\n",
    "cc_lr_lobe_idx = (55, 98, 53)\n",
    "# Dual-polar approx. equal volume fiber crossing\n",
    "lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "# Vox. adjacent to CST, tri-polar\n",
    "tri_polar_lobe_idx = (60, 68, 43)\n",
    "\n",
    "\n",
    "# Re-orient volumes from RAS to SAR (xyz -> zyx)\n",
    "nib_affine_vox2ras_mm = fod_coeff_im.affine\n",
    "affine_ras_vox2ras_mm = torch.from_numpy(nib_affine_vox2ras_mm).to(device)\n",
    "ornt_ras = nib.orientations.io_orientation(nib_affine_vox2ras_mm)\n",
    "ornt_sar = nib.orientations.axcodes2ornt((\"S\", \"A\", \"R\"))\n",
    "ornt_ras2sar = nib.orientations.ornt_transform(ornt_ras, ornt_sar)\n",
    "# We also need an affine that maps from SAR -> RAS\n",
    "affine_sar2ras = nib.orientations.inv_ornt_aff(\n",
    "    ornt_ras2sar, tuple(fod_coeff_im.shape[:-1])\n",
    ")\n",
    "affine_sar2ras = torch.from_numpy(affine_sar2ras).to(affine_ras_vox2ras_mm)\n",
    "affine_ras2sar = torch.linalg.inv(affine_sar2ras)\n",
    "\n",
    "# This essentially just flips the translation vector in the affine matrix. It may be\n",
    "# \"RAS\" relative to the object/volume itself, but it is \"SAR\" relative to the original\n",
    "# ordering of the dimensions in the data.\n",
    "affine_sar_vox2sar_mm = affine_ras2sar @ (affine_ras_vox2ras_mm @ affine_sar2ras)\n",
    "\n",
    "# Swap spatial dimensions, assign a new vox->world affine space.\n",
    "sar_fod = einops.rearrange(fod_coeff_im.get_fdata(), \"x y z coeffs -> z y x coeffs\")\n",
    "fod_coeff_im = nib.Nifti1Image(\n",
    "    sar_fod,\n",
    "    affine=(affine_sar_vox2sar_mm).cpu().numpy(),\n",
    "    header=fod_coeff_im.header,\n",
    ")\n",
    "sar_mask = einops.rearrange(mask_im.get_fdata().astype(bool), \"x y z -> z y x\")\n",
    "mask_im = nib.Nifti1Image(\n",
    "    sar_mask,\n",
    "    affine=(affine_sar_vox2sar_mm).cpu().numpy(),\n",
    "    header=mask_im.header,\n",
    ")\n",
    "sar_wm_mask = einops.rearrange(wm_mask_im.get_fdata().astype(bool), \"x y z -> z y x\")\n",
    "wm_mask_im = nib.Nifti1Image(\n",
    "    sar_wm_mask,\n",
    "    affine=(affine_sar_vox2sar_mm).cpu().numpy(),\n",
    "    header=wm_mask_im.header,\n",
    ")\n",
    "\n",
    "print(fod_coeff_im.affine)\n",
    "print(fod_coeff_im.shape)\n",
    "print(mask_im.affine)\n",
    "print(mask_im.shape)\n",
    "\n",
    "# Flip the pre-selected voxels.\n",
    "sar_vox_idx = pitn.affine.coord_transform_3d(\n",
    "    affine_ras2sar.new_tensor(\n",
    "        [cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx]\n",
    "    ),\n",
    "    affine_ras2sar,\n",
    ")\n",
    "cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx = tuple(\n",
    "    sar_vox_idx.int().cpu().tolist()\n",
    ")\n",
    "cc_lr_lobe_idx = tuple(cc_lr_lobe_idx)\n",
    "lr_and_ap_bipolar_lobe_idx = tuple(lr_and_ap_bipolar_lobe_idx)\n",
    "tri_polar_lobe_idx = tuple(tri_polar_lobe_idx)\n",
    "print(cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = fod_coeff_im.get_fdata()\n",
    "coeffs = torch.from_numpy(coeffs).to(device)\n",
    "fod_coeff_im.uncache()\n",
    "# Move to channels-first layout.\n",
    "coeffs = einops.rearrange(coeffs, \"z y x coeffs -> coeffs z y x\")\n",
    "brain_mask = mask_im.get_fdata().astype(bool)\n",
    "brain_mask = torch.from_numpy(brain_mask).to(device)\n",
    "mask_im.uncache()\n",
    "brain_mask = einops.rearrange(brain_mask, \"z y x -> 1 z y x\")\n",
    "wm_mask = torch.from_numpy(wm_mask_im.get_fdata().astype(bool)).to(device)\n",
    "wm_mask = einops.rearrange(wm_mask, \"z y x -> 1 z y x\")\n",
    "wm_mask_im.uncache()\n",
    "seed_mask = torch.zeros_like(brain_mask).bool()\n",
    "\n",
    "select_vox_idx = cc_lr_lobe_idx\n",
    "# select_vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# select_vox_idx = tri_polar_lobe_idx\n",
    "seed_mask[0, select_vox_idx[0], select_vox_idx[1], select_vox_idx[2]] = True\n",
    "\n",
    "print(coeffs.shape)\n",
    "print(brain_mask.shape)\n",
    "print(seed_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion200\"))\n",
    "sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion724\"))\n",
    "\n",
    "theta, phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "\n",
    "nearest_sphere_samples = pitn.odf.adjacent_sphere_points_idx(theta=theta, phi=phi)\n",
    "nearest_sphere_samples_idx = nearest_sphere_samples[0]\n",
    "nearest_sphere_samples_valid_mask = nearest_sphere_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sh_order = 8\n",
    "\n",
    "# Element-wise filtering of sphere samples.\n",
    "min_sample_pdf_threshold = 0.0001\n",
    "\n",
    "# Threshold parameter for FMLS segmentation.\n",
    "lobe_merge_ratio = 0.8\n",
    "# Post-segmentation label filtering.\n",
    "min_lobe_pdf_peak_threshold = 1e-5\n",
    "min_lobe_pdf_integral_threshold = 0.05\n",
    "\n",
    "# Seed creation.\n",
    "peaks_per_seed_vox = 3\n",
    "seed_batch_size = 2\n",
    "# Total seeds per voxel will be `seeds_per_vox_axis`^3\n",
    "seeds_per_vox_axis = 1\n",
    "\n",
    "# RK4 estimation\n",
    "step_size = 0.4\n",
    "alpha_exponential_moving_avg = 0.15\n",
    "\n",
    "# Stopping & invalidation criteria.\n",
    "min_streamline_len = 10\n",
    "max_streamline_len = 100\n",
    "gfa_min_threshold = 0.25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tractography Reconstruction Loop - Trilinear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp is x,y,z tuple of scipy.sparse.lil_arrays\n",
    "# full streamline list is x,y,z tuple of scipy.sparse.csr_arrays\n",
    "# After every seed batch, the remaining temp tracts are row-wise stacked onto the full\n",
    "# streamline list with scipy.sparse.vstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fn_linear_interp_zyx_tangent_t2theta_phi(\n",
    "    target_coords_mm_zyx: torch.Tensor,\n",
    "    init_direction_theta_phi: Optional[torch.Tensor],\n",
    "    fodf_coeffs_brain_vol: torch.Tensor,\n",
    "    affine_vox2mm: torch.Tensor,\n",
    "    sphere_samples_theta: torch.Tensor,\n",
    "    sphere_samples_phi: torch.Tensor,\n",
    "    sh_order: int,\n",
    "    fodf_pdf_thresh_min: float,\n",
    "    fmls_lobe_merge_ratio: float,\n",
    "    lobe_fodf_pdf_filter_kwargs: dict,\n",
    "    duplicate_peaks_whole_sphere: bool = True,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # Initial interpolation of fodf coefficients at the target points.\n",
    "    pred_sample_fodf_coeffs = pitn.odf.sample_odf_coeffs_lin_interp(\n",
    "        target_coords_mm_zyx,\n",
    "        fodf_coeff_vol=fodf_coeffs_brain_vol,\n",
    "        affine_vox2mm=affine_vox2mm,\n",
    "    )\n",
    "\n",
    "    # Transform to fodf spherical samples.\n",
    "    target_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        pred_sample_fodf_coeffs,\n",
    "        theta=sphere_samples_theta,\n",
    "        phi=sphere_samples_phi,\n",
    "        sh_order=sh_order,\n",
    "    )\n",
    "\n",
    "    # Threshold spherical function values.\n",
    "    target_sphere_samples = pitn.odf.thresh_fodf_samples_by_pdf(\n",
    "        target_sphere_samples, fodf_pdf_thresh_min\n",
    "    )\n",
    "\n",
    "    # Segment lobes on the fodf samples in each voxel.\n",
    "    lobe_labels = pitn.tract.peak.fmls_fodf_seg(\n",
    "        target_sphere_samples,\n",
    "        lobe_merge_ratio=fmls_lobe_merge_ratio,\n",
    "        theta=sphere_samples_theta,\n",
    "        phi=sphere_samples_phi,\n",
    "    )\n",
    "\n",
    "    # Refine the segmentation.\n",
    "    lobe_labels = pitn.tract.peak.remove_fodf_labels_by_pdf(\n",
    "        lobe_labels, target_sphere_samples, **lobe_fodf_pdf_filter_kwargs\n",
    "    )\n",
    "\n",
    "    # Find the peaks from the lobe segmentation.\n",
    "    peaks = pitn.tract.peak.peaks_from_segment(\n",
    "        lobe_labels,\n",
    "        target_sphere_samples,\n",
    "        theta_coord=sphere_samples_theta,\n",
    "        phi_coord=sphere_samples_phi,\n",
    "    )\n",
    "\n",
    "    # If no initial direction is given, or the initial direction vector is 0, then\n",
    "    # just find the largest peak.\n",
    "    if (init_direction_theta_phi is None) or (\n",
    "        torch.as_tensor(init_direction_theta_phi) == 0\n",
    "    ).all():\n",
    "        largest_peak = pitn.tract.peak.topk_peaks(\n",
    "            k=1,\n",
    "            fodf_peaks=peaks.peaks,\n",
    "            theta_peak=peaks.theta,\n",
    "            phi_peaks=peaks.phi,\n",
    "            valid_peak_mask=peaks.valid_peak_mask,\n",
    "        )\n",
    "        result_direction_theta_phi = (largest_peak.theta, largest_peak.phi)\n",
    "    # Otherwise if an initial direction vector is given, find the peak closest to that\n",
    "    # incoming direction.\n",
    "    else:\n",
    "        if duplicate_peaks_whole_sphere:\n",
    "            # Duplicate for coverage over the whole sphere.\n",
    "            full_sphere_fodf_peaks = (\n",
    "                pitn.tract.direction.fodf_duplicate_hemisphere2sphere(\n",
    "                    peaks.theta, peaks.phi, (peaks.peaks, peaks.valid_peak_mask), (1, 1)\n",
    "                )\n",
    "            )\n",
    "            fodf_peaks = full_sphere_fodf_peaks.vals[0]\n",
    "            peak_coords_theta_phi = torch.stack(\n",
    "                [full_sphere_fodf_peaks.theta, full_sphere_fodf_peaks.phi], -1\n",
    "            )\n",
    "            valid_mask = full_sphere_fodf_peaks.vals[1]\n",
    "        else:\n",
    "            fodf_peaks = peaks.peaks\n",
    "            peak_coords_theta_phi = torch.stack([peaks.theta, peaks.phi], -1)\n",
    "            valid_mask = peaks.valid_peak_mask\n",
    "\n",
    "        opposing_peak = pitn.tract.direction.closest_opposing_direction(\n",
    "            init_direction_theta_phi,\n",
    "            fodf_peaks=fodf_peaks,\n",
    "            peak_coords_theta_phi=peak_coords_theta_phi,\n",
    "            peaks_valid_mask=valid_mask,\n",
    "        )\n",
    "        # Unpack the spherical coordinates, then split each coordinate into a 2-tuple.\n",
    "        result_direction_theta_phi = opposing_peak[0]\n",
    "        result_direction_theta_phi = (\n",
    "            result_direction_theta_phi[..., 0],\n",
    "            result_direction_theta_phi[..., 1],\n",
    "        )\n",
    "\n",
    "    return result_direction_theta_phi\n",
    "\n",
    "\n",
    "fn_linear_interp_zyx_tangent_t2theta_phi = partial(\n",
    "    _fn_linear_interp_zyx_tangent_t2theta_phi,\n",
    "    fodf_coeffs_brain_vol=coeffs,\n",
    "    affine_vox2mm=affine_sar_vox2sar_mm,\n",
    "    sphere_samples_theta=theta,\n",
    "    sphere_samples_phi=phi,\n",
    "    sh_order=max_sh_order,\n",
    "    fodf_pdf_thresh_min=min_sample_pdf_threshold,\n",
    "    fmls_lobe_merge_ratio=lobe_merge_ratio,\n",
    "    lobe_fodf_pdf_filter_kwargs={\n",
    "        \"pdf_peak_min\": min_lobe_pdf_peak_threshold,\n",
    "        \"pdf_integral_min\": min_lobe_pdf_integral_threshold,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced version of the full interpolation function, to be called only when expanding\n",
    "# the seed points at the start of streamline estimation.\n",
    "def _peaks_only_fn_linear_interp_zyx(\n",
    "    target_coords_mm_zyx: torch.Tensor,\n",
    "    fodf_coeffs_brain_vol: torch.Tensor,\n",
    "    affine_vox2mm: torch.Tensor,\n",
    "    sphere_samples_theta: torch.Tensor,\n",
    "    sphere_samples_phi: torch.Tensor,\n",
    "    sh_order: int,\n",
    "    fodf_pdf_thresh_min: float,\n",
    "    fmls_lobe_merge_ratio: float,\n",
    "    lobe_fodf_pdf_filter_kwargs: dict,\n",
    ") -> pitn.tract.peak.PeaksContainer:\n",
    "    # Initial interpolation of fodf coefficients at the target points.\n",
    "    pred_sample_fodf_coeffs = pitn.odf.sample_odf_coeffs_lin_interp(\n",
    "        target_coords_mm_zyx,\n",
    "        fodf_coeff_vol=fodf_coeffs_brain_vol,\n",
    "        affine_vox2mm=affine_vox2mm,\n",
    "    )\n",
    "\n",
    "    # Transform to fodf spherical samples.\n",
    "    target_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        pred_sample_fodf_coeffs,\n",
    "        theta=sphere_samples_theta,\n",
    "        phi=sphere_samples_phi,\n",
    "        sh_order=sh_order,\n",
    "    )\n",
    "\n",
    "    # Threshold spherical function values.\n",
    "    target_sphere_samples = pitn.odf.thresh_fodf_samples_by_pdf(\n",
    "        target_sphere_samples, fodf_pdf_thresh_min\n",
    "    )\n",
    "\n",
    "    # Segment lobes on the fodf samples in each voxel.\n",
    "    lobe_labels = pitn.tract.peak.fmls_fodf_seg(\n",
    "        target_sphere_samples,\n",
    "        lobe_merge_ratio=fmls_lobe_merge_ratio,\n",
    "        theta=sphere_samples_theta,\n",
    "        phi=sphere_samples_phi,\n",
    "    )\n",
    "\n",
    "    # Refine the segmentation.\n",
    "    lobe_labels = pitn.tract.peak.remove_fodf_labels_by_pdf(\n",
    "        lobe_labels, target_sphere_samples, **lobe_fodf_pdf_filter_kwargs\n",
    "    )\n",
    "\n",
    "    # Find the peaks from the lobe segmentation.\n",
    "    peaks = pitn.tract.peak.peaks_from_segment(\n",
    "        lobe_labels,\n",
    "        target_sphere_samples,\n",
    "        theta_coord=sphere_samples_theta,\n",
    "        phi_coord=sphere_samples_phi,\n",
    "    )\n",
    "\n",
    "    return peaks\n",
    "\n",
    "\n",
    "# Copy the static parameters from the full interplation function.\n",
    "peaks_only_fn_linear_interp_zyx = partial(\n",
    "    _peaks_only_fn_linear_interp_zyx,\n",
    "    **fn_linear_interp_zyx_tangent_t2theta_phi.keywords,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial seeds and tangent/direction vectors.\n",
    "\n",
    "seeds_t_neg1 = pitn.tract.seed.seeds_from_mask(\n",
    "    seed_mask,\n",
    "    seeds_per_vox_axis=seeds_per_vox_axis,\n",
    "    affine_vox2mm=affine_sar_vox2sar_mm,\n",
    ")\n",
    "seed_peaks = peaks_only_fn_linear_interp_zyx(seeds_t_neg1)\n",
    "\n",
    "(seeds_t_neg1_to_0, tangent_t0_zyx,) = pitn.tract.seed.expand_seeds_from_topk_peaks_rk4(\n",
    "    seeds_t_neg1,\n",
    "    max_peaks_per_voxel=peaks_per_seed_vox,\n",
    "    seed_peak_vals=seed_peaks.peaks,\n",
    "    theta_peak=seed_peaks.theta,\n",
    "    phi_peak=seed_peaks.phi,\n",
    "    valid_peak_mask=seed_peaks.valid_peak_mask,\n",
    "    step_size=step_size,\n",
    "    fn_zyx_direction_t2theta_phi=partial(\n",
    "        fn_linear_interp_zyx_tangent_t2theta_phi, duplicate_peaks_whole_sphere=False\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle stopping conditions.\n",
    "with torch.no_grad():\n",
    "    gfa_sampling_sphere = dipy.data.get_sphere(\"repulsion724\").subdivide(1)\n",
    "\n",
    "    gfa_theta, gfa_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "        gfa_sampling_sphere, coeffs.device, coeffs.dtype\n",
    "    )\n",
    "    # Function applies non-negativity constraint.\n",
    "    gfa_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        coeffs.cpu(),\n",
    "        theta=gfa_theta.cpu(),\n",
    "        phi=gfa_phi.cpu(),\n",
    "        sh_order=8,\n",
    "        sh_order_dim=0,\n",
    "        mask=brain_mask.cpu(),\n",
    "    )\n",
    "\n",
    "    gfa = pitn.odf.gfa(gfa_sphere_samples, sphere_samples_idx=0).to(device)\n",
    "    # Also, mask out only the white matter in the gfa! Otherwise, gfa can be high in\n",
    "    # most places...\n",
    "    gfa = gfa * wm_mask\n",
    "    del gfa_sphere_samples, gfa_theta, gfa_phi, gfa_sampling_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!DEBUG\n",
    "\n",
    "\n",
    "def fn_only_right_zyx2theta_phi(\n",
    "    target_coords_mm_zyx: torch.Tensor, init_direction_theta_phi: Optional[torch.Tensor]\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    results_shape = tuple(target_coords_mm_zyx.shape[:-1])\n",
    "    theta = target_coords_mm_zyx.new_ones(results_shape) * (torch.pi / 2)\n",
    "    phi = torch.zeros_like(theta)\n",
    "\n",
    "    return (theta, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary tracrography loop.\n",
    "\n",
    "streamline_status = (\n",
    "    torch.ones(\n",
    "        seeds_t_neg1_to_0.shape[1], dtype=torch.int8, device=seeds_t_neg1_to_0.device\n",
    "    )\n",
    "    * pitn.tract.stopping.CONTINUE\n",
    ")\n",
    "# At least one step has been made.\n",
    "streamline_len = torch.zeros_like(streamline_status).float() + step_size\n",
    "\n",
    "streamlines = list()\n",
    "streamlines.append(seeds_t_neg1_to_0[0])\n",
    "streamlines.append(seeds_t_neg1_to_0[1])\n",
    "\n",
    "points_t = seeds_t_neg1_to_0[1]\n",
    "tangent_t_theta_phi = torch.stack(\n",
    "    pitn.tract.local.zyx2unit_sphere_theta_phi(tangent_t0_zyx), -1\n",
    ")\n",
    "tangent_t_zyx = tangent_t0_zyx\n",
    "\n",
    "# t_max = 1e8\n",
    "t_max = 300\n",
    "t = 1\n",
    "while pitn.tract.stopping.to_continue_mask(streamline_status).any():\n",
    "\n",
    "    points_tp1 = torch.zeros_like(points_t) * torch.nan\n",
    "    tangent_tp1_theta_phi = torch.zeros_like(tangent_t_theta_phi) * torch.nan\n",
    "\n",
    "    to_process_mask = pitn.tract.stopping.to_continue_mask(streamline_status)\n",
    "    valid_tangent_tp1_zyx = pitn.tract.local.gen_tract_step_rk4(\n",
    "        points_t[to_process_mask],\n",
    "        init_direction_theta_phi=tangent_t_theta_phi[to_process_mask],\n",
    "        fn_zyx_direction_t2theta_phi=fn_linear_interp_zyx_tangent_t2theta_phi,\n",
    "        # fn_zyx_direction_t2theta_phi=fn_only_right_zyx2theta_phi, #!DEBUG\n",
    "        step_size=step_size,\n",
    "    )\n",
    "    ema_tangent_tp1_zyx = (\n",
    "        alpha_exponential_moving_avg * valid_tangent_tp1_zyx\n",
    "        + (1 - alpha_exponential_moving_avg) * tangent_t_zyx[to_process_mask]\n",
    "    )\n",
    "    ema_tangent_tp1_zyx = (\n",
    "        step_size\n",
    "        * ema_tangent_tp1_zyx\n",
    "        / torch.linalg.vector_norm(ema_tangent_tp1_zyx, ord=2, dim=-1, keepdim=True)\n",
    "    )\n",
    "\n",
    "    points_tp1.masked_scatter_(\n",
    "        to_process_mask[..., None], points_t[to_process_mask] + ema_tangent_tp1_zyx\n",
    "    )\n",
    "    tangent_tp1_zyx = ema_tangent_tp1_zyx\n",
    "    valid_tangent_tp1_theta_phi = torch.stack(\n",
    "        pitn.tract.local.zyx2unit_sphere_theta_phi(tangent_tp1_zyx), -1\n",
    "    )\n",
    "    tangent_tp1_theta_phi.masked_scatter_(\n",
    "        to_process_mask[..., None], valid_tangent_tp1_theta_phi\n",
    "    )\n",
    "\n",
    "    # Update state variables based upon new streamline statuses.\n",
    "    status_tp1 = torch.clone(streamline_status)\n",
    "    tmp_len = torch.where(to_process_mask, streamline_len + step_size, streamline_len)\n",
    "    status_tp1 = pitn.tract.stopping.streamline_len_mm(\n",
    "        streamline_status,\n",
    "        tmp_len,\n",
    "        min_len=min_streamline_len,\n",
    "        max_len=max_streamline_len,\n",
    "    )\n",
    "    status_tp1 = pitn.tract.stopping.gfa_threshold(\n",
    "        status_tp1,\n",
    "        sample_coords_mm_zyx=points_tp1,\n",
    "        gfa_min_threshold=gfa_min_threshold,\n",
    "        gfa_vol=gfa,\n",
    "        affine_vox2mm=affine_sar_vox2sar_mm,\n",
    "    )\n",
    "\n",
    "    tp1_continue_mask = pitn.tract.stopping.to_continue_mask(status_tp1)\n",
    "\n",
    "    points_tp1.masked_fill_(~tp1_continue_mask[..., None], torch.nan)\n",
    "\n",
    "    # t <- t + 1\n",
    "    print(t, end=\" \")\n",
    "    t += 1\n",
    "    if t > t_max:\n",
    "        break\n",
    "\n",
    "    streamlines.append(points_tp1)\n",
    "    points_t = points_tp1\n",
    "    tangent_t_theta_phi = torch.where(\n",
    "        tp1_continue_mask[..., None], tangent_tp1_theta_phi, 0\n",
    "    )\n",
    "    tangent_t_zyx = (0 * tangent_t_zyx).masked_scatter(\n",
    "        tp1_continue_mask[..., None], tangent_tp1_zyx\n",
    "    )\n",
    "    streamline_len = torch.where(\n",
    "        tp1_continue_mask,\n",
    "        streamline_len + step_size,\n",
    "        streamline_len,\n",
    "    )\n",
    "    streamline_status = status_tp1\n",
    "    # if (streamline_status != pitn.tract.stopping.CONTINUE).any():\n",
    "    #     print(\"Stopped a tract!\")\n",
    "    #     break\n",
    "# Shape `tract_seed x n_steps x 3`\n",
    "streamlines = torch.stack(streamlines, 1)\n",
    "print(\"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = np.split(streamlines.detach().cpu().numpy(), streamlines.shape[0], axis=0)\n",
    "tracts = [t.squeeze()[(~np.isnan(t.squeeze())).any(-1)] for t in tracts]\n",
    "sar_tracts = dipy.io.dpy.Streamlines(tracts)\n",
    "sar_tracto = dipy.io.streamline.Tractogram(\n",
    "    sar_tracts, affine_to_rasmm=affine_sar2ras.cpu().numpy()\n",
    ")\n",
    "tracto = sar_tracto.to_world()\n",
    "# Get the header from an \"un-re-oriented\" fod volume and give to the tractogram.\n",
    "\n",
    "ref_header = nib.as_closest_canonical(nib.load(sample_fod_f)).header\n",
    "tracto = dipy.io.streamline.StatefulTractogram(\n",
    "    tracto.streamlines,\n",
    "    space=dipy.io.stateful_tractogram.Space.RASMM,\n",
    "    reference=ref_header,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipy.io.streamline.save_tck(tracto, \"/tmp/dipolar_single_vox_test_trax.tck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(streamlines[3, :, 2].cpu().numpy(), label=\"x\")\n",
    "plt.plot(streamlines[3, :, 1].cpu().numpy(), label=\"y\")\n",
    "plt.plot(streamlines[3, :, 0].cpu().numpy(), label=\"z\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = nib.Nifti1Image(\n",
    "    gfa[0].cpu().swapdims(0, 2).numpy(), affine_ras_vox2ras_mm.cpu().numpy(), ref_header\n",
    ")\n",
    "\n",
    "nib.save(im, str(sample_fod_f.parent / \"gfa.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfa_sampling_sphere = dipy.data.get_sphere(\"repulsion724\").subdivide(1)\n",
    "\n",
    "gfa_theta, gfa_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    gfa_sampling_sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "# Function applies non-negativity constraint.\n",
    "gfa_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "    coeffs.cpu(),\n",
    "    theta=gfa_theta.cpu(),\n",
    "    phi=gfa_phi.cpu(),\n",
    "    sh_order=8,\n",
    "    sh_order_dim=0,\n",
    "    mask=brain_mask.cpu(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipy_gfa = dipy.direction.gfa(\n",
    "    gfa_sphere_samples.cpu().movedim(0, -1).swapdims(0, 2).numpy()\n",
    ")\n",
    "\n",
    "dipy_gfa = np.nan_to_num(dipy_gfa, nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipy_im = nib.Nifti1Image(dipy_gfa, affine_ras_vox2ras_mm.cpu().numpy(), ref_header)\n",
    "nib.save(im, str(sample_fod_f.parent / \"dipy_gfa.nii.gz\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tractogram & Sampling Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fod_f.parent / \"gfa.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_tracto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(seeds_t_neg1[:, 0].unique().mean())\n",
    "\n",
    "start_point = pitn.affine.coord_transform_3d(\n",
    "    affine_vox2mm.new_tensor(select_vox_idx), affine_vox2mm\n",
    ")\n",
    "fake_tracts = start_point.new_empty(100, 3)\n",
    "# Just step along the same direction in small step sizes.\n",
    "for i in range(100):\n",
    "    fake_tracts[i] = start_point + i * 0.2 * (\n",
    "        start_point / torch.linalg.norm(start_point, 2)\n",
    "    )\n",
    "fake_tracts = fake_tracts[None]\n",
    "fake_tracts = np.split(fake_tracts.detach().cpu().numpy(), fake_tracts.shape[0], axis=0)\n",
    "fake_tracts = [t.squeeze()[(~np.isnan(t.squeeze())).any(-1)] for t in fake_tracts]\n",
    "fake_tracto = dipy.io.dpy.Streamlines(fake_tracts)\n",
    "# Coordinates are already in RAS+ (mm) world coordinates.\n",
    "fake_tracto = dipy.io.streamline.StatefulTractogram(\n",
    "    fake_tracto,\n",
    "    space=dipy.io.stateful_tractogram.Space.RASMM,\n",
    "    reference=fod_coeff_im.header,\n",
    ")\n",
    "\n",
    "dipy.io.streamline.save_tck(fake_tracto, \"/tmp/fake_trax.tck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(affine_vox2mm)\n",
    "aff = affine_vox2mm.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aff)\n",
    "ornt_ras = nib.orientations.io_orientation(aff)\n",
    "ornt_sar = nib.orientations.axcodes2ornt((\"S\", \"A\", \"R\"))\n",
    "print(ornt_ras)\n",
    "print(ornt_sar)\n",
    "ornt_sar2ras = nib.orientations.ornt_transform(ornt_sar, ornt_ras)\n",
    "aff_ras2sar = nib.orientations.inv_ornt_aff(ornt_sar2ras, tuple(coeffs.shape[1:]))\n",
    "\n",
    "print(aff_ras2sar)\n",
    "\n",
    "print(aff_ras2sar.dot(aff))\n",
    "print(aff_ras2sar @ aff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fODF Peak Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fod_f = (\n",
    "    hcp_full_res_fodf_dir / \"162329\" / \"T1w\" / \"postproc_wm_msmt_csd_fod.nii.gz\"\n",
    ")\n",
    "fod_coeff_im = nib.load(sample_fod_f)\n",
    "fod_coeff_im = nib.as_closest_canonical(fod_coeff_im)\n",
    "mask_f = sample_fod_f.parent / \"postproc_nodif_brain_mask.nii.gz\"\n",
    "mask_im = nib.load(mask_f)\n",
    "mask_im = nib.as_closest_canonical(mask_im)\n",
    "\n",
    "# Pre-select voxels of interest for this specific subject.\n",
    "# CC forceps minor, strong L-R uni-modal lobe\n",
    "cc_lr_lobe_idx = (55, 98, 53)\n",
    "# Dual-polar approx. equal volume fiber crossing\n",
    "lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "# Vox. adjacent to CST, tri-polar\n",
    "tri_polar_lobe_idx = (60, 68, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = fod_coeff_im.get_fdata()\n",
    "coeffs = torch.from_numpy(coeffs)\n",
    "# Move to channels-first layout.\n",
    "coeffs = coeffs.movedim(-1, 0)\n",
    "mask = mask_im.get_fdata().astype(bool)\n",
    "mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "print(coeffs.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = fod_coeff_im.affine\n",
    "aff = torch.from_numpy(aff)\n",
    "print(aff)\n",
    "print(aff.shape)\n",
    "\n",
    "p1 = torch.as_tensor(cc_lr_lobe_idx).float()\n",
    "p2 = torch.as_tensor(lr_and_ap_bipolar_lobe_idx).float()\n",
    "p3 = torch.as_tensor(tri_polar_lobe_idx).float()\n",
    "p = torch.stack([p1, p2, p3], 0)\n",
    "print(p)\n",
    "print(p.shape)\n",
    "p_mm = pitn.affine.coord_transform_3d(p, aff)\n",
    "print(p_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_shape = coeffs.shape\n",
    "aff_mm2vox = torch.linalg.inv(aff)\n",
    "aff_vox2grid = torch.eye(4).to(aff_mm2vox)\n",
    "aff_diag = 2 / (torch.as_tensor(vol_shape[-3:]) - 1)\n",
    "aff_diag = torch.cat([aff_diag, aff_diag.new_ones(1)], 0)\n",
    "aff_vox2grid = aff_vox2grid.diagonal_scatter(aff_diag)\n",
    "# aff_vox2grid = aff_vox2grid.diag_embed()\n",
    "aff_vox2grid[:3, 3:4] = -1\n",
    "print(aff_vox2grid)\n",
    "\n",
    "pitn.affine.coord_transform_3d(p_mm, aff_vox2grid @ aff_mm2vox)\n",
    "print(\n",
    "    pitn.affine.coord_transform_3d(\n",
    "        torch.as_tensor([68.75, 66.5, 73]), aff_vox2grid @ aff_mm2vox\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    pitn.affine.coord_transform_3d(\n",
    "        torch.as_tensor([-67.5, -99.75, -60.75]), aff_vox2grid @ aff_mm2vox\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mask sampling.\n",
    "print(mask.shape)\n",
    "print(mask_im.affine == fod_coeff_im.affine)\n",
    "aff = torch.from_numpy(fod_coeff_im.affine).to(torch.float32)\n",
    "p1 = torch.tensor([-51.25, 22.75, -2])  # Should be True, may have off-by-one error\n",
    "p2 = torch.tensor([-67.5, -99.75, -60.75])  # False\n",
    "p3 = torch.tensor([-67.5, -99.75, -48.25])  # False\n",
    "p4 = torch.tensor([-1.25, -2.25, -33])  # False\n",
    "p5 = torch.tensor([3.75, -18.5, 0.5])  # True\n",
    "p6 = torch.tensor([-46.25, -53.5, -58.25])  # True, inserted manually into mask.\n",
    "p = torch.stack([p1, p2, p3, p4, p5, p6], 0)\n",
    "m = torch.clone(mask)\n",
    "m[:, 17, 37, 2] = 1  # Corresponds to p6\n",
    "mask_samples = pitn.affine.sample_3d(m, p, aff, mode=\"nearest\", align_corners=True)\n",
    "print(mask_samples)\n",
    "print(mask_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sampling.\n",
    "vol = torch.arange(0, 4**3).reshape(1, 1, 4, 4, 4).float()\n",
    "print(vol.shape)\n",
    "aff = torch.eye(4)\n",
    "p = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [3, 3, 3],\n",
    "        [0, 0, 3],\n",
    "        [2, 1, 1],\n",
    "        [4, 4, 4],\n",
    "        [2.7095, 1.75, 1.5],\n",
    "    ]\n",
    ")\n",
    "print(p.shape)\n",
    "samples = pitn.affine.sample_3d(\n",
    "    vol, torch.stack([p[..., 2], p[..., 1], p[..., 0]], -1), aff\n",
    ")\n",
    "print(samples)\n",
    "print(samples.shape)\n",
    "print(vol.squeeze()[tuple(p[:-2].T.long())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change orientation for visualization.\n",
    "# new_ornt = nib.orientations.axcodes2ornt(tuple(\"IPR\"))\n",
    "# ornt_tf = nib.orientations.ornt_transform(\n",
    "#     nib.orientations.axcodes2ornt(nib.orientations.aff2axcodes(fod_coeff_im.affine)), new_ornt\n",
    "# )\n",
    "# coeffs = fod_coeff_im.as_reoriented(ornt_tf).get_fdata()\n",
    "# coeffs = torch.from_numpy(coeffs)\n",
    "# # Move to channels-first layout.\n",
    "# coeffs = coeffs.movedim(-1, 0)\n",
    "# mask = mask_im.as_reoriented(ornt_tf).get_fdata().astype(bool)\n",
    "# mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "# print(coeffs.shape)\n",
    "# print(mask.shape)\n",
    "\n",
    "# # Transform the points of interest to the new coord layout.\n",
    "# print(\"\\nTransforming voxel coordinates of interest.\")\n",
    "# affine_vox2ras_phys = fod_coeff_im.affine\n",
    "# affine_vox2ipr_phys = fod_coeff_im.as_reoriented(ornt_tf).affine\n",
    "# affine_ipr_phys2vox = np.linalg.inv(affine_vox2ipr_phys)\n",
    "# p_vox_ipr = list()\n",
    "# for p in (cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx):\n",
    "#     p = np.asarray(p)[:, None]\n",
    "#     p_phys = (affine_vox2ras_phys[:3, :3] @ p) + affine_vox2ras_phys[:3, 3:4]\n",
    "#     p_orient = (affine_ipr_phys2vox[:3, :3] @ p_phys) + affine_ipr_phys2vox[:3, 3:4]\n",
    "#     print(p_orient.flatten().astype(int))\n",
    "#     p_vox_ipr.append(tuple(p_orient.flatten().astype(int)))\n",
    "# cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx = tuple(p_vox_ipr)\n",
    "# print(cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion200\"))\n",
    "sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion724\"))\n",
    "\n",
    "theta, phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "with torch.no_grad():\n",
    "    # Function applies non-negativity constraint.\n",
    "    sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        coeffs, theta=theta, phi=phi, sh_order=8, sh_order_dim=0, mask=mask\n",
    "    )\n",
    "\n",
    "nearest_sphere_samples = pitn.odf.adjacent_sphere_points_idx(theta=theta, phi=phi)\n",
    "nearest_sphere_samples_idx = nearest_sphere_samples[0]\n",
    "nearest_sphere_samples_valid_mask = nearest_sphere_samples[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast-Marching Level Set (FMLS) Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold parameter from Algorithm 1 in Appendix A of SIFT paper.\n",
    "min_sample_pdf_threshold = 0.0001\n",
    "\n",
    "peak_diff_threshold = 0.8\n",
    "\n",
    "min_lobe_pdf_peak_threshold = 1e-5\n",
    "min_lobe_pdf_integral_threshold = 0.05\n",
    "\n",
    "# Single voxel lobe segmentation\n",
    "# vox_idx = cc_lr_lobe_idx\n",
    "# vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# vox_idx = tri_polar_lobe_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "fodf_idx_range = (slice(60, 81), slice(96, 117), slice(44, 65))\n",
    "\n",
    "b_fodf = sphere_samples[:, fodf_idx_range[0], fodf_idx_range[1], fodf_idx_range[2]]\n",
    "b_fodf = einops.rearrange(b_fodf, \"s ... -> (...) s\")\n",
    "# Remove low fodf values (count them as \"noise\").\n",
    "b_fodf = pitn.odf.thresh_fodf_samples_by_pdf(b_fodf, min_sample_pdf_threshold)\n",
    "\n",
    "b_fodf = b_fodf.to(device).to(torch.float32)\n",
    "b_theta = theta.to(device).to(torch.float32)\n",
    "b_phi = phi.to(device).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform FMLS segmentation.\n",
    "lobe_labels = pitn.tract.peak.fmls_fodf_seg(\n",
    "    b_fodf, peak_diff_threshold, theta=b_theta, phi=b_phi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine lobe labels.\n",
    "lobe_labels = pitn.tract.peak.remove_fodf_labels_by_pdf(\n",
    "    lobe_labels,\n",
    "    b_fodf,\n",
    "    pdf_peak_min=min_lobe_pdf_peak_threshold,\n",
    "    pdf_integral_min=min_lobe_pdf_integral_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = lobe_labels.unique()\n",
    "unique_labels = unique_labels[unique_labels > 0]\n",
    "\n",
    "peak_vals = torch.zeros(lobe_labels.shape[0], len(unique_labels)).to(b_fodf)\n",
    "peak_idx = -torch.ones_like(peak_vals).to(torch.long)\n",
    "for i, l in enumerate(unique_labels):\n",
    "    select_vals = torch.where(lobe_labels == l, b_fodf, -1)\n",
    "    l_peak_idx = torch.argmax(select_vals, dim=1)[:, None]\n",
    "    peak_idx[:, i] = l_peak_idx.flatten()\n",
    "    peak_idx[:, i] = torch.where(\n",
    "        select_vals.take_along_dim(l_peak_idx, dim=1) > 0, peak_idx[:, i, None], -1\n",
    "    ).flatten()\n",
    "\n",
    "valid_peak_mask = peak_idx >= 0\n",
    "peak_vals = torch.where(\n",
    "    peak_idx >= 0, b_fodf.take_along_dim(peak_idx.clamp_min(0), dim=1), -1\n",
    ")\n",
    "# The invalid indices are set to 0 to avoid subtle indexing errors later on; cuda in\n",
    "# particular hates indexing out-of-bounds of a Tensor. Even though it is possible that\n",
    "# an index value of 0 is valid, this is the only way to avoid those errors. The valid\n",
    "# peak mask must be used to distinguish between real peak indices and those that are\n",
    "# actually valued at 0.\n",
    "peak_idx.clamp_min_(0)\n",
    "print(peak_vals.shape)\n",
    "print(peak_idx.shape)\n",
    "print(valid_peak_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_theta = torch.take(b_theta, index=peak_idx) * valid_peak_mask\n",
    "peak_phi = torch.take(b_phi, index=peak_idx) * valid_peak_mask\n",
    "\n",
    "entry_dirs = torch.stack(\n",
    "    [\n",
    "        torch.ones_like(peak_theta[:, 0]) * torch.pi / 4,\n",
    "        torch.ones_like(peak_phi[:, 0]) * -torch.pi / 2,\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "peak_dirs = torch.stack([peak_theta, peak_phi], dim=-1)\n",
    "near_directs, near_peaks = pitn.tract.direct.closest_opposing_direction(\n",
    "    entry_dirs, peak_vals, peak_dirs, valid_peak_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.finfo(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize lobe segmentation result\n",
    "# # Plot 3D surface of odf.\n",
    "# %matplotlib widget\n",
    "\n",
    "# # \"surface\" or \"points\"\n",
    "# to_plot = \"points\"\n",
    "# post_seg_filter = True\n",
    "\n",
    "# viz_sphere = sphere\n",
    "# viz_theta, viz_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "#     viz_sphere, coeffs.device, coeffs.dtype\n",
    "# )\n",
    "# polar_tri = mpl.tri.Triangulation(viz_phi, viz_theta)\n",
    "# polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "\n",
    "# # Take labels from pre-segmentation filtering.\n",
    "# if not post_seg_filter:\n",
    "#     viz_tri_labels = lobe_labels.flatten()[polar_tri_idx]\n",
    "# else:\n",
    "#     # Take labels from post-segmentation filtering.\n",
    "#     viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "\n",
    "# label_cmap = sns.cubehelix_palette(\n",
    "#     n_colors=len(np.unique(viz_tri_labels.flatten())), reverse=True, rot=2, as_cmap=True\n",
    "# )\n",
    "# # viz_tri_labels = torch.mean(viz_tri_labels.float(), dim=1)\n",
    "# viz_tri_labels = torch.median(viz_tri_labels, dim=1).values\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     viz_coeffs = coeffs[(slice(None),) + vox_idx][:, None, None, None]\n",
    "#     viz_mask = mask[(slice(None),) + vox_idx][:, None, None, None]\n",
    "#     # Function applies non-negativity constraint.\n",
    "#     viz_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "#         viz_coeffs,\n",
    "#         theta=viz_theta,\n",
    "#         phi=viz_phi,\n",
    "#         sh_order=8,\n",
    "#         sh_order_dim=0,\n",
    "#         mask=viz_mask,\n",
    "#     )\n",
    "\n",
    "# viz_fodf = np.copy(viz_sphere_samples.detach().cpu().numpy().flatten())\n",
    "# viz_tri_labels = viz_tri_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "# viz_theta = viz_theta.detach().cpu().numpy().flatten()\n",
    "# viz_phi = viz_phi.detach().cpu().numpy().flatten()\n",
    "# directions, values, indices = dipy.direction.peak_directions(\n",
    "#     viz_fodf, viz_sphere, relative_peak_threshold=0.5, min_separation_angle=25\n",
    "# )\n",
    "# # viz_fodf[viz_fodf < values.min() * 0.3] = 1e-8\n",
    "# with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "#     fig = plt.figure(dpi=120)\n",
    "\n",
    "#     ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "#     vals = viz_fodf\n",
    "\n",
    "#     r = (vals - vals.min()) / (vals - vals.min()).max()\n",
    "#     r = vals / vals.sum()\n",
    "\n",
    "#     x = r * np.sin(viz_theta) * np.cos(viz_phi)\n",
    "#     y = r * np.sin(viz_theta) * np.sin(viz_phi)\n",
    "#     z = r * np.cos(viz_theta)\n",
    "#     mapper = mpl.cm.ScalarMappable(cmap=label_cmap)\n",
    "\n",
    "#     # center_colors = mapper.to_rgba(viz_tri_labels)\n",
    "#     # center_colors = np.where((viz_tri_labels == 0)[:, None], np.zeros_like(center_colors), center_colors)\n",
    "#     #     vertex_colors = mapper.to_rgba(ll.numpy().flatten()[polar_tri.edges])\n",
    "#     # polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "#     # viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "#     euclid_tri = mpl.tri.Triangulation(x, y, triangles=polar_tri.triangles)\n",
    "#     surf = ax.plot_trisurf(euclid_tri, z, linewidth=0.3, antialiased=True, zorder=4)\n",
    "\n",
    "#     if to_plot == \"surface\":\n",
    "#         face_colors = mapper.to_rgba(viz_tri_labels)\n",
    "#         face_colors = np.where(\n",
    "#             (viz_tri_labels == 0)[:, None], np.zeros_like(face_colors), face_colors\n",
    "#         )\n",
    "#         surf.set_fc(face_colors)\n",
    "#     elif to_plot == \"points\":\n",
    "#         surf.set_fc(\"white\")\n",
    "#         surf.set_edgecolors([0.2, 0.2, 0.2, 0.5])\n",
    "#         if post_seg_filter:\n",
    "#             point_colors = mapper.to_rgba(ll.numpy().flatten())\n",
    "#             point_colors = np.where(\n",
    "#                 (ll.numpy().flatten() == 0)[:, None],\n",
    "#                 np.zeros_like(point_colors),\n",
    "#                 point_colors,\n",
    "#             )\n",
    "#         else:\n",
    "#             point_colors = mapper.to_rgba(lobe_labels.numpy().flatten())\n",
    "#             point_colors = np.where(\n",
    "#                 (lobe_labels.numpy().flatten() == 0)[:, None],\n",
    "#                 np.zeros_like(point_colors),\n",
    "#                 point_colors,\n",
    "#             )\n",
    "#         ax.scatter3D(x, y, z, c=point_colors, s=20, zorder=0.1)\n",
    "#     plt.colorbar(mapper, shrink=0.67)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aef92aa78cb5293db69150d077de12929a6427717a8642923c8240ccc3365fd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
