{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import functools\n",
    "from functools import partial\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "import einops\n",
    "import monai\n",
    "import dipy\n",
    "import dipy.reconst\n",
    "import dipy.reconst.csdeconv, dipy.reconst.shm, dipy.viz\n",
    "import dipy.denoise\n",
    "import nibabel as nib\n",
    "\n",
    "import jax\n",
    "import jax.config\n",
    "\n",
    "# Disable jit for debugging.\n",
    "# jax.config.update(\"jax_disable_jit\", True)\n",
    "# Enable 64-bit precision.\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update(\"jax_default_matmul_precision\", 32)\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import jax.dlpack\n",
    "\n",
    "import pitn\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "plt.rcParams.update({\"image.cmap\": \"gray\"})\n",
    "plt.rcParams.update({\"image.interpolation\": \"antialiased\"})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device IDX  0\n",
      "CUDA Current Device  0\n",
      "CUDA Device properties:  _CudaDeviceProperties(name='NVIDIA RTX A5000', major=8, minor=6, total_memory=24256MB, multi_processor_count=64)\n",
      "CuDNN convolution optimization enabled.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# torch setup\n",
    "# allow for CUDA usage, if available\n",
    "if torch.cuda.is_available():\n",
    "    # Pick only one device for the default, may use multiple GPUs for training later.\n",
    "    dev_idx = 0\n",
    "    device = torch.device(f\"cuda:{dev_idx}\")\n",
    "    print(\"CUDA Device IDX \", dev_idx)\n",
    "    torch.cuda.set_device(device)\n",
    "    print(\"CUDA Current Device \", torch.cuda.current_device())\n",
    "    print(\"CUDA Device properties: \", torch.cuda.get_device_properties(device))\n",
    "    # The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n",
    "    # in PyTorch 1.12 and later.\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # See\n",
    "    # <https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices>\n",
    "    # for details.\n",
    "\n",
    "    # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(\"CuDNN convolution optimization enabled.\")\n",
    "        # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# keep device as the cpu\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_full_res_data_dir = Path(\"/data/srv/data/pitn/hcp\")\n",
    "hcp_full_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/full-res/fodf\")\n",
    "hcp_low_res_data_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/vol\")\n",
    "hcp_low_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/fodf\")\n",
    "\n",
    "assert hcp_full_res_data_dir.exists()\n",
    "assert hcp_full_res_fodf_dir.exists()\n",
    "assert hcp_low_res_data_dir.exists()\n",
    "assert hcp_low_res_fodf_dir.exists()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fODF Peak Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fod_f = (\n",
    "    hcp_full_res_fodf_dir / \"162329\" / \"T1w\" / \"postproc_wm_msmt_csd_fod.nii.gz\"\n",
    ")\n",
    "fod_coeff_im = nib.load(sample_fod_f)\n",
    "fod_coeff_im = nib.as_closest_canonical(fod_coeff_im)\n",
    "mask_f = sample_fod_f.parent / \"postproc_nodif_brain_mask.nii.gz\"\n",
    "mask_im = nib.load(mask_f)\n",
    "mask_im = nib.as_closest_canonical(mask_im)\n",
    "\n",
    "# Pre-select voxels of interest for this specific subject.\n",
    "# CC forceps minor, strong L-R uni-modal lobe\n",
    "cc_lr_lobe_idx = (55, 98, 53)\n",
    "# Dual-polar approx. equal volume fiber crossing\n",
    "lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "# Vox. adjacent to CST, tri-polar\n",
    "tri_polar_lobe_idx = (60, 68, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 110, 134, 108])\n",
      "torch.Size([1, 110, 134, 108])\n"
     ]
    }
   ],
   "source": [
    "coeffs = fod_coeff_im.get_fdata()\n",
    "coeffs = torch.from_numpy(coeffs)\n",
    "# Move to channels-first layout.\n",
    "coeffs = coeffs.movedim(-1, 0)\n",
    "mask = mask_im.get_fdata().astype(bool)\n",
    "mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "print(coeffs.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.2500,   0.0000,   0.0000, -67.5000],\n",
      "        [  0.0000,   1.2500,   0.0000, -99.7500],\n",
      "        [  0.0000,   0.0000,   1.2500, -60.7500],\n",
      "        [  0.0000,   0.0000,   0.0000,   1.0000]], dtype=torch.float64)\n",
      "torch.Size([4, 4])\n",
      "tensor([[ 55.,  98.,  53.],\n",
      "        [ 70., 106.,  54.],\n",
      "        [ 60.,  68.,  43.]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[  1.2500,  22.7500,   5.5000],\n",
      "        [ 20.0000,  32.7500,   6.7500],\n",
      "        [  7.5000, -14.7500,  -7.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "aff = fod_coeff_im.affine\n",
    "aff = torch.from_numpy(aff)\n",
    "print(aff)\n",
    "print(aff.shape)\n",
    "\n",
    "p1 = torch.as_tensor(cc_lr_lobe_idx).float()\n",
    "p2 = torch.as_tensor(lr_and_ap_bipolar_lobe_idx).float()\n",
    "p3 = torch.as_tensor(tri_polar_lobe_idx).float()\n",
    "p = torch.stack([p1, p2, p3], 0)\n",
    "print(p)\n",
    "print(p.shape)\n",
    "p_mm = pitn.affine.coord_transform_3d(p, aff)\n",
    "print(p_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 110, 134, 108])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0183,  0.0000,  0.0000, -1.0000],\n",
      "        [ 0.0000,  0.0150,  0.0000, -1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0187, -1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]], dtype=torch.float64)\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64)\n",
      "tensor([-1., -1., -1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "vol_shape = coeffs.shape\n",
    "aff_mm2vox = torch.linalg.inv(aff)\n",
    "aff_vox2grid = torch.eye(4).to(aff_mm2vox)\n",
    "aff_diag = 2 / (torch.as_tensor(vol_shape[-3:]) - 1)\n",
    "aff_diag = torch.cat([aff_diag, aff_diag.new_ones(1)], 0)\n",
    "aff_vox2grid = aff_vox2grid.diagonal_scatter(aff_diag)\n",
    "# aff_vox2grid = aff_vox2grid.diag_embed()\n",
    "aff_vox2grid[:3, 3:4] = -1\n",
    "print(aff_vox2grid)\n",
    "\n",
    "pitn.affine.coord_transform_3d(p_mm, aff_vox2grid @ aff_mm2vox)\n",
    "print(\n",
    "    pitn.affine.coord_transform_3d(\n",
    "        torch.as_tensor([68.75, 66.5, 73]), aff_vox2grid @ aff_mm2vox\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    pitn.affine.coord_transform_3d(\n",
    "        torch.as_tensor([-67.5, -99.75, -60.75]), aff_vox2grid @ aff_mm2vox\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 110, 134, 108])\n",
      "[[ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]]\n",
      "tensor([[ True, False, False, False,  True,  True]])\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# Test mask sampling.\n",
    "print(mask.shape)\n",
    "print(mask_im.affine == fod_coeff_im.affine)\n",
    "aff = torch.from_numpy(fod_coeff_im.affine).to(torch.float32)\n",
    "p1 = torch.tensor([-51.25, 22.75, -2])  # Should be True, may have off-by-one error\n",
    "p2 = torch.tensor([-67.5, -99.75, -60.75])  # False\n",
    "p3 = torch.tensor([-67.5, -99.75, -48.25])  # False\n",
    "p4 = torch.tensor([-1.25, -2.25, -33])  # False\n",
    "p5 = torch.tensor([3.75, -18.5, 0.5])  # True\n",
    "p6 = torch.tensor([-46.25, -53.5, -58.25])  # True, inserted manually into mask.\n",
    "p = torch.stack([p1, p2, p3, p4, p5, p6], 0)\n",
    "m = torch.clone(mask)\n",
    "m[:, 17, 37, 2] = 1  # Corresponds to p6\n",
    "mask_samples = pitn.affine.sample_3d(m, p, aff, mode=\"nearest\", align_corners=True)\n",
    "print(mask_samples)\n",
    "print(mask_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4, 4])\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 0.0000, 63.0000,  3.0000, 37.0000,  0.0000, 51.8520]])\n",
      "torch.Size([1, 6])\n",
      "tensor([ 0., 63.,  3., 37.])\n"
     ]
    }
   ],
   "source": [
    "# Test sampling.\n",
    "vol = torch.arange(0, 4**3).reshape(1, 1, 4, 4, 4).float()\n",
    "print(vol.shape)\n",
    "aff = torch.eye(4)\n",
    "p = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [3, 3, 3],\n",
    "        [0, 0, 3],\n",
    "        [2, 1, 1],\n",
    "        [4, 4, 4],\n",
    "        [2.7095, 1.75, 1.5],\n",
    "    ]\n",
    ")\n",
    "print(p.shape)\n",
    "samples = pitn.affine.sample_3d(\n",
    "    vol, torch.stack([p[..., 2], p[..., 1], p[..., 0]], -1), aff\n",
    ")\n",
    "print(samples)\n",
    "print(samples.shape)\n",
    "print(vol.squeeze()[tuple(p[:-2].T.long())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change orientation for visualization.\n",
    "# new_ornt = nib.orientations.axcodes2ornt(tuple(\"IPR\"))\n",
    "# ornt_tf = nib.orientations.ornt_transform(\n",
    "#     nib.orientations.axcodes2ornt(nib.orientations.aff2axcodes(fod_coeff_im.affine)), new_ornt\n",
    "# )\n",
    "# coeffs = fod_coeff_im.as_reoriented(ornt_tf).get_fdata()\n",
    "# coeffs = torch.from_numpy(coeffs)\n",
    "# # Move to channels-first layout.\n",
    "# coeffs = coeffs.movedim(-1, 0)\n",
    "# mask = mask_im.as_reoriented(ornt_tf).get_fdata().astype(bool)\n",
    "# mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "# print(coeffs.shape)\n",
    "# print(mask.shape)\n",
    "\n",
    "# # Transform the points of interest to the new coord layout.\n",
    "# print(\"\\nTransforming voxel coordinates of interest.\")\n",
    "# affine_vox2ras_phys = fod_coeff_im.affine\n",
    "# affine_vox2ipr_phys = fod_coeff_im.as_reoriented(ornt_tf).affine\n",
    "# affine_ipr_phys2vox = np.linalg.inv(affine_vox2ipr_phys)\n",
    "# p_vox_ipr = list()\n",
    "# for p in (cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx):\n",
    "#     p = np.asarray(p)[:, None]\n",
    "#     p_phys = (affine_vox2ras_phys[:3, :3] @ p) + affine_vox2ras_phys[:3, 3:4]\n",
    "#     p_orient = (affine_ipr_phys2vox[:3, :3] @ p_phys) + affine_ipr_phys2vox[:3, 3:4]\n",
    "#     print(p_orient.flatten().astype(int))\n",
    "#     p_vox_ipr.append(tuple(p_orient.flatten().astype(int)))\n",
    "# cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx = tuple(p_vox_ipr)\n",
    "# print(cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion200\"))\n",
    "sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion724\"))\n",
    "\n",
    "theta, phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "with torch.no_grad():\n",
    "    # Function applies non-negativity constraint.\n",
    "    sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        coeffs, theta=theta, phi=phi, sh_order=8, sh_order_dim=0, mask=mask\n",
    "    )\n",
    "\n",
    "nearest_sphere_samples = pitn.odf.adjacent_sphere_points_idx(theta=theta, phi=phi)\n",
    "nearest_sphere_samples_idx = nearest_sphere_samples[0]\n",
    "nearest_sphere_samples_valid_mask = nearest_sphere_samples[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast-Marching Level Set (FMLS) Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold parameter from Algorithm 1 in Appendix A of SIFT paper.\n",
    "min_sample_pdf_threshold = 0.0001\n",
    "\n",
    "peak_diff_threshold = 0.8\n",
    "\n",
    "min_lobe_pdf_peak_threshold = 1e-5\n",
    "min_lobe_pdf_integral_threshold = 0.05\n",
    "\n",
    "# Single voxel lobe segmentation\n",
    "# vox_idx = cc_lr_lobe_idx\n",
    "# vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# vox_idx = tri_polar_lobe_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "fodf_idx_range = (slice(60, 81), slice(96, 117), slice(44, 65))\n",
    "\n",
    "b_fodf = sphere_samples[:, fodf_idx_range[0], fodf_idx_range[1], fodf_idx_range[2]]\n",
    "b_fodf = einops.rearrange(b_fodf, \"s ... -> (...) s\")\n",
    "# Remove low fodf values (count them as \"noise\").\n",
    "b_fodf = pitn.odf.thresh_fodf_samples_by_pdf(b_fodf, min_sample_pdf_threshold)\n",
    "\n",
    "b_fodf = b_fodf.to(device).to(torch.float32)\n",
    "b_theta = theta.to(device).to(torch.float32)\n",
    "b_phi = phi.to(device).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-12 11:33:33,658 - Remote TPU is not linked into jax; skipping remote TPU.\n",
      "2023-01-12 11:33:33,659 - Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
      "2023-01-12 11:33:33,739 - Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter Host CUDA\n",
      "2023-01-12 11:33:33,741 - Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2023-01-12 11:33:33,742 - Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    }
   ],
   "source": [
    "# Perform FMLS segmentation.\n",
    "lobe_labels = pitn.tract.peak.fmls_fodf_seg(\n",
    "    b_fodf, peak_diff_threshold, theta=b_theta, phi=b_phi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine lobe labels.\n",
    "lobe_labels = pitn.tract.peak.remove_fodf_labels_by_pdf(\n",
    "    lobe_labels,\n",
    "    b_fodf,\n",
    "    pdf_peak_min=min_lobe_pdf_peak_threshold,\n",
    "    pdf_integral_min=min_lobe_pdf_integral_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9261, 8])\n",
      "torch.Size([9261, 8])\n",
      "torch.Size([9261, 8])\n"
     ]
    }
   ],
   "source": [
    "unique_labels = lobe_labels.unique()\n",
    "unique_labels = unique_labels[unique_labels > 0]\n",
    "\n",
    "peak_vals = torch.zeros(lobe_labels.shape[0], len(unique_labels)).to(b_fodf)\n",
    "peak_idx = -torch.ones_like(peak_vals).to(torch.long)\n",
    "for i, l in enumerate(unique_labels):\n",
    "    select_vals = torch.where(lobe_labels == l, b_fodf, -1)\n",
    "    l_peak_idx = torch.argmax(select_vals, dim=1)[:, None]\n",
    "    peak_idx[:, i] = l_peak_idx.flatten()\n",
    "    peak_idx[:, i] = torch.where(\n",
    "        select_vals.take_along_dim(l_peak_idx, dim=1) > 0, peak_idx[:, i, None], -1\n",
    "    ).flatten()\n",
    "\n",
    "valid_peak_mask = peak_idx >= 0\n",
    "peak_vals = torch.where(\n",
    "    peak_idx >= 0, b_fodf.take_along_dim(peak_idx.clamp_min(0), dim=1), -1\n",
    ")\n",
    "# The invalid indices are set to 0 to avoid subtle indexing errors later on; cuda in\n",
    "# particular hates indexing out-of-bounds of a Tensor. Even though it is possible that\n",
    "# an index value of 0 is valid, this is the only way to avoid those errors. The valid\n",
    "# peak mask must be used to distinguish between real peak indices and those that are\n",
    "# actually valued at 0.\n",
    "peak_idx.clamp_min_(0)\n",
    "print(peak_vals.shape)\n",
    "print(peak_idx.shape)\n",
    "print(valid_peak_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_theta = torch.take(b_theta, index=peak_idx) * valid_peak_mask\n",
    "peak_phi = torch.take(b_phi, index=peak_idx) * valid_peak_mask\n",
    "\n",
    "entry_dirs = torch.stack(\n",
    "    [\n",
    "        torch.ones_like(peak_theta[:, 0]) * torch.pi / 4,\n",
    "        torch.ones_like(peak_phi[:, 0]) * -torch.pi / 2,\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "peak_dirs = torch.stack([peak_theta, peak_phi], dim=-1)\n",
    "near_directs, near_peaks = pitn.tract.direct.closest_opposing_direction(\n",
    "    entry_dirs, peak_vals, peak_dirs, valid_peak_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize lobe segmentation result\n",
    "# # Plot 3D surface of odf.\n",
    "# %matplotlib widget\n",
    "\n",
    "# # \"surface\" or \"points\"\n",
    "# to_plot = \"points\"\n",
    "# post_seg_filter = True\n",
    "\n",
    "# viz_sphere = sphere\n",
    "# viz_theta, viz_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "#     viz_sphere, coeffs.device, coeffs.dtype\n",
    "# )\n",
    "# polar_tri = mpl.tri.Triangulation(viz_phi, viz_theta)\n",
    "# polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "\n",
    "# # Take labels from pre-segmentation filtering.\n",
    "# if not post_seg_filter:\n",
    "#     viz_tri_labels = lobe_labels.flatten()[polar_tri_idx]\n",
    "# else:\n",
    "#     # Take labels from post-segmentation filtering.\n",
    "#     viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "\n",
    "# label_cmap = sns.cubehelix_palette(\n",
    "#     n_colors=len(np.unique(viz_tri_labels.flatten())), reverse=True, rot=2, as_cmap=True\n",
    "# )\n",
    "# # viz_tri_labels = torch.mean(viz_tri_labels.float(), dim=1)\n",
    "# viz_tri_labels = torch.median(viz_tri_labels, dim=1).values\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     viz_coeffs = coeffs[(slice(None),) + vox_idx][:, None, None, None]\n",
    "#     viz_mask = mask[(slice(None),) + vox_idx][:, None, None, None]\n",
    "#     # Function applies non-negativity constraint.\n",
    "#     viz_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "#         viz_coeffs,\n",
    "#         theta=viz_theta,\n",
    "#         phi=viz_phi,\n",
    "#         sh_order=8,\n",
    "#         sh_order_dim=0,\n",
    "#         mask=viz_mask,\n",
    "#     )\n",
    "\n",
    "# viz_fodf = np.copy(viz_sphere_samples.detach().cpu().numpy().flatten())\n",
    "# viz_tri_labels = viz_tri_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "# viz_theta = viz_theta.detach().cpu().numpy().flatten()\n",
    "# viz_phi = viz_phi.detach().cpu().numpy().flatten()\n",
    "# directions, values, indices = dipy.direction.peak_directions(\n",
    "#     viz_fodf, viz_sphere, relative_peak_threshold=0.5, min_separation_angle=25\n",
    "# )\n",
    "# # viz_fodf[viz_fodf < values.min() * 0.3] = 1e-8\n",
    "# with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "#     fig = plt.figure(dpi=120)\n",
    "\n",
    "#     ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "#     vals = viz_fodf\n",
    "\n",
    "#     r = (vals - vals.min()) / (vals - vals.min()).max()\n",
    "#     r = vals / vals.sum()\n",
    "\n",
    "#     x = r * np.sin(viz_theta) * np.cos(viz_phi)\n",
    "#     y = r * np.sin(viz_theta) * np.sin(viz_phi)\n",
    "#     z = r * np.cos(viz_theta)\n",
    "#     mapper = mpl.cm.ScalarMappable(cmap=label_cmap)\n",
    "\n",
    "#     # center_colors = mapper.to_rgba(viz_tri_labels)\n",
    "#     # center_colors = np.where((viz_tri_labels == 0)[:, None], np.zeros_like(center_colors), center_colors)\n",
    "#     #     vertex_colors = mapper.to_rgba(ll.numpy().flatten()[polar_tri.edges])\n",
    "#     # polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "#     # viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "#     euclid_tri = mpl.tri.Triangulation(x, y, triangles=polar_tri.triangles)\n",
    "#     surf = ax.plot_trisurf(euclid_tri, z, linewidth=0.3, antialiased=True, zorder=4)\n",
    "\n",
    "#     if to_plot == \"surface\":\n",
    "#         face_colors = mapper.to_rgba(viz_tri_labels)\n",
    "#         face_colors = np.where(\n",
    "#             (viz_tri_labels == 0)[:, None], np.zeros_like(face_colors), face_colors\n",
    "#         )\n",
    "#         surf.set_fc(face_colors)\n",
    "#     elif to_plot == \"points\":\n",
    "#         surf.set_fc(\"white\")\n",
    "#         surf.set_edgecolors([0.2, 0.2, 0.2, 0.5])\n",
    "#         if post_seg_filter:\n",
    "#             point_colors = mapper.to_rgba(ll.numpy().flatten())\n",
    "#             point_colors = np.where(\n",
    "#                 (ll.numpy().flatten() == 0)[:, None],\n",
    "#                 np.zeros_like(point_colors),\n",
    "#                 point_colors,\n",
    "#             )\n",
    "#         else:\n",
    "#             point_colors = mapper.to_rgba(lobe_labels.numpy().flatten())\n",
    "#             point_colors = np.where(\n",
    "#                 (lobe_labels.numpy().flatten() == 0)[:, None],\n",
    "#                 np.zeros_like(point_colors),\n",
    "#                 point_colors,\n",
    "#             )\n",
    "#         ax.scatter3D(x, y, z, c=point_colors, s=20, zorder=0.1)\n",
    "#     plt.colorbar(mapper, shrink=0.67)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aef92aa78cb5293db69150d077de12929a6427717a8642923c8240ccc3365fd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
