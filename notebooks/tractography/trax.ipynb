{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import functools\n",
    "from functools import partial\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "import einops\n",
    "import monai\n",
    "import dipy\n",
    "import dipy.reconst\n",
    "import dipy.reconst.csdeconv, dipy.reconst.shm, dipy.viz\n",
    "import dipy.denoise\n",
    "import nibabel as nib\n",
    "\n",
    "import jax\n",
    "import jax.config\n",
    "\n",
    "# Disable jit for debugging.\n",
    "# jax.config.update(\"jax_disable_jit\", True)\n",
    "# Enable 64-bit precision.\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update(\"jax_default_matmul_precision\", 32)\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import jax.dlpack\n",
    "\n",
    "import pitn\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "plt.rcParams.update({\"image.cmap\": \"gray\"})\n",
    "plt.rcParams.update({\"image.interpolation\": \"antialiased\"})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_full_res_data_dir = Path(\"/data/srv/data/pitn/hcp\")\n",
    "hcp_full_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/full-res/fodf\")\n",
    "hcp_low_res_data_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/vol\")\n",
    "hcp_low_res_fodf_dir = Path(\"/data/srv/outputs/pitn/hcp/downsample/scale-2.00mm/fodf\")\n",
    "\n",
    "assert hcp_full_res_data_dir.exists()\n",
    "assert hcp_full_res_fodf_dir.exists()\n",
    "assert hcp_low_res_data_dir.exists()\n",
    "assert hcp_low_res_fodf_dir.exists()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fODF Peak Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fod_f = (\n",
    "    hcp_full_res_fodf_dir / \"162329\" / \"T1w\" / \"postproc_wm_msmt_csd_fod.nii.gz\"\n",
    ")\n",
    "fod_coeff_im = nib.load(sample_fod_f)\n",
    "fod_coeff_im = nib.as_closest_canonical(fod_coeff_im)\n",
    "mask_f = sample_fod_f.parent / \"postproc_nodif_brain_mask.nii.gz\"\n",
    "mask_im = nib.load(mask_f)\n",
    "mask_im = nib.as_closest_canonical(mask_im)\n",
    "\n",
    "# Pre-select voxels of interest for this specific subject.\n",
    "# CC forceps minor, strong L-R uni-modal lobe\n",
    "cc_lr_lobe_idx = (55, 98, 53)\n",
    "# Dual-polar approx. equal volume fiber crossing\n",
    "lr_and_ap_bipolar_lobe_idx = (70, 106, 54)\n",
    "# Vox. adjacent to CST, tri-polar\n",
    "tri_polar_lobe_idx = (60, 68, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 110, 134, 108])\n",
      "torch.Size([1, 110, 134, 108])\n"
     ]
    }
   ],
   "source": [
    "coeffs = fod_coeff_im.get_fdata()\n",
    "coeffs = torch.from_numpy(coeffs)\n",
    "# Move to channels-first layout.\n",
    "coeffs = coeffs.movedim(-1, 0)\n",
    "mask = mask_im.get_fdata().astype(bool)\n",
    "mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "print(coeffs.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change orientation for visualization.\n",
    "# new_ornt = nib.orientations.axcodes2ornt(tuple(\"IPR\"))\n",
    "# ornt_tf = nib.orientations.ornt_transform(\n",
    "#     nib.orientations.axcodes2ornt(nib.orientations.aff2axcodes(fod_coeff_im.affine)), new_ornt\n",
    "# )\n",
    "# coeffs = fod_coeff_im.as_reoriented(ornt_tf).get_fdata()\n",
    "# coeffs = torch.from_numpy(coeffs)\n",
    "# # Move to channels-first layout.\n",
    "# coeffs = coeffs.movedim(-1, 0)\n",
    "# mask = mask_im.as_reoriented(ornt_tf).get_fdata().astype(bool)\n",
    "# mask = torch.from_numpy(mask)[None]\n",
    "\n",
    "# print(coeffs.shape)\n",
    "# print(mask.shape)\n",
    "\n",
    "# # Transform the points of interest to the new coord layout.\n",
    "# print(\"\\nTransforming voxel coordinates of interest.\")\n",
    "# affine_vox2ras_phys = fod_coeff_im.affine\n",
    "# affine_vox2ipr_phys = fod_coeff_im.as_reoriented(ornt_tf).affine\n",
    "# affine_ipr_phys2vox = np.linalg.inv(affine_vox2ipr_phys)\n",
    "# p_vox_ipr = list()\n",
    "# for p in (cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx):\n",
    "#     p = np.asarray(p)[:, None]\n",
    "#     p_phys = (affine_vox2ras_phys[:3, :3] @ p) + affine_vox2ras_phys[:3, 3:4]\n",
    "#     p_orient = (affine_ipr_phys2vox[:3, :3] @ p_phys) + affine_ipr_phys2vox[:3, 3:4]\n",
    "#     print(p_orient.flatten().astype(int))\n",
    "#     p_vox_ipr.append(tuple(p_orient.flatten().astype(int)))\n",
    "# cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx = tuple(p_vox_ipr)\n",
    "# print(cc_lr_lobe_idx, lr_and_ap_bipolar_lobe_idx, tri_polar_lobe_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere = dipy.data.HemiSphere.from_sphere(dipy.data.get_sphere(\"repulsion200\"))\n",
    "sphere = dipy.data.HemiSphere.from_sphere(\n",
    "    dipy.data.get_sphere(\"repulsion724\")\n",
    ").subdivide(1)\n",
    "\n",
    "theta, phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "with torch.no_grad():\n",
    "    # Function applies non-negativity constraint.\n",
    "    sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        coeffs, theta=theta, phi=phi, sh_order=8, sh_order_dim=0, mask=mask\n",
    "    )\n",
    "\n",
    "nearest_sphere_samples = pitn.odf.adjacent_sphere_points_idx(theta=theta, phi=phi)\n",
    "nearest_sphere_samples_idx = nearest_sphere_samples[0]\n",
    "nearest_sphere_samples_valid_mask = nearest_sphere_samples[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast-Marching Level Set (FMLS) Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold parameter from Algorithm 1 in Appendix A of SIFT paper.\n",
    "peak_diff_threshold = 0.8\n",
    "min_lobe_pdf_peak_threshold = 1e-5\n",
    "min_lobe_pdf_integral_threshold = 0.05\n",
    "min_sample_pdf_threshold = 0.0001\n",
    "\n",
    "# Single voxel lobe segmentation\n",
    "# vox_idx = cc_lr_lobe_idx\n",
    "vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# vox_idx = tri_polar_lobe_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un-Batched Pytorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From\n",
    "# R. E. Smith, J.-D. Tournier, F. Calamante, and A. Connelly,\n",
    "# \"SIFT: Spherical-deconvolution informed filtering of tractograms,\" NeuroImage,\n",
    "# vol. 67, pp. 298–312, Feb. 2013, doi: 10.1016/j.neuroimage.2012.11.049.\n",
    "# Algorithm 1. in Appendix A.\n",
    "\n",
    "s = torch.clone(sphere_samples[(slice(None),) + vox_idx])\n",
    "\n",
    "# Perform basic thresholding of the sample to remove noise.\n",
    "# Normalize to a pdf to keep threshold values standardized across fodfs.\n",
    "s_pdf = s - s.min()\n",
    "s_pdf = s_pdf / s_pdf.sum()\n",
    "s = torch.where(s_pdf >= min_sample_pdf_threshold, s, 0)\n",
    "# Update the PDF.\n",
    "s_pdf = s - s.min()\n",
    "s_pdf = s_pdf / s_pdf.sum()\n",
    "\n",
    "lobe_labels = torch.zeros_like(s).to(torch.int16)\n",
    "lobe_labels_index_space = torch.arange(lobe_labels.shape[0])\n",
    "\n",
    "# Directions are sorted by absolute value, but the sign of their absolute value\n",
    "# will be needed later.\n",
    "# Get the indices of the sorted sample values, with each idx indexing into the\n",
    "# directions/sample values on the spherical function.\n",
    "sort_sample_idx = torch.argsort(torch.abs(s), dim=0, descending=True)\n",
    "sort_sample_val = torch.gather(s, 0, sort_sample_idx)\n",
    "\n",
    "curr_max_lobe_label = lobe_labels.new_tensor([0])\n",
    "for i_sample, fod_sample, sample_idx in zip(\n",
    "    range(s.shape[-1]),\n",
    "    sort_sample_val[..., None],\n",
    "    sort_sample_idx[..., None],\n",
    "):\n",
    "    i_sample_mask = lobe_labels_index_space == sample_idx\n",
    "    # Get the 6 directions closest to the current sample direction by providing the\n",
    "    # current sample's index over the spherical function samples. These adjacent\n",
    "    # indices correspond to the unsorted sample values and unsorted theta/phi sphereical\n",
    "    # coordinates.\n",
    "    sample_adj_idx = nearest_sphere_samples_idx[sample_idx].flatten()\n",
    "    sample_adj = torch.gather(s, 0, sample_adj_idx)\n",
    "    # Adjacent lobe labels\n",
    "    lobe_label_adj = torch.gather(lobe_labels, 0, sample_adj_idx)\n",
    "    # Some adjacent samples should not be considered such as when taking a sample from\n",
    "    # a hemisphere near the equator.\n",
    "    sample_adj_valid = nearest_sphere_samples_valid_mask[sample_idx].squeeze(0)\n",
    "\n",
    "    lobe_label_adj = lobe_label_adj * sample_adj_valid\n",
    "    # Find the number of adjacent lobes in such a way that is compatible with\n",
    "    # functorch.vmap().\n",
    "    # Sort the lobe labels themselves and and take the diff. The number of non-zero\n",
    "    # diffs is equal to the number of unique labels, +/- 1. The +/- 1 is determined\n",
    "    # by whether or not a $label_{l=0} - label_{l\\neq0}$ is responsible for one of the\n",
    "    # diffs being non-zero.\n",
    "    n_unique_adj_lobe_labels = (\n",
    "        (torch.diff(lobe_label_adj.sort().values) != 0).sum()\n",
    "        + 1\n",
    "        - 1 * (lobe_label_adj == 0).any(-1)  # indicator for any 0s being present.\n",
    "    )\n",
    "\n",
    "    # Now handle the 3 conditionals without any 'if' statements!\n",
    "    # 1. If no lobes are adjacent to this sample.\n",
    "    no_lobes_adj = torch.atleast_1d(n_unique_adj_lobe_labels == 0)\n",
    "    no_lobes_adj = i_sample_mask * no_lobes_adj\n",
    "    # If 0 lobes are adjacent, create a new lobe label and iterate on it.\n",
    "    # The masked_scatter_ in-place function is the best way to do assignment without\n",
    "    # casting Tensor indices to tuples, while combining multiple conditions...\n",
    "    lobe_labels.masked_scatter_(no_lobes_adj, curr_max_lobe_label + 1)\n",
    "    curr_max_lobe_label.masked_scatter_(no_lobes_adj.any(), curr_max_lobe_label + 1)\n",
    "\n",
    "    # 2. If 1 lobe is adjacent to this sample.\n",
    "    one_lobe_adj = torch.atleast_1d(n_unique_adj_lobe_labels == 1)\n",
    "    one_lobe_adj = i_sample_mask * one_lobe_adj\n",
    "    # If only 1 lobe is adjacent, assign the max (i.e., non-zero) adj lobe label.\n",
    "    lobe_labels.masked_scatter_(one_lobe_adj, lobe_label_adj.max())\n",
    "\n",
    "    # 3. If > 1 lobe is adjacent to this sample.\n",
    "    else_gt_1_lobe_adj = torch.atleast_1d(n_unique_adj_lobe_labels > 1)\n",
    "    else_gt_1_lobe_adj = i_sample_mask * else_gt_1_lobe_adj\n",
    "    # A 2D mask of n_samples x m_adj_samples can contain a label value/mask of all\n",
    "    # samples that correspond to a label value, for all adjacent samples.\n",
    "    adj_lobe_sample_mask = (\n",
    "        lobe_labels.expand(lobe_label_adj.shape[-1], -1).T == lobe_label_adj\n",
    "    ) * (lobe_label_adj != 0)\n",
    "    # For the samples adjacent to sample i, collect the samples that have previously\n",
    "    # been assigned a valid label.\n",
    "    samples_of_adj_lobe_labels = torch.masked_fill(\n",
    "        s.expand(lobe_label_adj.shape[-1], -1).T, ~adj_lobe_sample_mask, torch.nan\n",
    "    )\n",
    "    # Equivilent to a `nanmax` function.\n",
    "    adj_peaks = torch.nanquantile(samples_of_adj_lobe_labels, 1.0, dim=0)\n",
    "    adj_peaks = torch.nan_to_num(adj_peaks, nan=-torch.inf)\n",
    "    # adj_peaks = torch.masked.amax(samples_of_adj_lobe_labels, dim=-1)\n",
    "    adj_lobe_labels_idx_sorted_by_peaks = torch.argsort(adj_peaks)\n",
    "    # The min lobe label must not be 0, so we need to select the first non-zero lobe\n",
    "    # label. If there are 0 or 1 adjacent lobes, then we won't actually use this result,\n",
    "    # and instead consider *all* as unique lobes, and just grab a dummy index instead.\n",
    "    # Indexes into the original list of adjacent samples/directions.\n",
    "    min_lobe_label_adj_idx = torch.cat(\n",
    "        torch.where(\n",
    "            ~else_gt_1_lobe_adj.any(-1)  # prevents empty tensors when <= 1 adj lobes\n",
    "            | (lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks] != 0)\n",
    "        ),\n",
    "    )[0]\n",
    "    # Need both the smallest adjacent lobe (and its label), and the peak of that lobe.\n",
    "    min_lobe_label_adj = torch.gather(\n",
    "        lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks], 0, min_lobe_label_adj_idx\n",
    "    )\n",
    "    min_lobe_adj_peak = torch.gather(\n",
    "        adj_peaks[adj_lobe_labels_idx_sorted_by_peaks], 0, min_lobe_label_adj_idx\n",
    "    )\n",
    "    # We know that there exist at least 2 valid lobe labels, so select the label\n",
    "    # with the max peak.\n",
    "    max_lobe_label_adj = lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks][-1]\n",
    "    r = fod_sample / min_lobe_adj_peak.clamp_min(1e-6)\n",
    "    # 3.1 The difference between the current sample and the smallest peak of the\n",
    "    # adjacent lobes is < the user-defined threshold.\n",
    "    lobe_labels.masked_scatter_(\n",
    "        else_gt_1_lobe_adj & (r < peak_diff_threshold), max_lobe_label_adj\n",
    "    )\n",
    "\n",
    "    # 3.2 Same comparison as 3.1, but >= the user-defined threshold.\n",
    "    # Merge into the largest adjacent lobe, to keep the lobe indices sorted by peak\n",
    "    # values.\n",
    "    lobe_labels.masked_scatter_(\n",
    "        else_gt_1_lobe_adj & (r >= peak_diff_threshold), max_lobe_label_adj\n",
    "    )\n",
    "    # If the sample_i has > 1 adjacent lobes\n",
    "    # AND the ratio exceeds the threshold\n",
    "    # AND for each lobe label, is the label in the set of adjacent labels\n",
    "    # AND for each lobe label, is the label not 0\n",
    "    # then assign to the largest adjacent lobe.\n",
    "    lobe_labels.masked_scatter_(\n",
    "        else_gt_1_lobe_adj.any(-1)\n",
    "        & (r >= peak_diff_threshold)\n",
    "        & torch.isin(lobe_labels, lobe_label_adj)\n",
    "        & (lobe_labels != 0),\n",
    "        max_lobe_label_adj.expand(lobe_labels.shape[-1]),\n",
    "    )\n",
    "\n",
    "print(\"Pre-filter unique lobes:\", torch.unique(lobe_labels).shape)\n",
    "###! The below code does not work with vmap()\n",
    "# Filter out lobes that don't meet some criteria\n",
    "ll = torch.clone(lobe_labels[None])\n",
    "batch_s = s[None]\n",
    "batch_s_pdf = s_pdf[None]\n",
    "orig_unique_ll = ll.unique(dim=1)\n",
    "lobe_peaks = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_integrals = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_pdf_peaks = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_pdf_integrals = torch.zeros_like(orig_unique_ll).float()\n",
    "for i in range(orig_unique_ll.shape[1]):\n",
    "    l = orig_unique_ll[:, i]\n",
    "    # print(l.item(), end=\" \")\n",
    "    select_s = torch.where(ll == l, batch_s, torch.nan)\n",
    "    select_s_pdf = torch.where(ll == l, batch_s_pdf, torch.nan)\n",
    "    # print(ll == l, end=\" \")\n",
    "    lobe_peaks[:, i] = torch.nanquantile(select_s, 1.0, dim=1)\n",
    "    lobe_pdf_peaks[:, i] = torch.nanquantile(select_s_pdf, 1.0, dim=1)\n",
    "    # print(lobe_peaks[:, i], end=\" \")\n",
    "    lobe_integrals[:, i] = torch.nansum(select_s, dim=1)\n",
    "    lobe_pdf_integrals[:, i] = torch.nansum(select_s_pdf, dim=1)\n",
    "    lobe_labels_to_remove_mask = ~(select_s.isnan()) & (\n",
    "        (lobe_pdf_peaks[:, i] < min_lobe_pdf_peak_threshold)\n",
    "        | (lobe_pdf_integrals[:, i] < min_lobe_pdf_integral_threshold)\n",
    "    )\n",
    "    ll[lobe_labels_to_remove_mask] = 0\n",
    "\n",
    "    new_select_s = torch.where((ll == l) & (ll != 0), batch_s, torch.nan)\n",
    "    new_select_s_pdf = torch.where((ll == l) & (ll != 0), batch_s_pdf, torch.nan)\n",
    "    # print(ll == l, end=\" \")\n",
    "    lobe_peaks[:, i] = torch.nanquantile(new_select_s, 1.0, dim=1)\n",
    "    lobe_pdf_peaks[:, i] = torch.nanquantile(new_select_s, 1.0, dim=1)\n",
    "lobe_peaks.nan_to_num_(nan=-torch.inf)\n",
    "lobe_pdf_peaks.nan_to_num_(nan=0)\n",
    "\n",
    "# Re-map labels to be evenly-spaced, ascending index, in order of largest lobe\n",
    "# peak to smallest lobe peak. Performs batch-wise.\n",
    "sorted_lobe_peaks_idx = torch.argsort(lobe_peaks, dim=1, descending=True)\n",
    "sorted_lobe_peaks = lobe_peaks.gather(1, sorted_lobe_peaks_idx)\n",
    "sorted_lobe_labels = orig_unique_ll.gather(1, sorted_lobe_peaks_idx)\n",
    "i = 0\n",
    "new_label = 1\n",
    "reduced_lobe_peak_i = sorted_lobe_peaks[:, i]\n",
    "reduced_lobe_label_i = sorted_lobe_labels[:, i]\n",
    "while not reduced_lobe_peak_i.isneginf().all() and (reduced_lobe_peak_i > 0).all():\n",
    "    ll.masked_fill_(ll == reduced_lobe_label_i, new_label)\n",
    "    new_label += 1\n",
    "    i += 1\n",
    "    reduced_lobe_label_i = sorted_lobe_labels[:, i]\n",
    "    reduced_lobe_peak_i = sorted_lobe_peaks[:, i]\n",
    "\n",
    "print(ll)\n",
    "print(ll.unique())\n",
    "\n",
    "for l in ll.unique():\n",
    "    if l.item() == 0:\n",
    "        continue\n",
    "    print(\"l:\", l.item())\n",
    "    print(\"\\tpeak \", s[ll.flatten() == l].max().item())\n",
    "    print(\"\\tintegral \", s[ll.flatten() == l].sum().item())\n",
    "    print(\"\\tPDF peak \", s_pdf[ll.flatten() == l].max().item())\n",
    "    print(\"\\tPDF integral \", s_pdf[ll.flatten() == l].sum().item())\n",
    "\n",
    "# # DEBUG info\n",
    "# print(ll.unique())\n",
    "# for l in ll.unique(dim=1).T:\n",
    "#     # print(l.item(), end=\" \")\n",
    "#     select_s = torch.where(ll != l, torch.nan, batch_s)\n",
    "#     # print(ll == l, end=\" \")\n",
    "#     print(l.item(), torch.nanquantile(select_s, 1.0, dim=1).item())\n",
    "#     print(torch.nansum(select_s, dim=1).item())\n",
    "\n",
    "# # print(lobe_integrals)\n",
    "# print()\n",
    "# # print(lobe_labels.unique())\n",
    "# # print(lobe_labels.unique().shape)\n",
    "# for l in lobe_labels.unique():\n",
    "#     if l.item() == 0:\n",
    "#         continue\n",
    "#     lobe_peak = s[lobe_labels == l].max()\n",
    "#     lobe_peak_sample_idx = torch.cat(\n",
    "#         torch.where((s == lobe_peak) & (lobe_labels == l))\n",
    "#     )[0]\n",
    "#     # print(l.item(), \":\", lobe_peak.item(), lobe_peak_sample_idx.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipy.direction.peak_directions(\n",
    "    s.numpy(), sphere, relative_peak_threshold=0.4, min_separation_angle=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize lobe segmentation result\n",
    "# Plot 3D surface of odf.\n",
    "%matplotlib widget\n",
    "\n",
    "# \"surface\" or \"points\"\n",
    "to_plot = \"points\"\n",
    "post_seg_filter = True\n",
    "\n",
    "viz_sphere = sphere\n",
    "viz_theta, viz_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    viz_sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "polar_tri = mpl.tri.Triangulation(viz_phi, viz_theta)\n",
    "polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "\n",
    "# Take labels from pre-segmentation filtering.\n",
    "if not post_seg_filter:\n",
    "    viz_tri_labels = lobe_labels.flatten()[polar_tri_idx]\n",
    "else:\n",
    "    # Take labels from post-segmentation filtering.\n",
    "    viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "\n",
    "label_cmap = sns.cubehelix_palette(\n",
    "    n_colors=len(np.unique(viz_tri_labels.flatten())), reverse=True, rot=2, as_cmap=True\n",
    ")\n",
    "# viz_tri_labels = torch.mean(viz_tri_labels.float(), dim=1)\n",
    "viz_tri_labels = torch.median(viz_tri_labels, dim=1).values\n",
    "\n",
    "with torch.no_grad():\n",
    "    viz_coeffs = coeffs[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    viz_mask = mask[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    # Function applies non-negativity constraint.\n",
    "    viz_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        viz_coeffs,\n",
    "        theta=viz_theta,\n",
    "        phi=viz_phi,\n",
    "        sh_order=8,\n",
    "        sh_order_dim=0,\n",
    "        mask=viz_mask,\n",
    "    )\n",
    "\n",
    "viz_fodf = np.copy(viz_sphere_samples.detach().cpu().numpy().flatten())\n",
    "viz_tri_labels = viz_tri_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "viz_theta = viz_theta.detach().cpu().numpy().flatten()\n",
    "viz_phi = viz_phi.detach().cpu().numpy().flatten()\n",
    "directions, values, indices = dipy.direction.peak_directions(\n",
    "    viz_fodf, viz_sphere, relative_peak_threshold=0.5, min_separation_angle=25\n",
    ")\n",
    "# viz_fodf[viz_fodf < values.min() * 0.3] = 1e-8\n",
    "with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "    fig = plt.figure(dpi=120)\n",
    "\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    vals = viz_fodf\n",
    "\n",
    "    r = (vals - vals.min()) / (vals - vals.min()).max()\n",
    "    r = vals / vals.sum()\n",
    "\n",
    "    x = r * np.sin(viz_theta) * np.cos(viz_phi)\n",
    "    y = r * np.sin(viz_theta) * np.sin(viz_phi)\n",
    "    z = r * np.cos(viz_theta)\n",
    "    mapper = mpl.cm.ScalarMappable(cmap=label_cmap)\n",
    "\n",
    "    # center_colors = mapper.to_rgba(viz_tri_labels)\n",
    "    # center_colors = np.where((viz_tri_labels == 0)[:, None], np.zeros_like(center_colors), center_colors)\n",
    "    #     vertex_colors = mapper.to_rgba(ll.numpy().flatten()[polar_tri.edges])\n",
    "    # polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "    # viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "    euclid_tri = mpl.tri.Triangulation(x, y, triangles=polar_tri.triangles)\n",
    "    surf = ax.plot_trisurf(euclid_tri, z, linewidth=0.3, antialiased=True, zorder=4)\n",
    "\n",
    "    if to_plot == \"surface\":\n",
    "        face_colors = mapper.to_rgba(viz_tri_labels)\n",
    "        face_colors = np.where(\n",
    "            (viz_tri_labels == 0)[:, None], np.zeros_like(face_colors), face_colors\n",
    "        )\n",
    "        surf.set_fc(face_colors)\n",
    "    elif to_plot == \"points\":\n",
    "        surf.set_fc(\"white\")\n",
    "        surf.set_edgecolors([0.2, 0.2, 0.2, 0.5])\n",
    "        if post_seg_filter:\n",
    "            point_colors = mapper.to_rgba(ll.numpy().flatten())\n",
    "            point_colors = np.where(\n",
    "                (ll.numpy().flatten() == 0)[:, None],\n",
    "                np.zeros_like(point_colors),\n",
    "                point_colors,\n",
    "            )\n",
    "        else:\n",
    "            point_colors = mapper.to_rgba(lobe_labels.numpy().flatten())\n",
    "            point_colors = np.where(\n",
    "                (lobe_labels.numpy().flatten() == 0)[:, None],\n",
    "                np.zeros_like(point_colors),\n",
    "                point_colors,\n",
    "            )\n",
    "        ax.scatter3D(x, y, z, c=point_colors, s=20, zorder=0.1)\n",
    "    plt.colorbar(mapper, shrink=0.67)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot colored points on the surface of a unit [hemi]sphere.\n",
    "%matplotlib widget\n",
    "sph = sphere\n",
    "r = 1\n",
    "x = r * np.sin(sph.theta) * np.cos(sph.phi)\n",
    "y = r * np.sin(sph.theta) * np.sin(sph.phi)\n",
    "z = r * np.cos(sph.theta)\n",
    "with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "    fig = plt.figure(dpi=120)\n",
    "\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    ax.scatter3D(x, y, zs=z, marker=\".\", edgecolors=None, alpha=0.5)\n",
    "\n",
    "# fig.canvas.mpl_connect(\"close_event\", on_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3D surface of odf.\n",
    "%matplotlib widget\n",
    "\n",
    "# sphere = dipy.data.get_sphere(\"repulsion200\").subdivide(2)\n",
    "viz_sphere = dipy.data.get_sphere(\"repulsion724\").subdivide(2)\n",
    "viz_theta, viz_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    viz_sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "polar_tri = mpl.tri.Triangulation(viz_phi, viz_theta)\n",
    "polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "# Center coordinate of each triangle:\n",
    "barycenter_spherical_coords = torch.mean(\n",
    "    torch.stack([viz_phi[polar_tri_idx], viz_theta[polar_tri_idx]], dim=1), dim=2\n",
    ")\n",
    "# Set the center coordinate to just be the 0'th vertex in each triangle.\n",
    "# barycenter_spherical_coords = torch.stack(\n",
    "#         [viz_phi[polar_tri_idx], viz_theta[polar_tri_idx]],\n",
    "#         dim=1)[:, :, 0]\n",
    "center_theta = barycenter_spherical_coords[:, 1]\n",
    "center_phi = barycenter_spherical_coords[:, 0]\n",
    "# vox_idx = cc_lr_lobe_idx\n",
    "vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# vox_idx = tri_polar_lobe_idx\n",
    "with torch.no_grad():\n",
    "    viz_coeffs = coeffs[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    viz_mask = mask[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    # Function applies non-negativity constraint.\n",
    "    viz_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        viz_coeffs,\n",
    "        theta=viz_theta,\n",
    "        phi=viz_phi,\n",
    "        sh_order=8,\n",
    "        sh_order_dim=0,\n",
    "        mask=viz_mask,\n",
    "    )\n",
    "    viz_tri_center_samples = pitn.odf.sample_sphere_coords(\n",
    "        viz_coeffs,\n",
    "        theta=center_theta,\n",
    "        phi=center_phi,\n",
    "        sh_order=8,\n",
    "        sh_order_dim=0,\n",
    "        mask=viz_mask,\n",
    "    )\n",
    "\n",
    "viz_fodf = viz_sphere_samples.detach().cpu().numpy().flatten()\n",
    "viz_tri_center_fodf = viz_tri_center_samples.detach().cpu().numpy().flatten()\n",
    "viz_tri_center_theta = center_theta.detach().cpu().numpy().flatten()\n",
    "viz_tri_center_phi = center_phi.detach().cpu().numpy().flatten()\n",
    "\n",
    "viz_theta = viz_theta.detach().cpu().numpy().flatten()\n",
    "viz_phi = viz_phi.detach().cpu().numpy().flatten()\n",
    "directions, values, indices = dipy.direction.peak_directions(\n",
    "    viz_fodf, viz_sphere, relative_peak_threshold=0.5, min_separation_angle=25\n",
    ")\n",
    "viz_fodf[viz_fodf < values.min() * 0.3] = 1e-8\n",
    "with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "    fig = plt.figure(dpi=120)\n",
    "\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    vals = viz_fodf\n",
    "\n",
    "    r = (vals - vals.min()) / (vals - vals.min()).max()\n",
    "    r = vals / vals.sum()\n",
    "\n",
    "    x = r * np.sin(viz_theta) * np.cos(viz_phi)\n",
    "    y = r * np.sin(viz_theta) * np.sin(viz_phi)\n",
    "    z = r * np.cos(viz_theta)\n",
    "\n",
    "    norm = mpl.colors.Normalize(\n",
    "        vmin=viz_tri_center_fodf.min(), vmax=viz_tri_center_fodf.max()\n",
    "    )\n",
    "    mapper = mpl.cm.ScalarMappable(norm=norm, cmap=\"gnuplot\")\n",
    "    center_colors = mapper.to_rgba(viz_tri_center_fodf)\n",
    "    # face_colors = mapper.to_rgba(r)\n",
    "    # face_colors = np.random.uniform(0.0, 1.0, size=face_colors.shape)\n",
    "    # face_colors[:, 3] = 1.0\n",
    "    euclid_tri = mpl.tri.Triangulation(x, y, triangles=polar_tri.triangles)\n",
    "    # ax.plot_trisurf(x, y, z, triangles=tri.triangles, cmap=\"gnuplot\", alpha=1, linewidth=0)\n",
    "    # surf = ax.plot_trisurf(tri, z, antialiased=False, linewidth=0, cmap='gnuplot')\n",
    "    surf = ax.plot_trisurf(euclid_tri, z, antialiased=False, linewidth=0)\n",
    "    surf.set_fc(center_colors)\n",
    "    plt.colorbar(mapper, shrink=0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(dpi=200)\n",
    "norm = mpl.colors.Normalize(vmin=r.min(), vmax=r.max())\n",
    "mapper = mpl.cm.ScalarMappable(norm=norm, cmap=\"gnuplot\")\n",
    "face_colors = mapper.to_rgba(r)\n",
    "plt.triplot(polar_tri, lw=0.3, alpha=0.7)\n",
    "# plt.scatter(viz_phi, viz_theta, s=4, c=face_colors, marker='.')\n",
    "centers = np.mean(\n",
    "    np.stack([viz_phi[polar_tri.triangles], viz_theta[polar_tri.triangles]], axis=1),\n",
    "    axis=2,\n",
    ")\n",
    "center_vals = mpl.tri.LinearTriInterpolator(polar_tri, r)(centers[:, 0], centers[:, 1])\n",
    "center_colors = mapper.to_rgba(center_vals)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c=center_colors, marker=\".\", s=0.2)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FMLS Vectorized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch (Failed!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbatched_fmls_fodf_seg(\n",
    "    sphere_sample: torch.Tensor,\n",
    "    peak_diff_threshold: float,\n",
    "    min_lobe_pdf_peak_threshold: float,\n",
    "    min_lobe_pdf_integral_threshold: float,\n",
    "    min_sample_pdf_threshold: float = 0.001,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    # From\n",
    "    # R. E. Smith, J.-D. Tournier, F. Calamante, and A. Connelly,\n",
    "    # \"SIFT: Spherical-deconvolution informed filtering of tractograms,\" NeuroImage,\n",
    "    # vol. 67, pp. 298–312, Feb. 2013, doi: 10.1016/j.neuroimage.2012.11.049.\n",
    "\n",
    "    # Algorithm 1. in Appendix A of the SIFT paper.\n",
    "    # peak_diff_threshold = 0.8\n",
    "    # min_lobe_pdf_peak_threshold = 1e-5\n",
    "    # min_lobe_pdf_integral_threshold = 0.05\n",
    "\n",
    "    # s = torch.clone(sphere_samples[(slice(None),) + vox_idx])\n",
    "    s = sphere_sample\n",
    "\n",
    "    # Perform basic thresholding of the sample to remove noise.\n",
    "    # Normalize to a pdf to keep threshold values standardized across fodfs.\n",
    "    s_pdf = s - s.min()\n",
    "    s_pdf = s_pdf / s_pdf.sum()\n",
    "    s = torch.where(s_pdf >= min_sample_pdf_threshold, s, 0)\n",
    "    s_pdf = s - s.min()\n",
    "    s_pdf = s_pdf / s_pdf.sum()\n",
    "\n",
    "    lobe_labels = torch.zeros_like(s).to(torch.int16)\n",
    "    lobe_labels_index_space = torch.arange(lobe_labels.shape[0])\n",
    "\n",
    "    # Directions are sorted by absolute value, but the sign of their absolute value\n",
    "    # will be needed later.\n",
    "    # Get the indices of the sorted sample values, with each idx indexing into the\n",
    "    # directions/sample values on the spherical function.\n",
    "    sort_sample_idx = torch.argsort(torch.abs(s), dim=0, descending=True)\n",
    "    sort_sample_val = torch.gather(s, 0, sort_sample_idx)\n",
    "\n",
    "    # curr_max_lobe_label = lobe_labels.new_tensor([0])\n",
    "    curr_max_lobe_label = torch.tensor([0]).to(lobe_labels)\n",
    "    for i_sample, fod_sample, sample_idx in zip(\n",
    "        range(s.shape[-1]),\n",
    "        sort_sample_val[..., None],\n",
    "        sort_sample_idx[..., None],\n",
    "    ):\n",
    "        i_sample_mask = lobe_labels_index_space == sample_idx\n",
    "        # Get the 6 directions closest to the current sample direction by providing the\n",
    "        # current sample's index over the spherical function samples. These adjacent\n",
    "        # indices correspond to the unsorted sample values and unsorted theta/phi sphereical\n",
    "        # coordinates.\n",
    "        sample_adj_idx = nearest_sphere_samples_idx[sample_idx].flatten()\n",
    "        sample_adj = torch.gather(s, 0, sample_adj_idx)\n",
    "        # Adjacent lobe labels\n",
    "        lobe_label_adj = torch.gather(lobe_labels, 0, sample_adj_idx)\n",
    "        # Some adjacent samples should not be considered such as when taking a sample from\n",
    "        # a hemisphere near the equator.\n",
    "        sample_adj_valid = nearest_sphere_samples_valid_mask[sample_idx].squeeze(0)\n",
    "\n",
    "        lobe_label_adj = lobe_label_adj * sample_adj_valid\n",
    "        # Find the number of adjacent lobes in such a way that is compatible with\n",
    "        # functorch.vmap().\n",
    "        # Sort the lobe labels themselves and and take the diff. The number of non-zero\n",
    "        # diffs is equal to the number of unique labels, +/- 1. The +/- 1 is determined\n",
    "        # by whether or not a $label_{l=0} - label_{l\\neq0}$ is responsible for one of the\n",
    "        # diffs being non-zero.\n",
    "        n_unique_adj_lobe_labels = (\n",
    "            (torch.diff(lobe_label_adj.sort().values) != 0).sum()\n",
    "            + 1\n",
    "            - 1 * (lobe_label_adj == 0).any(-1)  # indicator for any 0s being present.\n",
    "        )\n",
    "\n",
    "        # Now handle the 3 conditionals without any 'if' statements!\n",
    "        # 1. If no lobes are adjacent to this sample.\n",
    "        no_lobes_adj = torch.atleast_1d(n_unique_adj_lobe_labels == 0)\n",
    "        no_lobes_adj = i_sample_mask * no_lobes_adj\n",
    "        # If 0 lobes are adjacent, create a new lobe label and iterate on it.\n",
    "        # The masked_scatter_ in-place function is the best way to do assignment without\n",
    "        # casting Tensor indices to tuples, while combining multiple conditions...\n",
    "        lobe_labels.masked_scatter_(no_lobes_adj, curr_max_lobe_label + 1)\n",
    "        # curr_max_lobe_label.masked_scatter_(\n",
    "        #     no_lobes_adj.any(-1), curr_max_lobe_label + 1\n",
    "        # )\n",
    "        curr_max_lobe_label = torch.masked_scatter(\n",
    "            curr_max_lobe_label, no_lobes_adj.any(-1), curr_max_lobe_label + 1\n",
    "        )\n",
    "        # 2. If 1 lobe is adjacent to this sample.\n",
    "        one_lobe_adj = torch.atleast_1d(n_unique_adj_lobe_labels == 1)\n",
    "        one_lobe_adj = i_sample_mask * one_lobe_adj\n",
    "        # If only 1 lobe is adjacent, assign the max (i.e., non-zero) adj lobe label.\n",
    "        lobe_labels.masked_scatter_(one_lobe_adj, lobe_label_adj.max())\n",
    "\n",
    "        # 3. If > 1 lobe is adjacent to this sample.\n",
    "        else_gt_1_lobe_adj = torch.atleast_1d(n_unique_adj_lobe_labels > 1)\n",
    "        else_gt_1_lobe_adj = i_sample_mask * else_gt_1_lobe_adj\n",
    "        # A 2D mask of n_samples x m_adj_samples can contain a label value/mask of all\n",
    "        # samples that correspond to a label value, for all adjacent samples.\n",
    "        adj_lobe_sample_mask = (\n",
    "            lobe_labels.expand(lobe_label_adj.shape[-1], -1).T == lobe_label_adj\n",
    "        ) * (lobe_label_adj != 0)\n",
    "        # For the samples adjacent to sample i, collect the samples that have previously\n",
    "        # been assigned a valid label.\n",
    "        samples_of_adj_lobe_labels = torch.masked_fill(\n",
    "            s.expand(lobe_label_adj.shape[-1], -1).T, ~adj_lobe_sample_mask, torch.nan\n",
    "        )\n",
    "        # Equivilent to a `nanmax` function.\n",
    "        adj_peaks = torch.nanquantile(samples_of_adj_lobe_labels, 1.0, dim=0)\n",
    "        adj_peaks = torch.nan_to_num(adj_peaks, nan=-torch.inf)\n",
    "        # adj_peaks = torch.masked.amax(samples_of_adj_lobe_labels, dim=-1)\n",
    "        adj_lobe_labels_idx_sorted_by_peaks = torch.argsort(adj_peaks)\n",
    "        # The min lobe label must not be 0, so we need to select the first non-zero lobe\n",
    "        # label. If there are 0 or 1 adjacent lobes, then we won't actually use this result,\n",
    "        # and instead consider *all* as unique lobes, and just grab a dummy index instead.\n",
    "        # Indexes into the original list of adjacent samples/directions.\n",
    "        min_lobe_label_adj_idx = torch.cat(\n",
    "            torch.where(\n",
    "                ~else_gt_1_lobe_adj.any(\n",
    "                    -1\n",
    "                )  # prevents empty tensors when <= 1 adj lobes\n",
    "                | (lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks] != 0)\n",
    "            ),\n",
    "        )[0]\n",
    "        # Need both the smallest adjacent lobe (and its label), and the peak of that lobe.\n",
    "        min_lobe_label_adj = torch.gather(\n",
    "            lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks],\n",
    "            0,\n",
    "            min_lobe_label_adj_idx,\n",
    "        )\n",
    "        min_lobe_adj_peak = torch.gather(\n",
    "            adj_peaks[adj_lobe_labels_idx_sorted_by_peaks], 0, min_lobe_label_adj_idx\n",
    "        )\n",
    "        # We know that there exist at least 2 valid lobe labels, so select the label\n",
    "        # with the max peak.\n",
    "        max_lobe_label_adj = lobe_label_adj[adj_lobe_labels_idx_sorted_by_peaks][-1]\n",
    "        r = fod_sample / min_lobe_adj_peak.clamp_min(1e-6)\n",
    "        # 3.1 The difference between the current sample and the smallest peak of the\n",
    "        # adjacent lobes is < the user-defined threshold.\n",
    "        lobe_labels.masked_scatter_(\n",
    "            else_gt_1_lobe_adj & (r < peak_diff_threshold), max_lobe_label_adj\n",
    "        )\n",
    "\n",
    "        # 3.2 Same comparison as 3.1, but >= the user-defined threshold.\n",
    "        # Merge into the largest adjacent lobe, to keep the lobe indices sorted by peak\n",
    "        # values.\n",
    "        lobe_labels.masked_scatter_(\n",
    "            else_gt_1_lobe_adj & (r >= peak_diff_threshold), max_lobe_label_adj\n",
    "        )\n",
    "        # If the sample_i has > 1 adjacent lobes\n",
    "        # AND the ratio exceeds the threshold\n",
    "        # AND for each lobe label, is the label in the set of adjacent labels\n",
    "        # AND for each lobe label, is the label not 0\n",
    "        # then assign to the largest adjacent lobe.\n",
    "        lobe_labels.masked_scatter_(\n",
    "            else_gt_1_lobe_adj.any(-1)\n",
    "            & (r >= peak_diff_threshold)\n",
    "            & torch.isin(lobe_labels, lobe_label_adj)\n",
    "            & (lobe_labels != 0),\n",
    "            max_lobe_label_adj.expand(lobe_labels.shape[-1]),\n",
    "        )\n",
    "\n",
    "    return lobe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single voxel lobe segmentation\n",
    "vox_idx = cc_lr_lobe_idx\n",
    "# vox_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# vox_idx = tri_polar_lobe_idx\n",
    "\n",
    "peak_diff_threshold = 0.8\n",
    "min_lobe_pdf_peak_threshold = 1e-5\n",
    "min_lobe_pdf_integral_threshold = 0.05\n",
    "\n",
    "s = torch.clone(sphere_samples[(slice(None),) + vox_idx])\n",
    "\n",
    "ll = unbatched_fmls_fodf_seg(\n",
    "    s,\n",
    "    peak_diff_threshold=peak_diff_threshold,\n",
    "    min_lobe_pdf_peak_threshold=min_lobe_pdf_peak_threshold,\n",
    "    min_lobe_pdf_integral_threshold=min_lobe_pdf_integral_threshold,\n",
    ")\n",
    "print(ll.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Does not work!\n",
    "# v0_idx = lr_and_ap_bipolar_lobe_idx\n",
    "# v1_idx = cc_lr_lobe_idx\n",
    "# s = torch.stack(\n",
    "#     [sphere_samples[(slice(None),) + v0_idx], sphere_samples[(slice(None),) + v1_idx]]\n",
    "# )\n",
    "# b_ll = functorch.vmap(unbatched_fmls_fodf_seg)(\n",
    "#     s,\n",
    "#     peak_diff_threshold=peak_diff_threshold,\n",
    "#     min_lobe_pdf_peak_threshold=min_lobe_pdf_peak_threshold,\n",
    "#     min_lobe_pdf_integral_threshold=min_lobe_pdf_integral_threshold,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jax\n",
    "torch -> dlpack -> jax -> dlpack -> torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _jax_unbatched_fmls_fodf_seg(\n",
    "    sphere_sample: jax.Array,\n",
    "    nearest_sphere_samples_idx: jax.Array,\n",
    "    nearest_sphere_samples_valid_mask: jax.Array,\n",
    "    peak_diff_threshold: float,\n",
    ") -> jax.Array:\n",
    "\n",
    "    # From\n",
    "    # R. E. Smith, J.-D. Tournier, F. Calamante, and A. Connelly,\n",
    "    # \"SIFT: Spherical-deconvolution informed filtering of tractograms,\" NeuroImage,\n",
    "    # vol. 67, pp. 298–312, Feb. 2013, doi: 10.1016/j.neuroimage.2012.11.049.\n",
    "    # Algorithm 1. in Appendix A.\n",
    "    s = sphere_sample\n",
    "\n",
    "    lobe_labels = jnp.zeros_like(s, dtype=jnp.int16)\n",
    "    lobe_labels_index_space = jnp.arange(lobe_labels.shape[0])\n",
    "    # Directions are sorted by absolute value, but the sign of their absolute value\n",
    "    # will be needed later.\n",
    "    # Get the indices of the sorted sample values, with each idx indexing into the\n",
    "    # directions/sample values on the spherical function.\n",
    "    sort_sample_idx = jnp.flip(jnp.argsort(jnp.abs(s)).astype(jnp.int16))\n",
    "    sort_sample_val = jnp.take(s, sort_sample_idx)\n",
    "\n",
    "    curr_max_lobe_label = 0\n",
    "\n",
    "    def fmls_loop_body_fn(\n",
    "        i_sample: int,\n",
    "        state: dict,\n",
    "        s,\n",
    "        peak_diff_threshold,\n",
    "        sort_sample_val,\n",
    "        sort_sample_idx,\n",
    "        lobe_labels_index_space,\n",
    "        nearest_sphere_samples_idx,\n",
    "        nearest_sphere_samples_valid_mask,\n",
    "    ) -> dict:\n",
    "\n",
    "        lobe_labels = state[\"lobe_labels\"]\n",
    "        curr_max_lobe_label = state[\"curr_max_lobe_label\"]\n",
    "\n",
    "        # i_sample gives the array index in the *sorted* fod samples, but we also need\n",
    "        # the current sample's index from the original *unsorted* array of fod samples.\n",
    "        idx_in_unsort_samples = sort_sample_idx[i_sample]\n",
    "\n",
    "        # Get the 6 directions closest to the current sample direction by providing the\n",
    "        # current sample's index over the spherical function samples. These adjacent\n",
    "        # indices correspond to the unsorted sample values and unsorted theta/phi sphereical\n",
    "        # coordinates.\n",
    "        sample_adj_idx = nearest_sphere_samples_idx[idx_in_unsort_samples]\n",
    "        sample_adj = jnp.take(s, sample_adj_idx)\n",
    "        # Adjacent lobe labels\n",
    "        adj_lobe_label = jnp.take(lobe_labels, sample_adj_idx)\n",
    "        # Some adjacent samples should not be considered such as when taking a sample from\n",
    "        # a hemisphere near the equator.\n",
    "        sample_adj_valid = nearest_sphere_samples_valid_mask[idx_in_unsort_samples]\n",
    "\n",
    "        adj_lobe_label = adj_lobe_label * sample_adj_valid\n",
    "        # Find the number of adjacent lobes in such a way that is compatible with\n",
    "        # auto vectorization.\n",
    "        # Sort the lobe labels themselves and and take the diff. The number of non-zero\n",
    "        # diffs is equal to the number of unique labels, +/- 1. The +/- 1 is determined\n",
    "        # by whether or not a $label_{l=0} - label_{l\\neq0}$ is responsible for one of the\n",
    "        # diffs being non-zero.\n",
    "        n_unique_adj_lobe_labels = (\n",
    "            (jnp.diff(adj_lobe_label.sort()) != 0).sum()\n",
    "            + 1\n",
    "            - 1 * (adj_lobe_label == 0).any()  # indicator for any 0s being present.\n",
    "        )\n",
    "\n",
    "        # Now handle the 3 conditionals without any explicit 'if' statements!\n",
    "        # 1. If no lobes are adjacent to this sample.\n",
    "        def zero_lobes_adj_fn(\n",
    "            s,\n",
    "            peak_diff_threshold,\n",
    "            idx_in_unsort_samples,\n",
    "            adj_lobe_label,\n",
    "            lobe_labels,\n",
    "            curr_max_lobe_label,\n",
    "        ) -> dict:\n",
    "            # If 0 lobes are adjacent, create a new lobe label and iterate on it.\n",
    "            lobe_labels = lobe_labels.at[idx_in_unsort_samples].set(\n",
    "                curr_max_lobe_label + 1\n",
    "            )\n",
    "            curr_max_lobe_label = curr_max_lobe_label + 1\n",
    "\n",
    "            return dict(\n",
    "                lobe_labels=lobe_labels, curr_max_lobe_label=curr_max_lobe_label\n",
    "            )\n",
    "\n",
    "        # 2. If 1 lobe is adjacent to this sample.\n",
    "        def one_lobe_adj_fn(\n",
    "            s,\n",
    "            peak_diff_threshold,\n",
    "            idx_in_unsort_samples,\n",
    "            adj_lobe_label,\n",
    "            lobe_labels,\n",
    "            curr_max_lobe_label,\n",
    "        ) -> dict:\n",
    "            # If only 1 lobe is adjacent, assign the max (i.e., non-zero) adj lobe label.\n",
    "            only_adj_label = adj_lobe_label.max()\n",
    "            lobe_labels = lobe_labels.at[idx_in_unsort_samples].set(only_adj_label)\n",
    "            return dict(\n",
    "                lobe_labels=lobe_labels, curr_max_lobe_label=curr_max_lobe_label\n",
    "            )\n",
    "\n",
    "        # 3. If > 1 lobe is adjacent to this sample.\n",
    "        def gt_one_lobe_adj_fn(\n",
    "            s,\n",
    "            peak_diff_threshold,\n",
    "            idx_in_unsort_samples,\n",
    "            adj_lobe_label,\n",
    "            lobe_labels,\n",
    "            curr_max_lobe_label,\n",
    "        ) -> dict:\n",
    "\n",
    "            # A 2D mask of n_samples x m_adj_samples can contain a label value/mask of all\n",
    "            # samples that correspond to a label value, for all labels in adjacent\n",
    "            # samples.\n",
    "            max_num_adj_lobes = adj_lobe_label.shape[-1]\n",
    "            adj_lobe_sample_mask = (\n",
    "                jnp.tile(lobe_labels, (max_num_adj_lobes, 1)).T == adj_lobe_label\n",
    "            ) * (adj_lobe_label != 0)\n",
    "            # adj_lobe_sample_mask = (\n",
    "            #     lobe_labels.expand(adj_lobe_label.shape[-1], -1).T == adj_lobe_label\n",
    "            # ) * (adj_lobe_label != 0)\n",
    "            # For the samples adjacent to sample i, collect the samples that have previously\n",
    "            # been assigned a valid label.\n",
    "            samples_of_adj_lobe_labels = jnp.where(\n",
    "                adj_lobe_sample_mask, jnp.tile(s, (max_num_adj_lobes, 1)).T, jnp.nan\n",
    "            )\n",
    "            # samples_of_adj_lobe_labels = torch.masked_fill(\n",
    "            #     s.expand(adj_lobe_label.shape[-1], -1).T, ~adj_lobe_sample_mask, torch.nan\n",
    "            # )\n",
    "            # Take the max sample value over each adjacent lobe label, even the\n",
    "            # \"invalid\" labels (=0).\n",
    "            adj_peaks = jnp.nanmax(samples_of_adj_lobe_labels, axis=0)\n",
    "            # adj_peaks = torch.nanquantile(samples_of_adj_lobe_labels, 1.0, dim=0)\n",
    "            # adj_peaks = jnp.nan_to_num(adj_peaks, nan=-jnp.inf)\n",
    "            # adj_peaks = torch.masked.amax(samples_of_adj_lobe_labels, dim=-1)\n",
    "            # adj_lobe_labels_idx_sorted_by_peaks = torch.argsort(adj_peaks)\n",
    "            # The min lobe label must not be 0, so we need to select the first non-zero lobe\n",
    "            # label.\n",
    "            min_adj_lobe_label_idx = jnp.nanargmin(adj_peaks)\n",
    "            # min_adj_lobe_label_idx = torch.cat(\n",
    "            #     torch.where(\n",
    "            #         ~else_gt_1_lobe_adj.any(\n",
    "            #             -1\n",
    "            #         )  # prevents empty tensors when <= 1 adj lobes\n",
    "            #         | (adj_lobe_label[adj_lobe_labels_idx_sorted_by_peaks] != 0)\n",
    "            #     ),\n",
    "            # )[0]\n",
    "            # Need both the smallest adjacent lobe (and its label), and the peak of that lobe.\n",
    "            min_adj_lobe_label = adj_lobe_label[min_adj_lobe_label_idx]\n",
    "            min_adj_lobe_peak = adj_peaks[min_adj_lobe_label_idx]\n",
    "            # min_adj_lobe_label = torch.gather(\n",
    "            #     adj_lobe_label[adj_lobe_labels_idx_sorted_by_peaks],\n",
    "            #     0,\n",
    "            #     min_adj_lobe_label_idx,\n",
    "            # )\n",
    "            # min_lobe_adj_peak = torch.gather(\n",
    "            #     adj_peaks[adj_lobe_labels_idx_sorted_by_peaks],\n",
    "            #     0,\n",
    "            #     min_adj_lobe_label_idx,\n",
    "            # )\n",
    "            max_adj_lobe_label = adj_lobe_label[jnp.nanargmax(adj_peaks)]\n",
    "            # max_adj_lobe_label = adj_lobe_label[adj_lobe_labels_idx_sorted_by_peaks][-1]\n",
    "            fod_sample = s[idx_in_unsort_samples]\n",
    "            r = fod_sample / jnp.clip(min_adj_lobe_peak, 1e-6, jnp.inf)\n",
    "\n",
    "            # 3.1 The difference between the current sample and the smallest peak of the\n",
    "            # adjacent lobes is < the user-defined threshold.\n",
    "            def _assign_largest(lobe_l, s_idx, adj_s_mask, large_l):\n",
    "                return lobe_l.at[s_idx].set(large_l)\n",
    "\n",
    "            # 3.2 Same comparison as 3.1, but >= the user-defined threshold.\n",
    "            # Merge into the largest adjacent lobe, to keep the lobe indices sorted by peak\n",
    "            # values.\n",
    "            def _merge_adj(lobe_l, s_idx, adj_s_mask, large_l):\n",
    "                return jnp.where(adj_s_mask.at[s_idx].set(True), large_l, lobe_l)\n",
    "\n",
    "            lobe_labels = lax.cond(\n",
    "                r < peak_diff_threshold,\n",
    "                _assign_largest,\n",
    "                _merge_adj,\n",
    "                lobe_labels,\n",
    "                idx_in_unsort_samples,\n",
    "                jnp.sometrue(adj_lobe_sample_mask, axis=1),  # Collapse adj labels.\n",
    "                max_adj_lobe_label,\n",
    "            )\n",
    "            # lobe_labels.masked_scatter_(\n",
    "            #     else_gt_1_lobe_adj & (r < peak_diff_threshold), max_adj_lobe_label\n",
    "            # )\n",
    "\n",
    "            # lobe_labels.masked_scatter_(\n",
    "            #     else_gt_1_lobe_adj & (r >= peak_diff_threshold), max_adj_lobe_label\n",
    "            # )\n",
    "            # # If the sample_i has > 1 adjacent lobes\n",
    "            # # AND the ratio exceeds the threshold\n",
    "            # # AND for each lobe label, is the label in the set of adjacent labels\n",
    "            # # AND for each lobe label, is the label not 0\n",
    "            # # then assign to the largest adjacent lobe.\n",
    "            # lobe_labels.masked_scatter_(\n",
    "            #     else_gt_1_lobe_adj.any(-1)\n",
    "            #     & (r >= peak_diff_threshold)\n",
    "            #     & torch.isin(lobe_labels, adj_lobe_label)\n",
    "            #     & (lobe_labels != 0),\n",
    "            #     max_adj_lobe_label.expand(lobe_labels.shape[-1]),\n",
    "            # )\n",
    "            return dict(\n",
    "                lobe_labels=lobe_labels, curr_max_lobe_label=curr_max_lobe_label\n",
    "            )\n",
    "\n",
    "        segment_state_i = lax.switch(\n",
    "            jnp.clip(n_unique_adj_lobe_labels, 0, 2),\n",
    "            (zero_lobes_adj_fn, one_lobe_adj_fn, gt_one_lobe_adj_fn),\n",
    "            s,\n",
    "            peak_diff_threshold,\n",
    "            idx_in_unsort_samples,\n",
    "            adj_lobe_label,\n",
    "            lobe_labels,\n",
    "            curr_max_lobe_label,\n",
    "        )\n",
    "        lobe_labels_i = segment_state_i[\"lobe_labels\"]\n",
    "        curr_max_lobe_label_i = segment_state_i[\"curr_max_lobe_label\"]\n",
    "\n",
    "        return dict(\n",
    "            lobe_labels=lobe_labels_i, curr_max_lobe_label=curr_max_lobe_label_i\n",
    "        )\n",
    "\n",
    "    state_0 = dict(\n",
    "        lobe_labels=lobe_labels,\n",
    "        curr_max_lobe_label=curr_max_lobe_label,\n",
    "    )\n",
    "    # Most parameters are constant over the loop, so just fill those in with a partial\n",
    "    # function call.\n",
    "    body_fn_with_consts = partial(\n",
    "        fmls_loop_body_fn,\n",
    "        s=s,\n",
    "        peak_diff_threshold=peak_diff_threshold,\n",
    "        sort_sample_val=sort_sample_val,\n",
    "        sort_sample_idx=sort_sample_idx,\n",
    "        lobe_labels_index_space=lobe_labels_index_space,\n",
    "        nearest_sphere_samples_idx=nearest_sphere_samples_idx,\n",
    "        nearest_sphere_samples_valid_mask=nearest_sphere_samples_valid_mask,\n",
    "    )\n",
    "\n",
    "    t_max = jnp.where(sort_sample_val <= 0, jnp.arange(1, s.shape[0] + 1), jnp.nan)\n",
    "    t_max = jnp.nanmin(t_max).astype(int)\n",
    "    state_t = lax.fori_loop(0, t_max, body_fun=body_fn_with_consts, init_val=state_0)\n",
    "    lobe_labels = state_t[\"lobe_labels\"]\n",
    "\n",
    "    # Labels are already in descending order by peak value, but they are not contiguous.\n",
    "    # We can use the diff(sort(...)) trick as above to remap to contiguous, sorted\n",
    "    # lobe segmentation labels.\n",
    "    label_sorted_idx = jnp.argsort(lobe_labels)\n",
    "    unsort_label_idx = jnp.argsort(label_sorted_idx)\n",
    "    lobe_labels = jnp.cumsum(\n",
    "        jnp.diff(lobe_labels.at[label_sorted_idx].get(), prepend=0) > 0\n",
    "    )\n",
    "    lobe_labels = lobe_labels.at[unsort_label_idx].get()\n",
    "\n",
    "    return lobe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.clone(sphere_samples[(slice(None),) + vox_idx])\n",
    "# Perform basic thresholding of the sample to remove noise.\n",
    "# Normalize to a pdf to keep threshold values standardized across fodfs.\n",
    "s_pdf = s - s.min()\n",
    "s_pdf = s_pdf / s_pdf.sum()\n",
    "s = torch.where(s_pdf < min_sample_pdf_threshold, 0, s)\n",
    "# Update PDF.\n",
    "s_pdf = s - s.min()\n",
    "s_pdf = s_pdf / s_pdf.sum()\n",
    "\n",
    "sjx = jax.dlpack.from_dlpack(torch.utils.dlpack.to_dlpack(s))\n",
    "\n",
    "near_sph_samples_idx_jx = jax.dlpack.from_dlpack(\n",
    "    torch.utils.dlpack.to_dlpack(nearest_sphere_samples_idx.contiguous())\n",
    ")\n",
    "near_sph_samples_valid_mask_jx = jax.dlpack.from_dlpack(\n",
    "    torch.utils.dlpack.to_dlpack(\n",
    "        nearest_sphere_samples_valid_mask.contiguous().to(torch.int8)\n",
    "    )\n",
    ").astype(bool)\n",
    "\n",
    "ll_jax = _jax_unbatched_fmls_fodf_seg(\n",
    "    sjx,\n",
    "    nearest_sphere_samples_idx=near_sph_samples_idx_jx,\n",
    "    nearest_sphere_samples_valid_mask=near_sph_samples_valid_mask_jx,\n",
    "    peak_diff_threshold=peak_diff_threshold,\n",
    ")\n",
    "print(ll_jax)\n",
    "np.unique(ll_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 3 2 2]\n",
      " [0 0 0 ... 3 2 2]]\n",
      "(2, 1445)\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "jax_batched_fmls_fodf_seg_fn = jax.jit(\n",
    "    jax.vmap(_jax_unbatched_fmls_fodf_seg, in_axes=(0, None, None, None))\n",
    ")\n",
    "# jax transformed functions force in_axes=0 for all keyword-passed arguments! So, all\n",
    "# non-batched-over arguments must be passed by position! (Something to do with the\n",
    "# difficulty/fragility in parsing argument position in a function call in Python?)\n",
    "batched_ll_jax = jax_batched_fmls_fodf_seg_fn(\n",
    "    jnp.stack([sjx, sjx], 0),\n",
    "    # sjx[None],\n",
    "    near_sph_samples_idx_jx,\n",
    "    near_sph_samples_valid_mask_jx,\n",
    "    peak_diff_threshold,\n",
    ")\n",
    "print(batched_ll_jax)\n",
    "print(batched_ll_jax.shape)\n",
    "print(jnp.unique(batched_ll_jax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ll = torch.utils.dlpack.from_dlpack(\n",
    "    jax.dlpack.to_dlpack(batched_ll_jax, take_ownership=True)\n",
    ")\n",
    "batch_s = torch.stack([s, s], 0)\n",
    "batch_s_pdf = torch.stack([s_pdf, s_pdf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 3, 2, 2],\n",
      "        [0, 0, 0,  ..., 3, 2, 2]])\n",
      "tensor([0, 1, 2, 3])\n",
      "l: 1\n",
      "\tpeak  tensor([0.2178, 0.2178], dtype=torch.float64)\n",
      "\tintegral  tensor([22.9726, 22.9726], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0031, 0.0031], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.3242, 0.3242], dtype=torch.float64)\n",
      "l: 2\n",
      "\tpeak  tensor([0.1915, 0.1915], dtype=torch.float64)\n",
      "\tintegral  tensor([20.6128, 20.6128], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0027, 0.0027], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.2909, 0.2909], dtype=torch.float64)\n",
      "l: 3\n",
      "\tpeak  tensor([0.1796, 0.1796], dtype=torch.float64)\n",
      "\tintegral  tensor([22.9089, 22.9089], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0025, 0.0025], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.3233, 0.3233], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###! The below code does not work with vmap()\n",
    "# Filter out lobes that don't meet some criteria\n",
    "pre_filter_lobe_labels = torch.clone(batched_ll)\n",
    "ll = torch.clone(batched_ll)\n",
    "orig_unique_ll = ll.unique(dim=1)\n",
    "lobe_peaks = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_integrals = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_pdf_peaks = torch.zeros_like(orig_unique_ll).float()\n",
    "lobe_pdf_integrals = torch.zeros_like(orig_unique_ll).float()\n",
    "for i in range(orig_unique_ll.shape[1]):\n",
    "    l = orig_unique_ll[:, i, None]\n",
    "    # print(l.item(), end=\" \")\n",
    "    select_s = torch.where(ll == l, batch_s, torch.nan)\n",
    "    select_s_pdf = torch.where(ll == l, batch_s_pdf, torch.nan)\n",
    "    # print(ll == l, end=\" \")\n",
    "    lobe_peaks[:, i] = torch.nanquantile(select_s, 1.0, dim=1)\n",
    "    lobe_pdf_peaks[:, i] = torch.nanquantile(select_s_pdf, 1.0, dim=1)\n",
    "    # print(lobe_peaks[:, i], end=\" \")\n",
    "    lobe_integrals[:, i] = torch.nansum(select_s, dim=1)\n",
    "    lobe_pdf_integrals[:, i] = torch.nansum(select_s_pdf, dim=1)\n",
    "    lobe_labels_to_remove_mask = ~(select_s.isnan()) & (\n",
    "        (lobe_pdf_peaks[:, i, None] < min_lobe_pdf_peak_threshold)\n",
    "        | (lobe_pdf_integrals[:, i, None] < min_lobe_pdf_integral_threshold)\n",
    "    )\n",
    "    ll[lobe_labels_to_remove_mask] = 0\n",
    "\n",
    "    new_select_s = torch.where((ll == l) & (ll != 0), batch_s, torch.nan)\n",
    "    new_select_s_pdf = torch.where((ll == l) & (ll != 0), batch_s_pdf, torch.nan)\n",
    "    # print(ll == l, end=\" \")\n",
    "    lobe_peaks[:, i] = torch.nanquantile(new_select_s, 1.0, dim=1)\n",
    "    lobe_pdf_peaks[:, i] = torch.nanquantile(new_select_s, 1.0, dim=1)\n",
    "lobe_peaks.nan_to_num_(nan=-torch.inf)\n",
    "lobe_pdf_peaks.nan_to_num_(nan=0)\n",
    "\n",
    "# Re-map labels to be evenly-spaced, ascending index, in order of largest lobe\n",
    "# peak to smallest lobe peak. Performs batch-wise.\n",
    "sorted_lobe_peaks_idx = torch.argsort(lobe_peaks, dim=1, descending=True)\n",
    "sorted_lobe_peaks = lobe_peaks.gather(1, sorted_lobe_peaks_idx)\n",
    "sorted_lobe_labels = orig_unique_ll.gather(1, sorted_lobe_peaks_idx)\n",
    "i = 0\n",
    "new_label = 1\n",
    "reduced_lobe_peak_i = sorted_lobe_peaks[:, i, None]\n",
    "reduced_lobe_label_i = sorted_lobe_labels[:, i, None]\n",
    "while not reduced_lobe_peak_i.isneginf().all() and (reduced_lobe_peak_i > 0).all():\n",
    "    ll.masked_fill_(ll == reduced_lobe_label_i, new_label)\n",
    "    new_label += 1\n",
    "    i += 1\n",
    "    reduced_lobe_label_i = sorted_lobe_labels[:, i, None]\n",
    "    reduced_lobe_peak_i = sorted_lobe_peaks[:, i, None]\n",
    "\n",
    "print(ll)\n",
    "print(ll.unique())\n",
    "\n",
    "for l in ll.unique():\n",
    "    if l.item() == 0:\n",
    "        continue\n",
    "    print(\"l:\", l.item())\n",
    "    print(\"\\tpeak \", (batch_s * (ll == l)).max(1).values)\n",
    "    print(\"\\tintegral \", (batch_s * (ll == l)).sum(1))\n",
    "    print(\"\\tPDF peak \", (batch_s_pdf * (ll == l)).max(1).values)\n",
    "    print(\"\\tPDF integral \", (batch_s_pdf * (ll == l)).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "l: 1\n",
      "\tpeak  tensor([0.2178, 0.2178], dtype=torch.float64)\n",
      "\tintegral  tensor([22.9726, 22.9726], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0031, 0.0031], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.3242, 0.3242], dtype=torch.float64)\n",
      "2\n",
      "l: 2\n",
      "\tpeak  tensor([0.1915, 0.1915], dtype=torch.float64)\n",
      "\tintegral  tensor([20.6128, 20.6128], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0027, 0.0027], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.2909, 0.2909], dtype=torch.float64)\n",
      "3\n",
      "l: 3\n",
      "\tpeak  tensor([0.1796, 0.1796], dtype=torch.float64)\n",
      "\tintegral  tensor([22.9089, 22.9089], dtype=torch.float64)\n",
      "\tPDF peak  tensor([0.0025, 0.0025], dtype=torch.float64)\n",
      "\tPDF integral  tensor([0.3233, 0.3233], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_refine_ll = pitn.tract.peak.remove_fodf_labels_by_pdf(\n",
    "    batched_ll, batch_s, 1e-5, 0.05\n",
    ")\n",
    "\n",
    "for l in test_refine_ll.unique():\n",
    "    print(l.item())\n",
    "    if l.item() == 0:\n",
    "        continue\n",
    "    print(\"l:\", l.item())\n",
    "    print(\"\\tpeak \", (batch_s * (test_refine_ll == l)).max(1).values)\n",
    "    print(\"\\tintegral \", (batch_s * (test_refine_ll == l)).sum(1))\n",
    "    print(\"\\tPDF peak \", (batch_s_pdf * (test_refine_ll == l)).max(1).values)\n",
    "    print(\"\\tPDF integral \", (batch_s_pdf * (test_refine_ll == l)).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.65420586, -0.71558175,  0.24486211],\n",
       "        [ 0.59421223, -0.79664681,  0.11075059],\n",
       "        [-0.90070296,  0.41452208,  0.13002165]]),\n",
       " array([0.21784081, 0.19147219, 0.17525571]),\n",
       " array([653, 537, 212]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dipy.direction.peak_directions(\n",
    "    s.numpy(), sphere, relative_peak_threshold=0.4, min_separation_angle=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize lobe segmentation result\n",
    "# Plot 3D surface of odf.\n",
    "%matplotlib widget\n",
    "\n",
    "# \"surface\" or \"points\"\n",
    "to_plot = \"points\"\n",
    "post_seg_filter = True\n",
    "\n",
    "viz_sphere = sphere\n",
    "viz_theta, viz_phi = pitn.odf.get_torch_sample_sphere_coords(\n",
    "    viz_sphere, coeffs.device, coeffs.dtype\n",
    ")\n",
    "viz_ll = ll[0]\n",
    "viz_pre_filter_ll = pre_filter_lobe_labels[0]\n",
    "polar_tri = mpl.tri.Triangulation(viz_phi, viz_theta)\n",
    "polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "\n",
    "# Take labels from pre-segmentation filtering.\n",
    "if not post_seg_filter:\n",
    "    viz_tri_labels = viz_pre_filter_ll.flatten()[polar_tri_idx]\n",
    "else:\n",
    "    # Take labels from post-segmentation filtering.\n",
    "    viz_tri_labels = viz_ll.flatten()[polar_tri_idx]\n",
    "\n",
    "label_cmap = sns.cubehelix_palette(\n",
    "    n_colors=len(np.unique(viz_tri_labels.flatten())), reverse=True, rot=2, as_cmap=True\n",
    ")\n",
    "# viz_tri_labels = torch.mean(viz_tri_labels.float(), dim=1)\n",
    "viz_tri_labels = torch.median(viz_tri_labels, dim=1).values\n",
    "\n",
    "with torch.no_grad():\n",
    "    viz_coeffs = coeffs[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    viz_mask = mask[(slice(None),) + vox_idx][:, None, None, None]\n",
    "    # Function applies non-negativity constraint.\n",
    "    viz_sphere_samples = pitn.odf.sample_sphere_coords(\n",
    "        viz_coeffs,\n",
    "        theta=viz_theta,\n",
    "        phi=viz_phi,\n",
    "        sh_order=8,\n",
    "        sh_order_dim=0,\n",
    "        mask=viz_mask,\n",
    "    )\n",
    "\n",
    "viz_fodf = np.copy(viz_sphere_samples.detach().cpu().numpy().flatten())\n",
    "viz_tri_labels = viz_tri_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "viz_theta = viz_theta.detach().cpu().numpy().flatten()\n",
    "viz_phi = viz_phi.detach().cpu().numpy().flatten()\n",
    "directions, values, indices = dipy.direction.peak_directions(\n",
    "    viz_fodf, viz_sphere, relative_peak_threshold=0.5, min_separation_angle=25\n",
    ")\n",
    "# viz_fodf[viz_fodf < values.min() * 0.3] = 1e-8\n",
    "with mpl.rc_context({\"figure.autolayout\": False}):\n",
    "    fig = plt.figure(dpi=120)\n",
    "\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    vals = viz_fodf\n",
    "\n",
    "    r = (vals - vals.min()) / (vals - vals.min()).max()\n",
    "    r = vals / vals.sum()\n",
    "\n",
    "    x = r * np.sin(viz_theta) * np.cos(viz_phi)\n",
    "    y = r * np.sin(viz_theta) * np.sin(viz_phi)\n",
    "    z = r * np.cos(viz_theta)\n",
    "    mapper = mpl.cm.ScalarMappable(cmap=label_cmap)\n",
    "\n",
    "    # center_colors = mapper.to_rgba(viz_tri_labels)\n",
    "    # center_colors = np.where((viz_tri_labels == 0)[:, None], np.zeros_like(center_colors), center_colors)\n",
    "    #     vertex_colors = mapper.to_rgba(ll.numpy().flatten()[polar_tri.edges])\n",
    "    # polar_tri_idx = torch.from_numpy(polar_tri.triangles).long()\n",
    "    # viz_tri_labels = ll.flatten()[polar_tri_idx]\n",
    "    euclid_tri = mpl.tri.Triangulation(x, y, triangles=polar_tri.triangles)\n",
    "    surf = ax.plot_trisurf(euclid_tri, z, linewidth=0.3, antialiased=True, zorder=4)\n",
    "\n",
    "    if to_plot == \"surface\":\n",
    "        face_colors = mapper.to_rgba(viz_tri_labels)\n",
    "        face_colors = np.where(\n",
    "            (viz_tri_labels == 0)[:, None], np.zeros_like(face_colors), face_colors\n",
    "        )\n",
    "        surf.set_fc(face_colors)\n",
    "    elif to_plot == \"points\":\n",
    "        surf.set_fc(\"white\")\n",
    "        surf.set_edgecolors([0.2, 0.2, 0.2, 0.5])\n",
    "        if post_seg_filter:\n",
    "            point_colors = mapper.to_rgba(viz_ll.numpy().flatten())\n",
    "            point_colors = np.where(\n",
    "                (viz_ll.numpy().flatten() == 0)[:, None],\n",
    "                np.zeros_like(point_colors),\n",
    "                point_colors,\n",
    "            )\n",
    "        else:\n",
    "            point_colors = mapper.to_rgba(viz_pre_filter_ll.numpy().flatten())\n",
    "            point_colors = np.where(\n",
    "                (viz_pre_filter_ll.numpy().flatten() == 0)[:, None],\n",
    "                np.zeros_like(point_colors),\n",
    "                point_colors,\n",
    "            )\n",
    "        ax.scatter3D(x, y, z, c=point_colors, s=20, zorder=0.1)\n",
    "    plt.colorbar(mapper, shrink=0.67)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "fill = x.new_tensor([1, 3, 2])[:, None]\n",
    "m = torch.randint_like(x, 0, 2).bool()\n",
    "print(m)\n",
    "x.masked_scatter(m, fill.expand(3, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aef92aa78cb5293db69150d077de12929a6427717a8642923c8240ccc3365fd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
