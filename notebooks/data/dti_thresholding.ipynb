{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e889a1da-5b94-4875-8f67-f2474ef1ea69",
   "metadata": {},
   "source": [
    "# DTI Noise Removal via Threshold Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a215b67-c9cd-4fb6-82bb-243c5d50cd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically re-import project-specific modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import collections\n",
    "import functools\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import copy\n",
    "import pdb\n",
    "import inspect\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import zipfile\n",
    "\n",
    "import dipy\n",
    "import dipy.core\n",
    "import dipy.reconst\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask\n",
    "import dotenv\n",
    "\n",
    "# visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipyplot\n",
    "\n",
    "# Data management libraries.\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "from addict import Addict\n",
    "import pprint\n",
    "from pprint import pprint as ppr\n",
    "import box\n",
    "from box import Box\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchio\n",
    "import monai\n",
    "\n",
    "import skimage\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import pitn\n",
    "\n",
    "plt.rcParams.update({\"figure.autolayout\": True})\n",
    "plt.rcParams.update({\"figure.facecolor\": [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# Set print options for ndarrays/tensors.\n",
    "np.set_printoptions(suppress=True, threshold=100, linewidth=88)\n",
    "torch.set_printoptions(sci_mode=False, threshold=100, linewidth=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb97321-ff19-4cea-98f5-c4ee1ae922de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update notebook's environment variables with direnv.\n",
    "# This requires the python-dotenv package, and direnv be installed on the system\n",
    "# This will not work on Windows.\n",
    "# NOTE: This is kind of hacky, and not necessarily safe. Be careful...\n",
    "# Libraries needed on the python side:\n",
    "# - os\n",
    "# - subprocess\n",
    "# - io\n",
    "# - dotenv\n",
    "\n",
    "# Form command to be run in direnv's context. This command will print out\n",
    "# all environment variables defined in the subprocess/sub-shell.\n",
    "command = \"direnv exec {} /usr/bin/env\".format(os.getcwd())\n",
    "# Run command in a new subprocess.\n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, cwd=os.getcwd())\n",
    "# Store and format the subprocess' output.\n",
    "proc_out = proc.communicate()[0].strip().decode(\"utf-8\")\n",
    "# Use python-dotenv to load the environment variables by using the output of\n",
    "# 'direnv exec ...' as a 'dummy' .env file.\n",
    "dotenv.load_dotenv(stream=io.StringIO(proc_out), override=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b8d5a-719b-477a-b9be-258165d7607d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specs Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a525432-3d7a-492c-abb5-dca3545950bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "# Capture output and save to log. Needs to be at the *very first* line of the cell.\n",
    "# Watermark\n",
    "%load_ext watermark\n",
    "%watermark --author \"Tyler Spears\" --updated --iso8601  --python --machine --iversions --githash\n",
    "if torch.cuda.is_available():\n",
    "    # GPU information\n",
    "    try:\n",
    "        gpu_info = pitn.utils.system.get_gpu_specs()\n",
    "        print(gpu_info)\n",
    "    except NameError:\n",
    "        print(\"CUDA Version: \", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA not in use, falling back to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3daf41c-a0e3-48a9-9612-abf1794542e6",
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Tyler Spears\n",
      "\n",
      "Last updated: 2022-02-15T18:11:32.447400+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-99-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 4152448860d966bfad5dd6d91175a4c83ce3512d\n",
      "\n",
      "numpy     : 1.20.2\n",
      "dipy      : 1.4.1\n",
      "scipy     : 1.5.3\n",
      "monai     : 0.8.0\n",
      "skimage   : 0.18.1\n",
      "box       : 5.4.1\n",
      "pitn      : 0.0.post1.dev132+g02c0d1a\n",
      "matplotlib: 3.4.1\n",
      "seaborn   : 0.11.1\n",
      "torch     : 1.10.0\n",
      "torchio   : 0.18.30\n",
      "natsort   : 7.1.1\n",
      "json      : 2.0.9\n",
      "nibabel   : 3.2.1\n",
      "sys       : 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "pandas    : 1.2.3\n",
      "\n",
      "==================================================GPU Specs==================================================\n",
      "  id  Name              Driver Version      CUDA Version  Total Memory    uuid\n",
      "----  ----------------  ----------------  --------------  --------------  ----------------------------------------\n",
      "   0  NVIDIA TITAN RTX  470.103.01                  11.3  24217.0MB       GPU-586d2016-71ef-ebb3-437b-6721a22191ec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cap is defined in an ipython magic command\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1f93f-76ba-4f93-821a-306759961bac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Variables & Definitions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7f9d0-bfdb-45ae-95d8-68c722c6ba91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "assert data_dir.exists()\n",
    "write_data_dir = pathlib.Path(os.environ[\"WRITE_DATA_DIR\"])\n",
    "assert write_data_dir.exists()\n",
    "results_dir = pathlib.Path(os.environ[\"RESULTS_DIR\"])\n",
    "assert results_dir.exists()\n",
    "tmp_results_dir = pathlib.Path(os.environ[\"TMP_RESULTS_DIR\"])\n",
    "assert tmp_results_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e924fa8-0852-4d84-a5c2-e3611354543f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Reading & Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d1cde-0333-42ee-b27d-259ce10a3684",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e73fed-dd40-4266-8d0d-cc05c34bbbf8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Here are all the parameters! This makes it easy to find them! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6deee53-1fac-4585-8b42-2561ae7a5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Box(default_box=True)\n",
    "\n",
    "# General experiment-wide params\n",
    "###############################################\n",
    "params.experiment_name = \"debug_rmse_metrics\"\n",
    "###############################################\n",
    "# 6 channels for the 6 DTI components\n",
    "params.n_channels = 6\n",
    "params.n_subjs = 16\n",
    "params.lr_vox_size = 2.5\n",
    "params.fr_vox_size = 1.25\n",
    "params.use_anat = True\n",
    "\n",
    "# Data params\n",
    "params.data.fr_dir = data_dir / f\"scale-{params.fr_vox_size:.2f}mm\"\n",
    "params.data.lr_dir = data_dir / f\"scale-{params.lr_vox_size:.2f}mm\"\n",
    "params.data.dti_fname_pattern = r\"sub-*dti.nii.gz\"\n",
    "params.data.mask_fname_pattern = r\"dti/sub-*mask.nii.gz\"\n",
    "params.data.anat_type = \"t2w\"\n",
    "params.data.anat_fname_pattern = f\"sub-*{params.data.anat_type}.nii.gz\"\n",
    "# The data were downsampled artificially by this factor.\n",
    "params.data.downsampled_by_factor = params.lr_vox_size / params.fr_vox_size\n",
    "params.data.downsampled_by_factor = (\n",
    "    int(params.data.downsampled_by_factor)\n",
    "    if int(params.data.downsampled_by_factor) == params.data.downsampled_by_factor\n",
    "    else params.data.downsampled_by_factor\n",
    ")\n",
    "\n",
    "# This is the number of voxels to remove (read: center crop out) from the network's\n",
    "# prediction. This allows for an \"oversampling\" of the low-res voxels to help inform a\n",
    "# more constrained HR prediction. This value of voxels will be removed from each spatial\n",
    "# dimension (D, H, and W) starting at the center of the output patches.\n",
    "# Ex. A size of 1 will remove the 2 outer-most voxels from each dimension in the output,\n",
    "# while still keeping the corresponding voxels in the LR input.\n",
    "params.hr_center_crop_per_side = 0\n",
    "\n",
    "# Quantile clamping to be done on the outer edge of the mask.\n",
    "# NOTE: This clamping *will* effect the test and validation scores, as those voxels\n",
    "# clamped by this are considered as \"errors\"/\"noise\" and will be discarded in testing.\n",
    "# 80,000 is ~ the average volume of the entire brain mask.\n",
    "# params.data.edge_correction_max_vox_to_change = 300\n",
    "# # params.data.mask_edge_clamp_max_quantile = False\n",
    "# # Second data scaling method, where the training data will be scaled and possibly clipped,\n",
    "# # but the testing data will be compared on the originals.\n",
    "# # Scale input data by the valid values of each channel of the DTI.\n",
    "# # I.e., Dx,x in [0, 1], Dx,y in [-1, 1], Dy,y in [0, 1], Dy,z in [-1, 1], etc.\n",
    "# params.data.dti_scale_range = ((0, -1, 0, -1, -1, 0), (1, 1, 1, 1, 1, 1))\n",
    "# params.data.anat_scale_range = (0, 1)\n",
    "# params.data.scale_to_quantiles = (0.0001, 0.9999)\n",
    "# params.data.clip_to_quantiles = True\n",
    "\n",
    "# Network params.\n",
    "# The network's goal is to upsample the input by this factor.\n",
    "params.net.upscale_factor = params.data.downsampled_by_factor\n",
    "params.net.kwargs.n_res_units = 3\n",
    "params.net.kwargs.n_dense_units = 3\n",
    "params.net.kwargs.interior_channels = params.n_channels * 2\n",
    "params.net.kwargs.activate_fn = F.elu\n",
    "params.net.kwargs.upsample_activate_fn = F.elu\n",
    "params.net.kwargs.center_crop_output_side_amt = params.hr_center_crop_per_side\n",
    "\n",
    "# Adam optimizer kwargs\n",
    "params.optim.name = \"AdamW\"\n",
    "params.optim.kwargs.lr = 5e-4\n",
    "params.optim.kwargs.betas = (0.9, 0.999)\n",
    "\n",
    "# Testing params\n",
    "params.test.dataset_subj_percent = 0.4\n",
    "\n",
    "# Validation params\n",
    "params.val.dataset_subj_percent = 0.2\n",
    "\n",
    "# Training params\n",
    "params.train.in_patch_size = (24, 24, 24)\n",
    "params.train.batch_size = 32\n",
    "params.train.samples_per_subj_per_epoch = 8000\n",
    "params.train.max_epochs = 50\n",
    "params.train.loss_name = \"mse\"\n",
    "# Percentage of subjs in dataset that go into the training set.\n",
    "params.train.dataset_subj_percent = 1 - (\n",
    "    params.test.dataset_subj_percent + params.val.dataset_subj_percent\n",
    ")\n",
    "\n",
    "# Learning rate scheduler config.\n",
    "params.train.lr_scheduler.name = \"OneCycleLR\"\n",
    "params.train.lr_scheduler.kwargs.max_lr = 3e-3\n",
    "params.train.lr_scheduler.kwargs.epochs = params.train.max_epochs\n",
    "num_test_subjs = int(np.ceil(params.n_subjs * params.test.dataset_subj_percent))\n",
    "num_val_subjs = int(np.ceil(params.n_subjs * params.val.dataset_subj_percent))\n",
    "num_train_subjs = params.n_subjs - (num_test_subjs + num_val_subjs)\n",
    "params.train.lr_scheduler.kwargs.steps_per_epoch = (\n",
    "    params.train.samples_per_subj_per_epoch * num_train_subjs // params.train.batch_size\n",
    ")\n",
    "\n",
    "# If a config file exists, override the defaults with those values.\n",
    "try:\n",
    "    if \"PITN_CONFIG\" in os.environ.keys():\n",
    "        config_fname = Path(os.environ[\"PITN_CONFIG\"])\n",
    "    else:\n",
    "        config_fname = pitn.utils.system.get_file_glob_unique(Path(\".\"), r\"config.*\")\n",
    "    f_type = config_fname.suffix.casefold()\n",
    "    if f_type in {\"yaml\", \"yml\"}:\n",
    "        f_params = Box.from_yaml(config_fname)\n",
    "    elif f_type == \"json\":\n",
    "        f_params = Box.from_json(config_fname)\n",
    "    elif f_type == \"toml\":\n",
    "        f_params = Box.from_toml(config_fname)\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    params.merge_update(f_params)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove the default_box behavior now that params have been fully read in.\n",
    "p = Box(default_box=False)\n",
    "p.merge_update(params)\n",
    "params = p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfde6ed-4ffe-4afb-9b54-28d68e1b50f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39896f-2326-424c-a48a-dcb72a592317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subject ID Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20c223-04ae-43da-ac5c-a8495b2113f1",
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'103010': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-103010'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-103010')},\n",
      " '135528': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-135528'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-135528')},\n",
      " '140117': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-140117'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-140117')},\n",
      " '141422': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-141422'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-141422')},\n",
      " '156637': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-156637'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-156637')},\n",
      " '185947': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-185947'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-185947')},\n",
      " '224022': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-224022'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-224022')},\n",
      " '227432': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-227432'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-227432')},\n",
      " '303624': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-303624'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-303624')},\n",
      " '397154': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-397154'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-397154')},\n",
      " '644246': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-644246'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-644246')},\n",
      " '700634': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-700634'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-700634')},\n",
      " '751348': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-751348'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-751348')},\n",
      " '753251': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-753251'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-753251')},\n",
      " '810439': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-810439'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-810439')},\n",
      " '894774': {'fr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-1.25mm/sub-894774'),\n",
      "            'lr': PosixPath('/srv/tmp/data/pitn/hcp/derivatives/diqt/mean-downsample/scale-2.50mm/sub-894774')}}\n"
     ]
    }
   ],
   "source": [
    "# Find data directories for each subject.\n",
    "subj_dirs: Box = Box()\n",
    "\n",
    "selected_ids = [\n",
    "    \"397154\",\n",
    "    \"224022\",\n",
    "    \"140117\",\n",
    "    \"751348\",\n",
    "    \"894774\",\n",
    "    \"156637\",\n",
    "    \"227432\",\n",
    "    \"303624\",\n",
    "    \"185947\",\n",
    "    \"810439\",\n",
    "    \"753251\",\n",
    "    \"644246\",\n",
    "    \"141422\",\n",
    "    \"135528\",\n",
    "    \"103010\",\n",
    "    \"700634\",\n",
    "]\n",
    "\n",
    "## Sub-set the chosen participants for dev and debugging!\n",
    "sampled_subjs = random.sample(selected_ids, params.n_subjs)\n",
    "if len(sampled_subjs) < len(selected_ids):\n",
    "    warnings.warn(\n",
    "        f\"WARNING: Sub-selecting {len(sampled_subjs)}/{len(selected_ids)} \"\n",
    "        + \"participants for dev and debugging. \"\n",
    "        + f\"Subj IDs selected: {sampled_subjs}\"\n",
    "    )\n",
    "selected_subjs = sampled_subjs\n",
    "# ### A nested warning! For debugging only.\n",
    "# warnings.warn(\"WARNING: Mixing training and testing subjects\")\n",
    "# selected_ids.append(selected_ids[0])\n",
    "# ###\n",
    "##\n",
    "\n",
    "selected_subjs = natsorted(selected_subjs)\n",
    "\n",
    "for subj_id in selected_subjs:\n",
    "    subj_dirs[subj_id] = Box()\n",
    "    subj_dirs[subj_id].fr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.fr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    subj_dirs[subj_id].lr = pitn.utils.system.get_file_glob_unique(\n",
    "        params.data.lr_dir, f\"*{subj_id}*\"\n",
    "    )\n",
    "    assert subj_dirs[subj_id].fr.exists()\n",
    "    assert subj_dirs[subj_id].lr.exists()\n",
    "ppr(subj_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efafa0b-7243-4d3c-8a4d-cb2946c76282",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf97e5-b3bb-4229-a081-3a0c576f2e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Dataset loading.\n",
    "\n",
    "# Data reader object for NIFTI files.\n",
    "nib_reader = monai.data.NibabelReader(as_closest_canonical=True)\n",
    "\n",
    "# HR -> LR patch coordinate conversion function.\n",
    "fr2lr_patch_coords_fn = {\n",
    "    \"lr_dti\": functools.partial(\n",
    "        pitn.coords.transform.int_downscale_patch_idx,\n",
    "        downscale_factor=params.data.downsampled_by_factor,\n",
    "        downscale_patch_shape=params.train.in_patch_size,\n",
    "    )\n",
    "}\n",
    "\n",
    "# Kwargs for the patches dataset (the _VolPatchDataset class) of the HR volumes.\n",
    "patch_kwargs = dict(\n",
    "    patch_shape=tuple(\n",
    "        np.floor(\n",
    "            np.asarray(params.train.in_patch_size) * params.data.downsampled_by_factor\n",
    "        ).astype(int)\n",
    "    ),\n",
    "    stride=1,\n",
    "    meta_keys_to_patch_index={\"dti\", \"mask\", params.data.anat_type},\n",
    "    mask_name=\"mask\",\n",
    ")\n",
    "\n",
    "\n",
    "def fix_downsample_shape_errors(\n",
    "    fr_vol: torch.Tensor, fr_affine: torch.Tensor, target_spatial_shape: tuple\n",
    "):\n",
    "    \"\"\"Small utility to fix shape differences between LR and FR data.\"\"\"\n",
    "    target_shape = np.asarray(target_spatial_shape)\n",
    "    if fr_vol.shape[1:] != tuple(target_shape):\n",
    "        # Use torchio objects because they fix the affine matrix, too.\n",
    "        # Flip before transform to pad on the right/top/furthest side of the dimension\n",
    "        # first, before the left/bottom/closest.\n",
    "        flip_vol = fr_vol.flip([1, 2, 3])\n",
    "        im = torchio.ScalarImage(tensor=flip_vol, affine=fr_affine)\n",
    "        transform = torchio.transforms.CropOrPad(target_spatial_shape, 0, copy=False)\n",
    "        im = transform(im)\n",
    "        result_vol = im[\"data\"]\n",
    "        # Unflip.\n",
    "        result_vol = result_vol.flip([1, 2, 3])\n",
    "        result_aff = im[\"affine\"]\n",
    "    else:\n",
    "        result_vol = fr_vol\n",
    "        result_aff = fr_affine\n",
    "\n",
    "    return result_vol, result_aff\n",
    "\n",
    "\n",
    "def orient_to_viz(vol, affine):\n",
    "\n",
    "    if torch.is_tensor(vol):\n",
    "        v = vol.detach().cpu().numpy()\n",
    "    else:\n",
    "        v = vol\n",
    "    v = np.rot90(np.rot90(v, k=1, axes=(1, 3)), k=2, axes=(2, 3))\n",
    "    if torch.is_tensor(vol):\n",
    "        v = torch.from_numpy(np.copy(v)).to(vol)\n",
    "\n",
    "    # Adjust the affine matrix.\n",
    "    full_rot_aff = np.zeros_like(affine)\n",
    "    full_rot_aff[-1, -1] = 1.0\n",
    "    # 90 degree rot around the second axis.\n",
    "    q1 = nib.quaternions.angle_axis2quat(np.pi / 2, [0, 1, 0])\n",
    "    # 180 degree rot around the first axis.\n",
    "    q2 = nib.quaternions.angle_axis2quat(np.pi, [1, 0, 0])\n",
    "    new_q = nib.quaternions.mult(q1, q2)\n",
    "    rot_aff = nib.quaternions.quat2mat(new_q)\n",
    "    full_rot_aff[:-1, :-1] = rot_aff\n",
    "    new_aff = full_rot_aff @ affine\n",
    "\n",
    "    return v, new_aff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dca13-79fc-4687-a9ec-727f634cb806",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c614f5-21c1-44a6-9768-f0377a2bc1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and organize all data.\n",
    "subj_data: dict = dict()\n",
    "\n",
    "meta_keys_to_keep = {\"affine\", \"original_affine\"}\n",
    "for subj_id, subj_dir in subj_dirs.items():\n",
    "\n",
    "    data = dict()\n",
    "    data[\"subj_id\"] = subj_id\n",
    "    fr_subj_dir = subj_dirs[subj_id][\"fr\"]\n",
    "    lr_subj_dir = subj_dirs[subj_id][\"lr\"]\n",
    "    data[\"fr_subj_dir\"] = fr_subj_dir\n",
    "    data[\"lr_subj_dir\"] = lr_subj_dir\n",
    "\n",
    "    # Low-resolution DTI.\n",
    "    lr_dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        lr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(lr_dti_f)\n",
    "    lr_dti, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    lr_dti = torch.from_numpy(lr_dti)\n",
    "    lr_dti, meta[\"affine\"] = orient_to_viz(lr_dti, meta[\"affine\"])\n",
    "    data[\"lr_dti\"] = lr_dti\n",
    "    # Store raw LR DTI for cubic spline comparisons.\n",
    "    data[\"raw_lr_dti\"] = lr_dti\n",
    "    data[\"lr_dti_meta_dict\"] = meta\n",
    "\n",
    "    # May need to handle shape errors when re-upscaling back from LR to HR.\n",
    "    lr_dti_shape = np.asarray(lr_dti.shape[1:])\n",
    "    target_fr_shape = np.floor(lr_dti_shape * params.net.upscale_factor).astype(int)\n",
    "\n",
    "    # Full-resolution images/volumes.\n",
    "    # DTI.\n",
    "    dti_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.dti_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(dti_f)\n",
    "    dti, meta = nib_reader.get_data(im)\n",
    "    dti = torch.from_numpy(dti)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    dti, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        dti, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    dti, meta[\"affine\"] = orient_to_viz(dti, meta[\"affine\"])\n",
    "    data[\"dti\"] = dti\n",
    "    # Store raw DTI for validation and testing.\n",
    "    data[\"raw_dti\"] = dti\n",
    "    data[\"dti_meta_dict\"] = meta\n",
    "\n",
    "    # Diffusion mask.\n",
    "    mask_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.mask_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(mask_f)\n",
    "    mask, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    mask = torch.from_numpy(mask)\n",
    "    # Add channel dim if not available.\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[\n",
    "            None,\n",
    "        ]\n",
    "    mask, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        mask, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    mask, meta[\"affine\"] = orient_to_viz(mask, meta[\"affine\"])\n",
    "    mask = mask.bool()\n",
    "    data[\"mask\"] = mask\n",
    "    data[\"mask_meta_dict\"] = meta\n",
    "\n",
    "    # Anatomical/structural volume.\n",
    "    anat_f = pitn.utils.system.get_file_glob_unique(\n",
    "        fr_subj_dir, params.data.anat_fname_pattern\n",
    "    )\n",
    "    im = nib_reader.read(anat_f)\n",
    "    anat, meta = nib_reader.get_data(im)\n",
    "    meta = {k: meta[k] for k in meta_keys_to_keep}\n",
    "    anat = torch.from_numpy(anat)\n",
    "    if anat.ndim == 3:\n",
    "        anat = anat[\n",
    "            None,\n",
    "        ]\n",
    "    anat, meta[\"affine\"] = fix_downsample_shape_errors(\n",
    "        anat, meta[\"affine\"], target_fr_shape\n",
    "    )\n",
    "    anat, meta[\"affine\"] = orient_to_viz(anat, meta[\"affine\"])\n",
    "    data[params.data.anat_type] = anat\n",
    "    data[params.data.anat_type + \"_meta_dict\"] = meta\n",
    "\n",
    "    # plt.clf()\n",
    "    # dti = data['dti']\n",
    "    # fig, axs = plt.subplots(nrows=3, dpi=110)\n",
    "    # plt.title(f\"Subject {subj_id}\")\n",
    "    # axs[0].plot(dti.view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # axs[1].plot(dti.permute(0, 2, 1, 3).contiguous().view(6, 174, -1).max(2).values.numpy().T)\n",
    "    # axs[2].plot(dti.permute(0, 3, 1, 2).contiguous().view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # plt.show(close=True)\n",
    "\n",
    "    # Consider this as the \"noise correction\" step to have more understandable,\n",
    "    # stable, and consistent metric results. Otherwise, metrics can change by orders of\n",
    "    # magnitude for no good reason!\n",
    "    if \"edge_correction_max_vox_to_change\" in params.data:\n",
    "\n",
    "        correct_dti = pitn.data.norm.correct_edge_noise_with_median(\n",
    "            data[\"dti\"],\n",
    "            data[\"mask\"],\n",
    "            max_num_vox_to_change=params.data.edge_correction_max_vox_to_change,\n",
    "            erosion_st_elem=skimage.morphology.ball(4),\n",
    "            median_st_elem=skimage.morphology.cube(2),\n",
    "        )\n",
    "        print(\"DTI Correction Mean Abs. Error Per Tensor Component: \")\n",
    "        abs_diff = torch.abs(data[\"dti\"] - correct_dti)\n",
    "        mae = abs_diff.view(6, -1).sum(1)\n",
    "        mae = mae / data[\"mask\"].sum()\n",
    "        mae_str = \"\"\n",
    "\n",
    "        for c in range(params.n_channels):\n",
    "            mae_v = mae.detach().cpu()[c]\n",
    "            # iqr = torch.quantile(data[\"dti\"][c][data['mask'][0]], torch.as_tensor([0.25, 0.75]))\n",
    "            # iqr = torch.abs(iqr[1] - iqr[0]).item()\n",
    "            num_changed = (abs_diff[c] > 1e-13).sum().item()\n",
    "            med = torch.median(data[\"dti\"][c][data[\"mask\"][0]]).item()\n",
    "            s = (\n",
    "                \"\\t\"\n",
    "                + str(mae_v.item())\n",
    "                + f\" with {num_changed} changes vs. median \"\n",
    "                + str(med)\n",
    "                + \"\\n\"\n",
    "            )\n",
    "            mae_str = mae_str + s\n",
    "\n",
    "        print(mae_str)\n",
    "        data[\"dti\"] = correct_dti\n",
    "\n",
    "    elif \"mask_edge_quantile_clamp\" in params.data:\n",
    "        data[\"dti\"] = pitn.data.norm.mask_constrain_clamp(\n",
    "            data[\"dti\"],\n",
    "            data[\"mask\"],\n",
    "            quantile_clamp=params.data.mask_edge_quantile_clamp,\n",
    "            selection_st_elem=skimage.morphology.ball(2),\n",
    "        )\n",
    "\n",
    "        # cheap_lr_mask = F.interpolate(\n",
    "        #     data[\"mask\"][\n",
    "        #         None,\n",
    "        #     ].float(),\n",
    "        #     size=tuple(data[\"lr_dti\"].shape[1:]),\n",
    "        #     mode=\"nearest\",\n",
    "        # ).bool()[0]\n",
    "        # data[\"lr_dti\"] = pitn.data.norm.mask_constrain_clamp(\n",
    "        #     data[\"lr_dti\"],\n",
    "        #     cheap_lr_mask,\n",
    "        #     quantile_clamp=params.data.mask_edge_quantile_clamp,\n",
    "        #     selection_st_elem=skimage.morphology.ball(1),\n",
    "        # )\n",
    "    # plt.clf()\n",
    "    # dti = data['dti']\n",
    "    # fig, axs = plt.subplots(nrows=3, dpi=110)\n",
    "    # plt.title(f\"Subject {subj_id}\")\n",
    "    # axs[0].plot(dti.view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # axs[1].plot(dti.permute(0, 2, 1, 3).contiguous().view(6, 174, -1).max(2).values.numpy().T)\n",
    "    # axs[2].plot(dti.permute(0, 3, 1, 2).contiguous().view(6, 144, -1).max(2).values.numpy().T)\n",
    "    # plt.show(close=True)\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if \"dti_scale_range\" in params.data:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"dti\"], stateful=True, keep_orig=False)\n",
    "        data[\"dti\"] = scaled\n",
    "        data[\"dti_scaler\"] = scaler\n",
    "\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.dti_scale_range[0],\n",
    "            params.data.dti_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=params.n_channels,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(data[\"lr_dti\"], stateful=True, keep_orig=False)\n",
    "        data[\"lr_dti\"] = scaled\n",
    "        data[\"lr_dti_scaler\"] = scaler\n",
    "\n",
    "    # Perform scaling of input data?\n",
    "    if \"anat_scale_range\" in params.data:\n",
    "        scaler = pitn.data.norm.DTIMinMaxScaler(\n",
    "            params.data.anat_scale_range[0],\n",
    "            params.data.anat_scale_range[1],\n",
    "            quantile_low=params.data.scale_to_quantiles[0],\n",
    "            quantile_high=params.data.scale_to_quantiles[1],\n",
    "            dim=(1, 2, 3),\n",
    "            channel_size=1,\n",
    "            clip=params.data.clip_to_quantiles,\n",
    "        )\n",
    "        scaled = scaler.scale(\n",
    "            data[params.data.anat_type], stateful=True, keep_orig=False\n",
    "        )\n",
    "        # *****Disables anat mode refinement*******\n",
    "        # scaled = (scaled * 0) + 1\n",
    "        data[params.data.anat_type] = scaled\n",
    "        data[params.data.anat_type + \"_scaler\"] = scaler\n",
    "\n",
    "    vol_names = {\"dti\", \"mask\", \"lr_dti\", params.data.anat_type}\n",
    "    metadata_names = set(data.keys()) - vol_names\n",
    "    vol_d = {k: data[k] for k in vol_names}\n",
    "    meta_d = {k: data[k] for k in metadata_names}\n",
    "\n",
    "    # Create multi-volume dataset for this subj-session.\n",
    "    subj_dataset = pitn.data.SubjSesDataset(\n",
    "        vol_d,\n",
    "        primary_vol_name=\"dti\",\n",
    "        special_secondary2primary_coords_fns=fr2lr_patch_coords_fn,\n",
    "        transform=None,\n",
    "        primary_patch_kwargs=patch_kwargs,\n",
    "        **meta_d,\n",
    "    )\n",
    "    print(\"Creating patches\")\n",
    "    # Init the patches dataset.\n",
    "    subj_dataset.patches\n",
    "\n",
    "    # Finalize this subject.\n",
    "    subj_data[subj_id] = subj_dataset\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "print(\"===Data Loaded===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1532658-7831-4bd4-bc1a-41d3a0d37748",
   "metadata": {},
   "source": [
    "## Threshold Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240f71a-124d-4d5d-8d20-795d2f24c0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store the upper thresholds found for the DTI components, the eigenvalues of the\n",
    "# DTIs, and the threshold for the CSF found in the MD volumes.\n",
    "dti_component_thresholds = list()\n",
    "eigvals_thresholds = list()\n",
    "csf_thresholds = list()\n",
    "\n",
    "output_dir = results_dir.parent / \"dti_threshold\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for k_subj in subj_data.keys():\n",
    "    s = subj_data[k_subj][0]\n",
    "    dti = torch.clone(s[\"raw_dti\"]).detach().cpu().numpy()\n",
    "    mask = torch.clone(s[\"mask\"]).detach().cpu().numpy()[0].astype(bool)\n",
    "    dti_tensor = dipy.reconst.dti.from_lower_triangular(dti.transpose(1, 2, 3, 0))\n",
    "    eigvals, eigvecs = dipy.reconst.dti.decompose_tensor(dti_tensor)\n",
    "    md = dipy.reconst.dti.mean_diffusivity(eigvals)\n",
    "\n",
    "    # median filtered mask the mask\n",
    "    st_elem = skimage.morphology.ball(8)\n",
    "    mask = skimage.morphology.binary_erosion(mask, st_elem)\n",
    "    # Focus more removal of the superior of the brain, but leave rest of sides more-or-less\n",
    "    # unchanged.\n",
    "    st_elem = skimage.morphology.ball(10)\n",
    "    st_elem[10:, :, :] = 0\n",
    "    mask = skimage.morphology.binary_erosion(mask, st_elem)\n",
    "\n",
    "    selected_md = md * mask\n",
    "    thresh = skimage.filters.threshold_li(\n",
    "        selected_md[mask], tolerance=1e-6, initial_guess=0.0013\n",
    "    )\n",
    "    print(thresh)\n",
    "    csf_thresholds.append(thresh)\n",
    "    thresh_md = selected_md > thresh\n",
    "    # Constrain the CSF selection to larger objects.\n",
    "    thresh_md = skimage.morphology.remove_small_objects(thresh_md, 12**3, 2)\n",
    "    csf_mask = thresh_md\n",
    "\n",
    "    print(mask.sum())\n",
    "    fig = plt.figure(dpi=120)\n",
    "    pitn.viz.plot_vol_slices(thresh_md, md * mask, md * csf_mask, cmap=\"gray\", fig=fig)\n",
    "    plt.title(k_subj)\n",
    "    plt.savefig(output_dir / f\"sub-{k_subj}_thresh_md__mask_md__csf_md.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Select some multiple of some quantile of CSF as the actual \"cutoff\"\n",
    "    cutoff_quantile = 0.99\n",
    "    cutoff_factor = 1.1\n",
    "\n",
    "    # Select CSF over all tensor components.\n",
    "    select_dti = dti.transpose(1, 2, 3, 0)[csf_mask]\n",
    "    component_thresholds = (\n",
    "        np.quantile(select_dti, cutoff_quantile, axis=0) * cutoff_factor\n",
    "    )\n",
    "    dti_component_thresholds.append(component_thresholds)\n",
    "    plt.figure(dpi=120)\n",
    "    hist = sns.histplot(select_dti, legend=True, bins=100)\n",
    "    plt.vlines(component_thresholds, 0, plt.gca().get_ylim()[1], color=\"black\", lw=0.8)\n",
    "    plt.title(k_subj)\n",
    "    plt.savefig(output_dir / f\"sub-{k_subj}_dti_component_hist.png\")\n",
    "    plt.show()\n",
    "    print(component_thresholds)\n",
    "\n",
    "    # Select CSF over all eigenvalues components.\n",
    "    select_eigvals = eigvals[csf_mask]\n",
    "    eigval_cutoff = np.quantile(select_eigvals, cutoff_quantile, axis=0) * cutoff_factor\n",
    "    eigvals_thresholds.append(eigval_cutoff)\n",
    "    plt.figure(dpi=120)\n",
    "    sns.histplot(select_eigvals, legend=True, bins=100)\n",
    "    plt.vlines(eigval_cutoff, 0, plt.gca().get_ylim()[1], color=\"black\", lw=0.8)\n",
    "    plt.title(k_subj)\n",
    "    plt.savefig(output_dir / f\"sub-{k_subj}_eigenval_hist.png\")\n",
    "    plt.show()\n",
    "    print(eigval_cutoff)\n",
    "\n",
    "dti_component_thresholds = np.stack(dti_component_thresholds)\n",
    "eigvals_thresholds = np.stack(eigvals_thresholds)\n",
    "csf_thresholds = np.asarray(csf_thresholds)\n",
    "\n",
    "np.savetxt(\n",
    "    output_dir / \"dti_component_cutoffs_over_subjs.txt\", dti_component_thresholds\n",
    ")\n",
    "np.savetxt(output_dir / \"eigval_cutoffs_over_subjs.txt\", eigvals_thresholds)\n",
    "np.savetxt(output_dir / \"md_csf_thresholds_over_subjs.txt\", csf_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e36bf8-9214-4ffc-b69c-586d99518dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-pitn]",
   "language": "python",
   "name": "conda-env-miniconda-pitn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
